{"cells":[{"cell_type":"markdown","source":["##ALBERT"],"metadata":{"id":"qrnXIyrb2V7y"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6424,"status":"ok","timestamp":1761255439053,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"EAbQ-pla534P","outputId":"bfe4d487-e6f4-40ba-841d-5c57b352c0c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["üì¶ Installing required libraries...\n"]}],"source":["\"\"\"\n","ALBERT Fine-tuning for NEDA/EDA Classification\n","Medical text classification using Hugging Face Transformers\n","\"\"\"\n","\n","# ============================================================================\n","# STEP 1: Install Required Libraries\n","# ============================================================================\n","print(\"üì¶ Installing required libraries...\")\n","!pip install -q transformers datasets accelerate openpyxl scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20098,"status":"ok","timestamp":1761255459153,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"8PaDtaNy-q8G","outputId":"ba9fd48e-4b6e-4134-f290-a6a91bff5d1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["üìö Importing libraries...\n","‚úÖ All libraries imported successfully!\n","üî• PyTorch version: 2.8.0+cu126\n","ü§ó Transformers library loaded\n","üíª CUDA available: True\n","üéÆ GPU: NVIDIA A100-SXM4-40GB\n"]}],"source":["# ============================================================================\n","# STEP 2: Import Libraries\n","# ============================================================================\n","print(\"üìö Importing libraries...\")\n","import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","from google.colab import files, userdata\n","from transformers import (\n","    AlbertTokenizer,\n","    AlbertForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding\n",")\n","from datasets import Dataset, DatasetDict\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"‚úÖ All libraries imported successfully!\")\n","print(f\"üî• PyTorch version: {torch.__version__}\")\n","print(f\"ü§ó Transformers library loaded\")\n","print(f\"üíª CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":949,"status":"ok","timestamp":1761255460105,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"DdWwX-gv-o-L","outputId":"855857af-f9ab-421a-9a6d-d1d26a331a4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üîë Retrieving HuggingFace token from secrets...\n","‚úÖ HuggingFace token retrieved successfully!\n","‚úÖ Logged in to HuggingFace Hub!\n"]}],"source":["# ============================================================================\n","# STEP 3: Get HuggingFace Token from Colab Secrets\n","# ============================================================================\n","print(\"\\nüîë Retrieving HuggingFace token from secrets...\")\n","try:\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","    print(\"‚úÖ HuggingFace token retrieved successfully!\")\n","\n","    # Login to HuggingFace\n","    from huggingface_hub import login\n","    login(token=HF_TOKEN)\n","    print(\"‚úÖ Logged in to HuggingFace Hub!\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Warning: Could not retrieve HF_TOKEN from secrets: {e}\")\n","    print(\"You can continue without it, but won't be able to push to Hub\")\n","    HF_TOKEN = None"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"elapsed":33524,"status":"ok","timestamp":1761255493645,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"5LNUv0_9-nnF","outputId":"8e396dac-e748-4f48-9928-69ef331378d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìÅ Please upload your training Excel file...\n"]},{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-f97fee44-bf04-478f-8673-11ac7932e32c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f97fee44-bf04-478f-8673-11ac7932e32c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving train.xlsx to train.xlsx\n","‚úÖ Training file uploaded: train.xlsx\n","\n","üìÅ Please upload your test Excel file...\n"]},{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-83994a92-1273-47c9-8a76-2f4e63f734da\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-83994a92-1273-47c9-8a76-2f4e63f734da\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving test.xlsx to test.xlsx\n","‚úÖ Test file uploaded: test.xlsx\n"]}],"source":["# ============================================================================\n","# STEP 4: Upload Excel Files\n","# ============================================================================\n","print(\"\\nüìÅ Please upload your training Excel file...\")\n","train_uploaded = files.upload()\n","train_filename = list(train_uploaded.keys())[0]\n","print(f\"‚úÖ Training file uploaded: {train_filename}\")\n","\n","print(\"\\nüìÅ Please upload your test Excel file...\")\n","test_uploaded = files.upload()\n","test_filename = list(test_uploaded.keys())[0]\n","print(f\"‚úÖ Test file uploaded: {test_filename}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1761255494592,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"uVDwLk2C-moX","outputId":"c37f90af-9059-4f09-b1a5-e72e69c35caf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìä Loading data from Excel files...\n","‚úÖ Training data shape: (6472, 3)\n","‚úÖ Test data shape: (3373, 3)\n","\n","üìã Training data columns: ['MSC research database ID', 'input', 'output']\n","\n","üîç First few rows of training data:\n","   MSC research database ID  \\\n","0                         1   \n","1                         1   \n","2                         1   \n","3                         1   \n","4                         1   \n","\n","                                               input  \\\n","0  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","1  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","2  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","3  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","4  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","\n","                                        output  \n","0  After 7 months the patient will be in NEDA.  \n","1   After 7 months the patient will be in EDA.  \n","2   After 0 months the patient will be in EDA.  \n","3   After 4 months the patient will be in EDA.  \n","4  After 6 months the patient will be in NEDA.  \n"]}],"source":["# ============================================================================\n","# STEP 5: Load and Prepare Data\n","# ============================================================================\n","print(\"\\nüìä Loading data from Excel files...\")\n","train_df = pd.read_excel(train_filename)\n","test_df = pd.read_excel(test_filename)\n","\n","print(f\"‚úÖ Training data shape: {train_df.shape}\")\n","print(f\"‚úÖ Test data shape: {test_df.shape}\")\n","print(f\"\\nüìã Training data columns: {train_df.columns.tolist()}\")\n","print(f\"\\nüîç First few rows of training data:\")\n","print(train_df.head())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1761255494655,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"ItWu0pnh-laK","outputId":"bf8f615d-6a54-49de-aeda-a5152d5cb237"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üè∑Ô∏è Processing labels...\n","‚úÖ Labels extracted successfully!\n","üìä Training set after label extraction: 6472 samples\n","üìä Test set after label extraction: 3373 samples\n","\n","üìà Training label distribution:\n","label_text\n","NEDA    4989\n","EDA     1483\n","Name: count, dtype: int64\n","\n","üìà Test label distribution:\n","label_text\n","NEDA    2630\n","EDA      743\n","Name: count, dtype: int64\n"]}],"source":["# ============================================================================\n","# STEP 6: Process Labels - Extract NEDA/EDA from Output\n","# ============================================================================\n","print(\"\\nüè∑Ô∏è Processing labels...\")\n","\n","def extract_label(output_text):\n","    \"\"\"Extract NEDA or EDA from output text\"\"\"\n","    output_text = str(output_text).upper()\n","    if 'NEDA' in output_text:\n","        return 'NEDA'\n","    elif 'EDA' in output_text:\n","        return 'EDA'\n","    else:\n","        return None\n","\n","# Apply label extraction\n","train_df['label_text'] = train_df['output'].apply(extract_label)\n","test_df['label_text'] = test_df['output'].apply(extract_label)\n","\n","# Remove rows with None labels\n","train_df = train_df[train_df['label_text'].notna()].reset_index(drop=True)\n","test_df = test_df[test_df['label_text'].notna()].reset_index(drop=True)\n","\n","# Create label mapping\n","label2id = {'NEDA': 0, 'EDA': 1}\n","id2label = {0: 'NEDA', 1: 'EDA'}\n","\n","# Convert to numeric labels\n","train_df['label'] = train_df['label_text'].map(label2id)\n","test_df['label'] = test_df['label_text'].map(label2id)\n","\n","print(f\"‚úÖ Labels extracted successfully!\")\n","print(f\"üìä Training set after label extraction: {len(train_df)} samples\")\n","print(f\"üìä Test set after label extraction: {len(test_df)} samples\")\n","print(f\"\\nüìà Training label distribution:\")\n","print(train_df['label_text'].value_counts())\n","print(f\"\\nüìà Test label distribution:\")\n","print(test_df['label_text'].value_counts())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281,"referenced_widgets":["f98dbcabd58041b995fb59bc0fda48ed","7c36ace12e03476d9c2318081e4f0a64","8e3b04e44ab24f1693c6d64a6fc8aa69","e7ea349499f440fd9204185769693582","54bb36e698094c20a906aefe97f74171","61e94eab8f9c4ddbb9f72db1f387db56","a0b04db43f0343678b1746755ce87308","d5f677be442b4ba691c8243f2b9d61ae","ff2e5d6107fc44dc8443682b70d86101","70d618901f01412885b1fa121ac7e484","7fef952b5514444cb3a79270ccde3da1","b44535fac2024ad79f9b76a9b0e984f3","826124241c1b47279117b6441f671bec","1c6b5e42f8e147b0aca4c5826e7ea98f","f896360945394f48bfddc6b1451087f9","e464abe04e8749b2bb1b15adf365112b","18727f1d39fb4da995d0951100175e4c","a228dc72b2824522a721011075088ae4","caec450cf4514404ae7f9f34ef84ac49","a3cc4a0ba1f44a3580e4b52904ec40de","c944af58a8b14eb48a1cfd49bf43955a","498fc5ebd93d47fa88af5885ebc3f266","506c672ddafd4a50be5ceb48b9dd5973","096e435e0c244e4ab9888a6ec4ee8abf","42d0bc4541fc4e6cb30c608052055d3b","f27aa427c5af435c98b3b10ed49bf4a8","b5930620dfdf4f4a865d71d96aaba07b","5579d0645fb1412f8a6a68d1e513e789","ae30904af6934731ab2aa7fb019a6aef","a36c46d6389040d3808cb6cf498b2dd5","40ca89c9f4024d95a472c3b9bed8e31f","dd81abd6309a4f79b6acd1eeb8f517aa","d25196f38bc14ea0ad06702dd30771cf","311ad8ee6369473ab5eed73bf0698932","657c38841d274459a8c7b60c216c21cd","3e8922867dd94bb2853c305a0b29500a","c5c44c78211b4aaf81be8fab2b9ed4c3","947f1ce68e154471be21ad6a3c18a12d","fb17d2cc2921446f8a49a731d3be62e4","6e47b14aa55046a99e050c0ea88eb9d8","7537bca305a64bcf8ea563c7a4db7472","4fa913e4bb4d4c499fce56b941a5fb12","57e0aa0e2b3d4abda0f9a20c5bb06b68","2cc6683cd8224983bbd49004eaf3e58b","96e65f9efbbf45a2bf8dec4cd7f60dd9","2388be90c1a54fb190364235bc50a021","d7042e99182c4b7bbdfb95233869fcaf","226c1c684586489093f6754c6c8f328a","a2c0bb04485945b3b339e59d4cb12a39","cb989660c5df44acb59a6f1e42c31b1d","fa2334be5f32453f9d2893d4680cedf0","277f90d071834752961268addfe1d862","03c7c0538ad0469fb55b7b9902662862","27fb9d6f1b95457790d7e30d35334d39","7d56812b9a3e42f2b00a0dacfa7e6949"]},"executionInfo":{"elapsed":7381,"status":"ok","timestamp":1761255502038,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"sgPG00oP-jzm","outputId":"12e0252c-61f2-4ba7-88c8-40b6295b7dac"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ü§ñ Loading ALBERT model and tokenizer...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f98dbcabd58041b995fb59bc0fda48ed","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b44535fac2024ad79f9b76a9b0e984f3","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"506c672ddafd4a50be5ceb48b9dd5973","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"311ad8ee6369473ab5eed73bf0698932","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96e65f9efbbf45a2bf8dec4cd7f60dd9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["‚úÖ Model loaded: albert-base-v2\n","‚úÖ Number of parameters: 11,685,122\n"]}],"source":["# ============================================================================\n","# STEP 7: Initialize Tokenizer and Model\n","# ============================================================================\n","print(\"\\nü§ñ Loading ALBERT model and tokenizer...\")\n","MODEL_NAME = \"albert-base-v2\"\n","\n","tokenizer = AlbertTokenizer.from_pretrained(MODEL_NAME)\n","model = AlbertForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id\n",")\n","\n","print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n","print(f\"‚úÖ Number of parameters: {model.num_parameters():,}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150,"referenced_widgets":["2b4b97855d10405ab070fdfd1a94fe74","85c7cdaed31e430c98bfaa53c922ec15","51336ce99fad4acf91bc9b9b5e5a2c5c","a30551dd672b44bfbafc8c4b76b7cfc1","79b25194457b42d7a723cd2581f9b740","e4c24bb3e1bc42d7a08f7b5c89a8ff4c","3ca2d12652574408a593639a7cc71680","4050fae0063f4cb0bac0d422c6b7c5ad","82c21b5ce1c14932b6ba97a035977385","40ec891fac5347e3b56828a2e3a318d2","46ead435f72c47108fe6e2f29d2fbac8","04c2ebf382ac4cd9b608c19ab968305f","26f42274caf546d8af44ee2617ed60b1","e7a5592ab86a456784018812fee11537","8e3cbf6a7f814bd092a312e1fd8a4f63","26abaf092ac645a8af180e956364aec9","987c83f9ae8e41caac17e0d3878c80b6","a96dc792ec16466696bc1dca8344ce09","ff2d9cbf049b499da0df0b98d7c32e8c","a0e20b8d09a84fde976061225ed23448","c4b6c531c99c4e0e93c8188a165f24e2","0ead3fdcd6c34b20b8168dbaec99d373"]},"executionInfo":{"elapsed":17710,"status":"ok","timestamp":1761255519750,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"Yz4Jo7Ty-icd","outputId":"8f94339d-fd33-42f0-8569-7aef364ee2f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üî§ Tokenizing data...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b4b97855d10405ab070fdfd1a94fe74","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/6472 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04c2ebf382ac4cd9b608c19ab968305f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["‚úÖ Training dataset: 6472 samples\n","‚úÖ Test dataset: 3373 samples\n"]}],"source":["# ============================================================================\n","# STEP 8: Tokenize Data\n","# ============================================================================\n","print(\"\\nüî§ Tokenizing data...\")\n","\n","def tokenize_function(examples):\n","    \"\"\"Tokenize input texts\"\"\"\n","    return tokenizer(\n","        examples['input'],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=512\n","    )\n","\n","# Convert to Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(train_df[['input', 'label']])\n","test_dataset = Dataset.from_pandas(test_df[['input', 'label']])\n","\n","# Tokenize datasets\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","test_dataset = test_dataset.map(tokenize_function, batched=True)\n","\n","# Set format for PyTorch\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","print(f\"‚úÖ Training dataset: {len(train_dataset)} samples\")\n","print(f\"‚úÖ Test dataset: {len(test_dataset)} samples\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1761255519762,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"OOCBkvK8-guC","outputId":"7f11092a-d90b-4245-f86c-61e11dff9998"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìä Setting up evaluation metrics...\n","‚úÖ Evaluation metrics configured!\n"]}],"source":["\n","# ============================================================================\n","# STEP 9: Define Evaluation Metrics\n","# ============================================================================\n","print(\"\\nüìä Setting up evaluation metrics...\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"Compute metrics for evaluation\"\"\"\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels, predictions, average='binary'\n","    )\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(labels, predictions)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","print(\"‚úÖ Evaluation metrics configured!\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1761255519878,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"lQLAhUYH-e3W","outputId":"ca9a7363-c466-4edd-dae1-620da36078b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","‚öôÔ∏è Configuring training arguments...\n","‚úÖ Training arguments configured!\n","   - Learning rate: 2e-05\n","   - Batch size: 8\n","   - Epochs: 30\n","   - Device: GPU\n"]}],"source":["# ============================================================================\n","# STEP 10: Setup Training Arguments\n","# ============================================================================\n","print(\"\\n‚öôÔ∏è Configuring training arguments...\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',  # Disable wandb/tensorboard\n","    push_to_hub=False,  # Set to True if you want to push to Hub\n","    optim='adamw_torch',  # Use AdamW optimizer (Adam with weight decay)\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n",")\n","\n","print(\"‚úÖ Training arguments configured!\")\n","print(f\"   - Learning rate: {training_args.learning_rate}\")\n","print(f\"   - Batch size: {training_args.per_device_train_batch_size}\")\n","print(f\"   - Epochs: {training_args.num_train_epochs}\")\n","print(f\"   - Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1761255520161,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"KNtKCk3T-dVJ","outputId":"13510860-fc12-467d-805a-8ae8ed95dba7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üéØ Initializing Trainer...\n","‚úÖ Trainer initialized successfully!\n"]}],"source":["# ============================================================================\n","# STEP 11: Initialize Trainer\n","# ============================================================================\n","print(\"\\nüéØ Initializing Trainer...\")\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","print(\"‚úÖ Trainer initialized successfully!\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5194274,"status":"ok","timestamp":1761260714506,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"UOOgHyuI-b_5","outputId":"fc4de6cc-2e73-4cf1-cef5-1a14cf69d71f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üöÄ Starting training...\n","================================================================================\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='24270' max='24270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24270/24270 1:24:53, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.536500</td>\n","      <td>0.529978</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.464000</td>\n","      <td>0.527031</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.523600</td>\n","      <td>0.526867</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.529500</td>\n","      <td>0.527289</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.528900</td>\n","      <td>0.527028</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.675600</td>\n","      <td>0.529052</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.539200</td>\n","      <td>0.526671</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.550200</td>\n","      <td>0.535423</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.593600</td>\n","      <td>0.527373</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.514200</td>\n","      <td>0.527905</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.621600</td>\n","      <td>0.529218</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.494900</td>\n","      <td>0.528586</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.471800</td>\n","      <td>0.521190</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.626200</td>\n","      <td>0.528484</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.421400</td>\n","      <td>0.497166</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.452700</td>\n","      <td>0.496324</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.536800</td>\n","      <td>0.498853</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.442900</td>\n","      <td>0.507460</td>\n","      <td>0.776757</td>\n","      <td>0.432432</td>\n","      <td>0.043069</td>\n","      <td>0.078335</td>\n","      <td>[[2588, 42], [711, 32]]</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.533300</td>\n","      <td>0.519062</td>\n","      <td>0.757782</td>\n","      <td>0.395480</td>\n","      <td>0.188425</td>\n","      <td>0.255242</td>\n","      <td>[[2416, 214], [603, 140]]</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.476800</td>\n","      <td>0.522029</td>\n","      <td>0.777350</td>\n","      <td>0.433333</td>\n","      <td>0.034993</td>\n","      <td>0.064757</td>\n","      <td>[[2596, 34], [717, 26]]</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.453400</td>\n","      <td>0.535797</td>\n","      <td>0.744145</td>\n","      <td>0.387218</td>\n","      <td>0.277254</td>\n","      <td>0.323137</td>\n","      <td>[[2304, 326], [537, 206]]</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.374800</td>\n","      <td>0.559259</td>\n","      <td>0.739698</td>\n","      <td>0.378378</td>\n","      <td>0.282638</td>\n","      <td>0.323575</td>\n","      <td>[[2285, 345], [533, 210]]</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.608400</td>\n","      <td>0.630170</td>\n","      <td>0.723392</td>\n","      <td>0.353395</td>\n","      <td>0.308210</td>\n","      <td>0.329260</td>\n","      <td>[[2211, 419], [514, 229]]</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.438900</td>\n","      <td>0.598222</td>\n","      <td>0.745331</td>\n","      <td>0.364486</td>\n","      <td>0.209960</td>\n","      <td>0.266439</td>\n","      <td>[[2358, 272], [587, 156]]</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.561000</td>\n","      <td>0.635868</td>\n","      <td>0.755114</td>\n","      <td>0.388140</td>\n","      <td>0.193809</td>\n","      <td>0.258528</td>\n","      <td>[[2403, 227], [599, 144]]</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.402500</td>\n","      <td>0.738586</td>\n","      <td>0.728728</td>\n","      <td>0.346975</td>\n","      <td>0.262450</td>\n","      <td>0.298851</td>\n","      <td>[[2263, 367], [548, 195]]</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.421900</td>\n","      <td>0.693978</td>\n","      <td>0.731100</td>\n","      <td>0.351449</td>\n","      <td>0.261104</td>\n","      <td>0.299614</td>\n","      <td>[[2272, 358], [549, 194]]</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.333500</td>\n","      <td>0.712128</td>\n","      <td>0.743848</td>\n","      <td>0.366446</td>\n","      <td>0.223419</td>\n","      <td>0.277592</td>\n","      <td>[[2343, 287], [577, 166]]</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.199500</td>\n","      <td>0.715924</td>\n","      <td>0.750667</td>\n","      <td>0.388128</td>\n","      <td>0.228802</td>\n","      <td>0.287892</td>\n","      <td>[[2362, 268], [573, 170]]</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.320800</td>\n","      <td>0.742070</td>\n","      <td>0.748592</td>\n","      <td>0.382550</td>\n","      <td>0.230148</td>\n","      <td>0.287395</td>\n","      <td>[[2354, 276], [572, 171]]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","‚úÖ Training completed!\n","üìä Training Loss: 0.4914\n","‚è±Ô∏è Training Time: 5094.79 seconds\n"]}],"source":["# ============================================================================\n","# STEP 12: Train the Model\n","# ============================================================================\n","print(\"\\nüöÄ Starting training...\")\n","print(\"=\" * 80)\n","\n","train_result = trainer.train()\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"‚úÖ Training completed!\")\n","print(f\"üìä Training Loss: {train_result.training_loss:.4f}\")\n","print(f\"‚è±Ô∏è Training Time: {train_result.metrics['train_runtime']:.2f} seconds\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1761260714819,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"DCPqmwhK-arD","outputId":"031d6e5b-5434-458d-9a07-38c0ea2b829a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìà Evaluating on test set...\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='422' max='422' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [422/422 00:25]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","================================================================================\n","üìä EVALUATION RESULTS\n","================================================================================\n","‚úÖ Accuracy:  0.7234\n","‚úÖ Precision: 0.3534\n","‚úÖ Recall:    0.3082\n","‚úÖ F1 Score:  0.3293\n","\n","üéØ Confusion Matrix:\n","   [[2211, 419], [514, 229]]\n","================================================================================\n"]}],"source":["# ============================================================================\n","# STEP 13: Evaluate on Test Set\n","# ============================================================================\n","print(\"\\nüìà Evaluating on test set...\")\n","\n","eval_results = trainer.evaluate()\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"üìä EVALUATION RESULTS\")\n","print(\"=\" * 80)\n","print(f\"‚úÖ Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n","print(f\"‚úÖ Precision: {eval_results['eval_precision']:.4f}\")\n","print(f\"‚úÖ Recall:    {eval_results['eval_recall']:.4f}\")\n","print(f\"‚úÖ F1 Score:  {eval_results['eval_f1']:.4f}\")\n","print(f\"\\nüéØ Confusion Matrix:\")\n","print(f\"   {eval_results['eval_confusion_matrix']}\")\n","print(\"=\" * 80)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1761260714826,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"rIrJzqCj-ZWx","outputId":"dd30eb79-f7ad-47bb-a4a3-59537dd3f6c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üíæ Saving fine-tuned model...\n","‚úÖ Model saved to: ./albert_neda_eda_classifier\n"]}],"source":["# ============================================================================\n","# STEP 14: Save Model\n","# ============================================================================\n","print(\"\\nüíæ Saving fine-tuned model...\")\n","\n","model_save_path = './albert_neda_eda_classifier'\n","trainer.save_model(model_save_path)\n","tokenizer.save_pretrained(model_save_path)\n","\n","print(f\"‚úÖ Model saved to: {model_save_path}\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1761260714835,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"},"user_tz":-180},"id":"6cIn7XFF-YTm","outputId":"ea6a4b92-63d7-4820-dc9d-a9b3383c6ed8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üß™ Testing predictions on sample data...\n","\n","================================================================================\n","üîÆ SAMPLE PREDICTIONS\n","================================================================================\n","\n","üìù Input: Age:36.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation motor weakn...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.8917)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:34.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation motor weakn...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: EDA (Confidence: 0.8270)\n","‚ùå INCORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:48.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation motor weakn...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.8917)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:38.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation sensory, mo...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.8914)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:53.  Gender:female.  Diagnosis:spms. Converted to SPMS.  OCBs in CSF:positive. IgG index in CSF:...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.8915)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n"]}],"source":["# ============================================================================\n","# STEP 15: Test Predictions on Sample Data\n","# ============================================================================\n","print(\"\\nüß™ Testing predictions on sample data...\")\n","\n","# Get some test samples\n","test_samples = test_df.sample(min(5, len(test_df)))\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"üîÆ SAMPLE PREDICTIONS\")\n","print(\"=\" * 80)\n","\n","for idx, row in test_samples.iterrows():\n","    # Tokenize input\n","    inputs = tokenizer(\n","        row['input'],\n","        return_tensors='pt',\n","        truncation=True,\n","        max_length=512\n","    ).to(model.device)\n","\n","    # Get prediction\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","        predicted_class = torch.argmax(predictions, dim=-1).item()\n","\n","    predicted_label = id2label[predicted_class]\n","    true_label = row['label_text']\n","    confidence = predictions[0][predicted_class].item()\n","\n","    print(f\"\\nüìù Input: {row['input'][:100]}...\")\n","    print(f\"‚úÖ True Label: {true_label}\")\n","    print(f\"üîÆ Predicted: {predicted_label} (Confidence: {confidence:.4f})\")\n","    print(f\"{'‚úÖ CORRECT' if predicted_label == true_label else '‚ùå INCORRECT'}\")\n","    print(\"-\" * 80)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52t_3B9jVVml"},"outputs":[],"source":["# ============================================================================\n","# STEP 16: Save Model to Google Drive\n","# ============================================================================\n","print(\"\\nüíæ Saving fine-tuned model to Google Drive...\")\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Define model save path in Google Drive\n","model_save_path = '/content/drive/MyDrive/ALBERT_finetunned_Lynn'\n","\n","# Create the directory if it doesn't exist\n","import os\n","if not os.path.exists(model_save_path):\n","    os.makedirs(model_save_path)\n","    print(f\"Created directory: {model_save_path}\")\n","\n","# Save the model and tokenizer using the already initialized trainer and tokenizer\n","try:\n","    trainer.save_model(model_save_path)\n","    tokenizer.save_pretrained(model_save_path)\n","    print(f\"‚úÖ Model saved to: {model_save_path}\")\n","except NameError:\n","    print(\"‚ö†Ô∏è Error: trainer or tokenizer objects not found. Please ensure previous steps were executed.\")"]},{"cell_type":"markdown","metadata":{"id":"xwR88AnjUVh-"},"source":["##TinyBert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["3e1fa6e80ab34ce7aa14655c07f78d2c","9e9e45c2b6d54f1ca085e8cbfee81697","3d9d09fcaf5e47059e0dd6a734a78ce8","9eacbf8b844548289ce30fb0e3dd866a","db0a6fbd58f743e69d2cddc874be71e2","3f7156d0abe64efd9e31c495d47afa1f","3e865a810e9c42d4860cb3d379fca2f7","88c838515838441eb005d7514db57172","ad293daf28444776a531509849ef7535","0dfce3eef7e546d38e930efb66140897","aa6563cd1ff44c3eac0836532c9ae96a","fd807bfdfa814ebb8e9a6a47e8ac0046","a7b30f123a094f17b92088df05f5cb3f","d024a48e4bd1413c8806cb625abe167e","80cd098b8a0a421cadfc95d718b5b9b2","1df8f4b8584e42cdb62e1fb2f4f2fbe8","fd2b161432774c5db3049f9c6e443ee8","81cd439fdebb48dd8c7debf130595c42","3b937f6a1fa147999341005362f0df28","fc8778eb7ce24752a60342709c5f928a","b768ddd3cfd74fd4b6eef98fb107fca9","77fb09fa32354456aca69760f28a7d23"]},"id":"ySNIwZpVVYqH","executionInfo":{"status":"ok","timestamp":1761741209425,"user_tz":-120,"elapsed":1523503,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"cffc9678-02d6-40f5-cf46-f5bf2085103c"},"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing required libraries...\n","üìö Importing libraries...\n","‚úÖ All libraries imported successfully!\n","üî• PyTorch version: 2.8.0+cu126\n","ü§ó Transformers library loaded\n","üíª CUDA available: True\n","üéÆ GPU: NVIDIA A100-SXM4-40GB\n","\n","üîë Retrieving HuggingFace token from secrets...\n","‚úÖ Logged in to HuggingFace Hub!\n","\n","üìÅ Please upload your training Excel file...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c434eb62-36ef-4ef0-a597-0278b56e1293\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c434eb62-36ef-4ef0-a597-0278b56e1293\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train.xlsx to train (1).xlsx\n","‚úÖ Training file uploaded: train (1).xlsx\n","\n","üìÅ Please upload your test Excel file...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-26c25023-dfe4-46da-99d3-07624edcbf8b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-26c25023-dfe4-46da-99d3-07624edcbf8b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test.xlsx to test (1).xlsx\n","‚úÖ Test file uploaded: test (1).xlsx\n","\n","üìä Loading data from Excel files...\n","‚úÖ Training data shape: (6472, 3)\n","‚úÖ Test data shape: (3373, 3)\n","\n","üìã Training data columns: ['MSC research database ID', 'input', 'output']\n","\n","üîç First few rows of training data:\n","   MSC research database ID  \\\n","0                         1   \n","1                         1   \n","2                         1   \n","3                         1   \n","4                         1   \n","\n","                                               input  \\\n","0  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","1  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","2  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","3  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","4  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","\n","                                        output  \n","0  After 7 months the patient will be in NEDA.  \n","1   After 7 months the patient will be in EDA.  \n","2   After 0 months the patient will be in EDA.  \n","3   After 4 months the patient will be in EDA.  \n","4  After 6 months the patient will be in NEDA.  \n","\n","üè∑Ô∏è Processing labels...\n","‚úÖ Labels extracted successfully!\n","üìä Training set after label extraction: 6472 samples\n","üìä Test set after label extraction: 3373 samples\n","\n","üìà Training label distribution:\n","label_text\n","NEDA    4989\n","EDA     1483\n","Name: count, dtype: int64\n","\n","üìà Test label distribution:\n","label_text\n","NEDA    2630\n","EDA      743\n","Name: count, dtype: int64\n","\n","ü§ñ Loading TinyBERT model and tokenizer...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_6L_768D and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Model loaded: huawei-noah/TinyBERT_General_6L_768D\n","‚úÖ Number of parameters: 66,956,546\n","\n","üî§ Tokenizing data...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6472 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1fa6e80ab34ce7aa14655c07f78d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd807bfdfa814ebb8e9a6a47e8ac0046"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Training dataset: 6472 samples\n","‚úÖ Test dataset: 3373 samples\n","\n","üìä Setting up evaluation metrics...\n","‚úÖ Evaluation metrics configured!\n","\n","‚öôÔ∏è Configuring training arguments...\n","‚úÖ Training arguments configured!\n","   - Learning rate: 2e-05\n","   - Batch size: 8\n","   - Epochs: 30\n","   - Device: GPU\n","\n","üéØ Initializing Trainer...\n","‚úÖ Trainer initialized successfully!\n","\n","üöÄ Starting training...\n","================================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='24270' max='24270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [24270/24270 23:37, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.523900</td>\n","      <td>0.518769</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.477200</td>\n","      <td>0.526306</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.506900</td>\n","      <td>0.514623</td>\n","      <td>0.779721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[2630, 0], [743, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.522700</td>\n","      <td>0.517905</td>\n","      <td>0.778832</td>\n","      <td>0.459459</td>\n","      <td>0.022880</td>\n","      <td>0.043590</td>\n","      <td>[[2610, 20], [726, 17]]</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.560900</td>\n","      <td>0.518197</td>\n","      <td>0.775274</td>\n","      <td>0.409639</td>\n","      <td>0.045760</td>\n","      <td>0.082324</td>\n","      <td>[[2581, 49], [709, 34]]</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.707000</td>\n","      <td>0.515361</td>\n","      <td>0.774088</td>\n","      <td>0.434483</td>\n","      <td>0.084791</td>\n","      <td>0.141892</td>\n","      <td>[[2548, 82], [680, 63]]</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.492200</td>\n","      <td>0.518236</td>\n","      <td>0.778239</td>\n","      <td>0.475248</td>\n","      <td>0.064603</td>\n","      <td>0.113744</td>\n","      <td>[[2577, 53], [695, 48]]</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.522000</td>\n","      <td>0.511904</td>\n","      <td>0.780611</td>\n","      <td>0.527273</td>\n","      <td>0.039031</td>\n","      <td>0.072682</td>\n","      <td>[[2604, 26], [714, 29]]</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.544400</td>\n","      <td>0.522516</td>\n","      <td>0.780018</td>\n","      <td>0.509804</td>\n","      <td>0.034993</td>\n","      <td>0.065491</td>\n","      <td>[[2605, 25], [717, 26]]</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.491300</td>\n","      <td>0.527760</td>\n","      <td>0.774385</td>\n","      <td>0.400000</td>\n","      <td>0.048452</td>\n","      <td>0.086435</td>\n","      <td>[[2576, 54], [707, 36]]</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.617500</td>\n","      <td>0.528541</td>\n","      <td>0.764898</td>\n","      <td>0.354651</td>\n","      <td>0.082100</td>\n","      <td>0.133333</td>\n","      <td>[[2519, 111], [682, 61]]</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.493400</td>\n","      <td>0.547749</td>\n","      <td>0.767566</td>\n","      <td>0.352518</td>\n","      <td>0.065949</td>\n","      <td>0.111111</td>\n","      <td>[[2540, 90], [694, 49]]</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.366500</td>\n","      <td>0.555636</td>\n","      <td>0.767566</td>\n","      <td>0.360544</td>\n","      <td>0.071332</td>\n","      <td>0.119101</td>\n","      <td>[[2536, 94], [690, 53]]</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.547100</td>\n","      <td>0.632685</td>\n","      <td>0.763712</td>\n","      <td>0.341176</td>\n","      <td>0.078062</td>\n","      <td>0.127054</td>\n","      <td>[[2518, 112], [685, 58]]</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.406100</td>\n","      <td>0.612179</td>\n","      <td>0.749778</td>\n","      <td>0.355301</td>\n","      <td>0.166891</td>\n","      <td>0.227106</td>\n","      <td>[[2405, 225], [619, 124]]</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.284200</td>\n","      <td>0.606182</td>\n","      <td>0.763415</td>\n","      <td>0.356021</td>\n","      <td>0.091521</td>\n","      <td>0.145610</td>\n","      <td>[[2507, 123], [675, 68]]</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.484000</td>\n","      <td>0.606385</td>\n","      <td>0.753335</td>\n","      <td>0.330798</td>\n","      <td>0.117093</td>\n","      <td>0.172962</td>\n","      <td>[[2454, 176], [656, 87]]</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.357000</td>\n","      <td>0.622968</td>\n","      <td>0.754521</td>\n","      <td>0.330677</td>\n","      <td>0.111709</td>\n","      <td>0.167002</td>\n","      <td>[[2462, 168], [660, 83]]</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.422100</td>\n","      <td>0.686041</td>\n","      <td>0.739401</td>\n","      <td>0.311111</td>\n","      <td>0.150740</td>\n","      <td>0.203083</td>\n","      <td>[[2382, 248], [631, 112]]</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.285700</td>\n","      <td>0.660487</td>\n","      <td>0.741476</td>\n","      <td>0.318310</td>\n","      <td>0.152086</td>\n","      <td>0.205829</td>\n","      <td>[[2388, 242], [630, 113]]</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.328000</td>\n","      <td>0.686385</td>\n","      <td>0.713905</td>\n","      <td>0.307958</td>\n","      <td>0.239569</td>\n","      <td>0.269493</td>\n","      <td>[[2230, 400], [565, 178]]</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.379900</td>\n","      <td>0.693856</td>\n","      <td>0.730803</td>\n","      <td>0.282322</td>\n","      <td>0.144011</td>\n","      <td>0.190731</td>\n","      <td>[[2358, 272], [636, 107]]</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.460700</td>\n","      <td>0.702786</td>\n","      <td>0.750074</td>\n","      <td>0.334437</td>\n","      <td>0.135935</td>\n","      <td>0.193301</td>\n","      <td>[[2429, 201], [642, 101]]</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.504400</td>\n","      <td>0.720709</td>\n","      <td>0.749185</td>\n","      <td>0.325424</td>\n","      <td>0.129206</td>\n","      <td>0.184971</td>\n","      <td>[[2431, 199], [647, 96]]</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.536100</td>\n","      <td>0.788143</td>\n","      <td>0.726653</td>\n","      <td>0.305011</td>\n","      <td>0.188425</td>\n","      <td>0.232945</td>\n","      <td>[[2311, 319], [603, 140]]</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.397400</td>\n","      <td>0.771382</td>\n","      <td>0.733472</td>\n","      <td>0.302030</td>\n","      <td>0.160162</td>\n","      <td>0.209323</td>\n","      <td>[[2355, 275], [624, 119]]</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.449800</td>\n","      <td>0.772535</td>\n","      <td>0.722799</td>\n","      <td>0.293991</td>\n","      <td>0.184388</td>\n","      <td>0.226634</td>\n","      <td>[[2301, 329], [606, 137]]</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.233600</td>\n","      <td>0.806506</td>\n","      <td>0.737919</td>\n","      <td>0.308943</td>\n","      <td>0.153432</td>\n","      <td>0.205036</td>\n","      <td>[[2375, 255], [629, 114]]</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.160900</td>\n","      <td>0.820490</td>\n","      <td>0.733472</td>\n","      <td>0.303030</td>\n","      <td>0.161507</td>\n","      <td>0.210711</td>\n","      <td>[[2354, 276], [623, 120]]</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.167900</td>\n","      <td>0.831165</td>\n","      <td>0.731100</td>\n","      <td>0.300971</td>\n","      <td>0.166891</td>\n","      <td>0.214719</td>\n","      <td>[[2342, 288], [619, 124]]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","‚úÖ Training completed!\n","üìä Training Loss: 0.4529\n","‚è±Ô∏è Training Time: 1417.84 seconds\n","\n","üìà Evaluating on test set...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='422' max='422' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [422/422 00:06]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","üìä EVALUATION RESULTS\n","================================================================================\n","‚úÖ Accuracy:  0.7139\n","‚úÖ Precision: 0.3080\n","‚úÖ Recall:    0.2396\n","‚úÖ F1 Score:  0.2695\n","\n","üéØ Confusion Matrix:\n","   [[2230, 400], [565, 178]]\n","================================================================================\n","\n","üíæ Saving fine-tuned model...\n","‚úÖ Model saved to: ./tinybert_neda_eda_classifier\n","\n","üß™ Testing predictions on sample data...\n","\n","================================================================================\n","üîÆ SAMPLE PREDICTIONS\n","================================================================================\n","\n","üìù Input: Age:36.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation motor weakn...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.9300)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:34.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation motor weakn...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: EDA (Confidence: 0.8573)\n","‚ùå INCORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:48.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation motor weakn...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.9253)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:38.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation sensory, mo...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.8507)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","üìù Input: Age:53.  Gender:female.  Diagnosis:spms. Converted to SPMS.  OCBs in CSF:positive. IgG index in CSF:...\n","‚úÖ True Label: NEDA\n","üîÆ Predicted: NEDA (Confidence: 0.9194)\n","‚úÖ CORRECT\n","--------------------------------------------------------------------------------\n","\n","ü§ó Would you like to push the model to HuggingFace Hub? (y/n)\n","n\n","\n","üíæ Would you like to download the trained model? (y/n)\n","n\n","\n","================================================================================\n","üéâ ALL DONE!\n","================================================================================\n","‚úÖ Model training completed successfully!\n","‚úÖ Model evaluated on test set\n","‚úÖ Model saved locally\n","\n","üìå Next steps:\n","   1. Review the evaluation metrics above\n","   2. Test the model with your own inputs\n","   3. Fine-tune hyperparameters if needed\n","   4. Deploy the model for inference\n","================================================================================\n"]}],"source":["\"\"\"\n","TinyBERT Fine-tuning for NEDA/EDA Classification\n","Medical text classification using Hugging Face Transformers\n","\"\"\"\n","\n","# ============================================================================\n","# STEP 1: Install Required Libraries\n","# ============================================================================\n","print(\"üì¶ Installing required libraries...\")\n","!pip install -q transformers datasets accelerate openpyxl scikit-learn huggingface_hub\n","\n","# ============================================================================\n","# STEP 2: Import Libraries\n","# ============================================================================\n","print(\"üìö Importing libraries...\")\n","import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","from google.colab import files, userdata\n","from transformers import (\n","    BertTokenizerFast,\n","    BertForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding\n",")\n","from datasets import Dataset\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"‚úÖ All libraries imported successfully!\")\n","print(f\"üî• PyTorch version: {torch.__version__}\")\n","print(f\"ü§ó Transformers library loaded\")\n","print(f\"üíª CUDA available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n","\n","# ============================================================================\n","# STEP 3: Get HuggingFace Token from Colab Secrets (optional)\n","# ============================================================================\n","print(\"\\nüîë Retrieving HuggingFace token from secrets...\")\n","try:\n","    from huggingface_hub import login\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","    if HF_TOKEN:\n","        login(token=HF_TOKEN)\n","        print(\"‚úÖ Logged in to HuggingFace Hub!\")\n","    else:\n","        print(\"‚ÑπÔ∏è No HF_TOKEN found in Colab secrets (that's okay).\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Warning: Could not retrieve HF_TOKEN from secrets: {e}\")\n","    HF_TOKEN = None\n","\n","# ============================================================================\n","# STEP 4: Upload Excel Files\n","# ============================================================================\n","print(\"\\nüìÅ Please upload your training Excel file...\")\n","train_uploaded = files.upload()\n","train_filename = list(train_uploaded.keys())[0]\n","print(f\"‚úÖ Training file uploaded: {train_filename}\")\n","\n","print(\"\\nüìÅ Please upload your test Excel file...\")\n","test_uploaded = files.upload()\n","test_filename = list(test_uploaded.keys())[0]\n","print(f\"‚úÖ Test file uploaded: {test_filename}\")\n","\n","# ============================================================================\n","# STEP 5: Load and Prepare Data\n","# ============================================================================\n","print(\"\\nüìä Loading data from Excel files...\")\n","train_df = pd.read_excel(train_filename)\n","test_df = pd.read_excel(test_filename)\n","\n","print(f\"‚úÖ Training data shape: {train_df.shape}\")\n","print(f\"‚úÖ Test data shape: {test_df.shape}\")\n","print(f\"\\nüìã Training data columns: {train_df.columns.tolist()}\")\n","print(f\"\\nüîç First few rows of training data:\")\n","print(train_df.head())\n","\n","# Expecting columns: 'input' (text) and 'output' (string containing 'NEDA' or 'EDA')\n","\n","# ============================================================================\n","# STEP 6: Process Labels - Extract NEDA/EDA from Output\n","# ============================================================================\n","print(\"\\nüè∑Ô∏è Processing labels...\")\n","\n","def extract_label(output_text):\n","    \"\"\"Extract NEDA or EDA from output text\"\"\"\n","    output_text = str(output_text).upper()\n","    if 'NEDA' in output_text:\n","        return 'NEDA'\n","    elif 'EDA' in output_text:\n","        return 'EDA'\n","    else:\n","        return None\n","\n","# Apply label extraction\n","train_df['label_text'] = train_df['output'].apply(extract_label)\n","test_df['label_text'] = test_df['output'].apply(extract_label)\n","\n","# Remove rows with None labels\n","train_df = train_df[train_df['label_text'].notna()].reset_index(drop=True)\n","test_df = test_df[test_df['label_text'].notna()].reset_index(drop=True)\n","\n","# Create label mapping\n","label2id = {'NEDA': 0, 'EDA': 1}\n","id2label = {0: 'NEDA', 1: 'EDA'}\n","\n","# Convert to numeric labels\n","train_df['label'] = train_df['label_text'].map(label2id)\n","test_df['label'] = test_df['label_text'].map(label2id)\n","\n","print(f\"‚úÖ Labels extracted successfully!\")\n","print(f\"üìä Training set after label extraction: {len(train_df)} samples\")\n","print(f\"üìä Test set after label extraction: {len(test_df)} samples\")\n","print(f\"\\nüìà Training label distribution:\")\n","print(train_df['label_text'].value_counts())\n","print(f\"\\nüìà Test label distribution:\")\n","print(test_df['label_text'].value_counts())\n","\n","# ============================================================================\n","# STEP 7: Initialize Tokenizer and Model (TinyBERT)\n","# ============================================================================\n","print(\"\\nü§ñ Loading TinyBERT model and tokenizer...\")\n","\n","# Common TinyBERT options (pick one):\n","#   \"huawei-noah/TinyBERT_General_4L_312D\"  -> very small (fastest)\n","#   \"huawei-noah/TinyBERT_General_6L_768D\"  -> bigger (better quality)\n","MODEL_NAME = \"huawei-noah/TinyBERT_General_6L_768D\"\n","\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id\n",")\n","\n","# Count parameters\n","try:\n","    n_params = model.num_parameters()\n","except:\n","    n_params = sum(p.numel() for p in model.parameters())\n","\n","print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n","print(f\"‚úÖ Number of parameters: {n_params:,}\")\n","\n","# ============================================================================\n","# STEP 8: Tokenize Data\n","# ============================================================================\n","print(\"\\nüî§ Tokenizing data...\")\n","\n","def tokenize_function(examples):\n","    \"\"\"Tokenize input texts\"\"\"\n","    return tokenizer(\n","        examples['input'],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=256  # TinyBERT-friendly; change to 512 if needed\n","    )\n","\n","# Convert to Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(train_df[['input', 'label']])\n","test_dataset = Dataset.from_pandas(test_df[['input', 'label']])\n","\n","# Tokenize datasets\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","test_dataset = test_dataset.map(tokenize_function, batched=True)\n","\n","# Set format for PyTorch\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","print(f\"‚úÖ Training dataset: {len(train_dataset)} samples\")\n","print(f\"‚úÖ Test dataset: {len(test_dataset)} samples\")\n","\n","# ============================================================================\n","# STEP 9: Define Evaluation Metrics\n","# ============================================================================\n","print(\"\\nüìä Setting up evaluation metrics...\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"Compute metrics for evaluation\"\"\"\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels, predictions, average='binary', zero_division=0\n","    )\n","    cm = confusion_matrix(labels, predictions)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","print(\"‚úÖ Evaluation metrics configured!\")\n","\n","# ============================================================================\n","# STEP 10: Setup Training Arguments\n","# ============================================================================\n","print(\"\\n‚öôÔ∏è Configuring training arguments...\")\n","\n","seed = 42\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',  # Disable wandb/tensorboard\n","    push_to_hub=False,  # Set to True if you want to push to Hub\n","    optim='adamw_torch',  # Use AdamW optimizer (Adam with weight decay)\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n",")\n","\n","print(\"‚úÖ Training arguments configured!\")\n","print(f\"   - Learning rate: {training_args.learning_rate}\")\n","print(f\"   - Batch size: {training_args.per_device_train_batch_size}\")\n","print(f\"   - Epochs: {training_args.num_train_epochs}\")\n","print(f\"   - Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n","\n","# ============================================================================\n","# STEP 11: Initialize Trainer\n","# ============================================================================\n","print(\"\\nüéØ Initializing Trainer...\")\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","print(\"‚úÖ Trainer initialized successfully!\")\n","\n","# ============================================================================\n","# STEP 12: Train the Model\n","# ============================================================================\n","print(\"\\nüöÄ Starting training...\")\n","print(\"=\" * 80)\n","\n","train_result = trainer.train()\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"‚úÖ Training completed!\")\n","print(f\"üìä Training Loss: {train_result.training_loss:.4f}\" if hasattr(train_result, 'training_loss') else \"üìä Training done.\")\n","if 'train_runtime' in train_result.metrics:\n","    print(f\"‚è±Ô∏è Training Time: {train_result.metrics['train_runtime']:.2f} seconds\")\n","\n","# ============================================================================\n","# STEP 13: Evaluate on Test Set\n","# ============================================================================\n","print(\"\\nüìà Evaluating on test set...\")\n","\n","eval_results = trainer.evaluate()\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"üìä EVALUATION RESULTS\")\n","print(\"=\" * 80)\n","print(f\"‚úÖ Accuracy:  {eval_results.get('eval_accuracy', 0):.4f}\")\n","print(f\"‚úÖ Precision: {eval_results.get('eval_precision', 0):.4f}\")\n","print(f\"‚úÖ Recall:    {eval_results.get('eval_recall', 0):.4f}\")\n","print(f\"‚úÖ F1 Score:  {eval_results.get('eval_f1', 0):.4f}\")\n","print(f\"\\nüéØ Confusion Matrix:\")\n","print(f\"   {eval_results.get('eval_confusion_matrix', [])}\")\n","print(\"=\" * 80)\n","\n","# ============================================================================\n","# STEP 14: Save Model\n","# ============================================================================\n","print(\"\\nüíæ Saving fine-tuned model...\")\n","\n","model_save_path = './tinybert_neda_eda_classifier'\n","trainer.save_model(model_save_path)\n","tokenizer.save_pretrained(model_save_path)\n","\n","print(f\"‚úÖ Model saved to: {model_save_path}\")\n","\n","# ============================================================================\n","# STEP 15: Test Predictions on Sample Data\n","# ============================================================================\n","print(\"\\nüß™ Testing predictions on sample data...\")\n","\n","# Get some test samples\n","test_samples = test_df.sample(min(5, len(test_df)), random_state=seed)\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"üîÆ SAMPLE PREDICTIONS\")\n","print(\"=\" * 80)\n","\n","model.eval()\n","for _, row in test_samples.iterrows():\n","    inputs = tokenizer(\n","        row['input'],\n","        return_tensors='pt',\n","        truncation=True,\n","        max_length=256\n","    ).to(model.device)\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","        pred_id = torch.argmax(probs, dim=-1).item()\n","\n","    predicted_label = id2label[pred_id]\n","    true_label = row['label_text']\n","    confidence = probs[0][pred_id].item()\n","\n","    print(f\"\\nüìù Input: {row['input'][:100]}...\")\n","    print(f\"‚úÖ True Label: {true_label}\")\n","    print(f\"üîÆ Predicted: {predicted_label} (Confidence: {confidence:.4f})\")\n","    print(f\"{'‚úÖ CORRECT' if predicted_label == true_label else '‚ùå INCORRECT'}\")\n","    print(\"-\" * 80)\n","\n","# ============================================================================\n","# STEP 16: Optional - Push to HuggingFace Hub\n","# ============================================================================\n","if HF_TOKEN:\n","    print(\"\\nü§ó Would you like to push the model to HuggingFace Hub? (y/n)\")\n","    push_choice = input().lower().strip()\n","\n","    if push_choice == 'y':\n","        print(\"üìù Enter your HuggingFace username:\")\n","        username = input().strip()\n","        print(\"üìù Enter model name (e.g., tinybert-neda-eda-classifier):\")\n","        model_name = input().strip()\n","\n","        repo_name = f\"{username}/{model_name}\"\n","        try:\n","            print(f\"\\n‚¨ÜÔ∏è Pushing model to {repo_name}...\")\n","            trainer.push_to_hub(repo_name)\n","            print(f\"‚úÖ Model successfully pushed to https://huggingface.co/{repo_name}\")\n","        except Exception as e:\n","            print(f\"‚ùå Error pushing to Hub: {e}\")\n","else:\n","    print(\"\\n‚ö†Ô∏è Skipping HuggingFace Hub push (no token available)\")\n","\n","# ============================================================================\n","# STEP 17: Download Trained Model\n","# ============================================================================\n","print(\"\\nüíæ Would you like to download the trained model? (y/n)\")\n","download_choice = input().lower().strip()\n","\n","if download_choice == 'y':\n","    print(\"\\nüì¶ Creating zip file...\")\n","    !zip -r tinybert_neda_eda_classifier.zip {model_save_path}\n","    print(\"‚¨áÔ∏è Downloading model...\")\n","    files.download('tinybert_neda_eda_classifier.zip')\n","    print(\"‚úÖ Model downloaded successfully!\")\n","\n","print(\"\\n\" + \"=\" * 80)\n","print(\"üéâ ALL DONE!\")\n","print(\"=\" * 80)\n","print(\"‚úÖ Model training completed successfully!\")\n","print(\"‚úÖ Model evaluated on test set\")\n","print(\"‚úÖ Model saved locally\")\n","print(\"\\nüìå Next steps:\")\n","print(\"   1. Review the evaluation metrics above\")\n","print(\"   2. Test the model with your own inputs\")\n","print(\"   3. Fine-tune hyperparameters if needed\")\n","print(\"   4. Deploy the model for inference\")\n","print(\"=\" * 80)\n"]},{"cell_type":"markdown","source":["##funnel transformer"],"metadata":{"id":"tRQLTvjf_QNW"}},{"cell_type":"code","source":["\n","# ============================================================================\n","# STEP 1: Install Required Libraries\n","# ============================================================================\n","print(\"üì¶ Installing required libraries...\")\n","!pip install -q transformers datasets openpyxl scikit-learn huggingface_hub accelerate\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sU0wts7IVV3","executionInfo":{"status":"ok","timestamp":1761745243322,"user_tz":-120,"elapsed":6737,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"3f38a096-cde7-43f0-d485-f4179ec234d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing required libraries...\n"]}]},{"cell_type":"code","source":["\n","# ============================================================================\n","# STEP 2: Import Libraries\n","# ============================================================================\n","print(\"\\nüìö Importing libraries...\")\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from google.colab import files, userdata\n","from transformers import (\n","    FunnelTokenizer,\n","    FunnelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer\n",")\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","from sklearn.utils.class_weight import compute_class_weight\n","from huggingface_hub import login\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"‚úÖ Libraries imported successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sesASwuIIX12","executionInfo":{"status":"ok","timestamp":1761745263934,"user_tz":-120,"elapsed":20608,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"a621693f-6f4a-42da-9d5d-35dd693410b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìö Importing libraries...\n","‚úÖ Libraries imported successfully!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 3: Login to Hugging Face (Optional but Recommended)\n","# ============================================================================\n","print(\"\\nüîê Logging into Hugging Face...\")\n","\n","try:\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","    login(token=HF_TOKEN)\n","    print(\"‚úÖ Successfully logged into Hugging Face!\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not login to HF: {e}\")\n","    print(\"Continuing without HF login...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BQMHHWaVIZTj","executionInfo":{"status":"ok","timestamp":1761745264857,"user_tz":-120,"elapsed":925,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"5a6aeea2-2da6-416a-9bc4-c6c25b1d4dc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîê Logging into Hugging Face...\n","‚úÖ Successfully logged into Hugging Face!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 4: Upload Training and Testing Files\n","# ============================================================================\n","print(\"\\nüìÅ Please upload your Excel files...\")\n","print(\"Expected format: 'input' column (text) and 'output' column (labels)\")\n","\n","# Check if files already exist\n","if not os.path.exists('/content/train.xlsx'):\n","    print(\"\\nüì§ Upload TRAINING file (train.xlsx):\")\n","    train_uploaded = files.upload()\n","else:\n","    print(\"‚úÖ Training file already exists!\")\n","\n","if not os.path.exists('/content/test.xlsx'):\n","    print(\"\\nüì§ Upload TESTING file (test.xlsx):\")\n","    test_uploaded = files.upload()\n","else:\n","    print(\"‚úÖ Testing file already exists!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4AXqT71GNGa","executionInfo":{"status":"ok","timestamp":1761745310291,"user_tz":-120,"elapsed":45430,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"26fbbada-1e0b-43d3-d65d-7e1b38d3c54d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìÅ Please upload your Excel files...\n","Expected format: 'input' column (text) and 'output' column (labels)\n","\n","üì§ Upload TRAINING file (train.xlsx):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-ca3e74a9-bb52-4fc0-8c24-051d5965d561\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ca3e74a9-bb52-4fc0-8c24-051d5965d561\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train.xlsx to train.xlsx\n","\n","üì§ Upload TESTING file (test.xlsx):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-301f52c1-4833-45b4-8d9f-02e4bfc6d859\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-301f52c1-4833-45b4-8d9f-02e4bfc6d859\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test.xlsx to test.xlsx\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 5: Load Data from Excel Files\n","# ============================================================================\n","print(\"\\nüìä Loading data from Excel files...\")\n","\n","train_df = pd.read_excel('/content/train.xlsx')\n","test_df = pd.read_excel('/content/test.xlsx')\n","\n","print(f\"‚úÖ Training data loaded: {train_df.shape[0]} rows, {train_df.shape[1]} columns\")\n","print(f\"‚úÖ Testing data loaded: {test_df.shape[0]} rows, {test_df.shape[1]} columns\")\n","\n","# Preview data\n","print(\"\\nüìã Training data preview:\")\n","print(train_df.head())\n","print(\"\\nüìã Testing data preview:\")\n","print(test_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMOpdiljI0aA","executionInfo":{"status":"ok","timestamp":1761745311254,"user_tz":-120,"elapsed":956,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"65337d9d-b040-4ddc-cf6e-2b170b5d20bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä Loading data from Excel files...\n","‚úÖ Training data loaded: 6472 rows, 3 columns\n","‚úÖ Testing data loaded: 3373 rows, 3 columns\n","\n","üìã Training data preview:\n","   MSC research database ID  \\\n","0                         1   \n","1                         1   \n","2                         1   \n","3                         1   \n","4                         1   \n","\n","                                               input  \\\n","0  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","1  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","2  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","3  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","4  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","\n","                                        output  \n","0  After 7 months the patient will be in NEDA.  \n","1   After 7 months the patient will be in EDA.  \n","2   After 0 months the patient will be in EDA.  \n","3   After 4 months the patient will be in EDA.  \n","4  After 6 months the patient will be in NEDA.  \n","\n","üìã Testing data preview:\n","   MSC research database ID  \\\n","0                         7   \n","1                         7   \n","2                         7   \n","3                         7   \n","4                         7   \n","\n","                                               input  \\\n","0  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","1  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","2  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","3  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","4  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","\n","                                        output  \n","0  After 9 months the patient will be in NEDA.  \n","1  After 6 months the patient will be in NEDA.  \n","2  After 5 months the patient will be in NEDA.  \n","3  After 6 months the patient will be in NEDA.  \n","4  After 6 months the patient will be in NEDA.  \n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 6: Process Labels\n","# ============================================================================\n","print(\"\\nüè∑Ô∏è Processing labels...\")\n","\n","def extract_label(output_text):\n","    \"\"\"Extract NEDA or EDA from output text\"\"\"\n","    output_text = str(output_text).upper()\n","    if 'NEDA' in output_text:\n","        return 'NEDA'\n","    elif 'EDA' in output_text:\n","        return 'EDA'\n","    else:\n","        return None\n","\n","# Apply label extraction\n","train_df['label_text'] = train_df['output'].apply(extract_label)\n","test_df['label_text'] = test_df['output'].apply(extract_label)\n","\n","# Remove rows with None labels\n","train_df = train_df[train_df['label_text'].notna()].reset_index(drop=True)\n","test_df = test_df[test_df['label_text'].notna()].reset_index(drop=True)\n","\n","# Create label mapping\n","label2id = {'NEDA': 0, 'EDA': 1}\n","id2label = {0: 'NEDA', 1: 'EDA'}\n","\n","# Convert to numeric labels\n","train_df['label'] = train_df['label_text'].map(label2id)\n","test_df['label'] = test_df['label_text'].map(label2id)\n","\n","print(f\"‚úÖ Labels extracted successfully!\")\n","print(f\"\\nüìä Training set: {len(train_df)} samples\")\n","print(f\"   - NEDA: {sum(train_df['label']==0)} ({sum(train_df['label']==0)/len(train_df)*100:.1f}%)\")\n","print(f\"   - EDA:  {sum(train_df['label']==1)} ({sum(train_df['label']==1)/len(train_df)*100:.1f}%)\")\n","print(f\"\\nüìä Testing set: {len(test_df)} samples\")\n","print(f\"   - NEDA: {sum(test_df['label']==0)} ({sum(test_df['label']==0)/len(test_df)*100:.1f}%)\")\n","print(f\"   - EDA:  {sum(test_df['label']==1)} ({sum(test_df['label']==1)/len(test_df)*100:.1f}%)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOnegi2EIy2I","executionInfo":{"status":"ok","timestamp":1761745311280,"user_tz":-120,"elapsed":23,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"a1f58aa7-fb2a-4e3e-9069-7d5eebf8b228"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üè∑Ô∏è Processing labels...\n","‚úÖ Labels extracted successfully!\n","\n","üìä Training set: 6472 samples\n","   - NEDA: 4989 (77.1%)\n","   - EDA:  1483 (22.9%)\n","\n","üìä Testing set: 3373 samples\n","   - NEDA: 2630 (78.0%)\n","   - EDA:  743 (22.0%)\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 7: Split Training Data into Train and Validation Sets\n","# ============================================================================\n","print(\"\\n‚úÇÔ∏è Splitting training data into train and validation sets...\")\n","\n","train_data, val_data = train_test_split(\n","    train_df,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=train_df['label']  # Maintain class balance\n",")\n","\n","print(f\"‚úÖ Final split:\")\n","print(f\"   - Training:   {len(train_data)} samples\")\n","print(f\"   - Validation: {len(val_data)} samples\")\n","print(f\"   - Testing:    {len(test_df)} samples\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZEHYoF-IwuM","executionInfo":{"status":"ok","timestamp":1761745311297,"user_tz":-120,"elapsed":15,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"2845aedc-1a36-4ed6-96b3-15ab621c4fd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚úÇÔ∏è Splitting training data into train and validation sets...\n","‚úÖ Final split:\n","   - Training:   5177 samples\n","   - Validation: 1295 samples\n","   - Testing:    3373 samples\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 8: Compute Class Weights for Imbalanced Data\n","# ============================================================================\n","print(\"\\n‚öñÔ∏è Computing class weights to handle class imbalance...\")\n","\n","train_labels = train_data['label'].values\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(train_labels),\n","    y=train_labels\n",")\n","class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n","\n","print(f\"‚úÖ Class weights computed:\")\n","print(f\"   - NEDA (class 0): {class_weights[0]:.4f}\")\n","print(f\"   - EDA  (class 1): {class_weights[1]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRj-vJ61Iu84","executionInfo":{"status":"ok","timestamp":1761745311321,"user_tz":-120,"elapsed":22,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"5324059c-4a0c-410b-ab3e-004cdc6cb434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚öñÔ∏è Computing class weights to handle class imbalance...\n","‚úÖ Class weights computed:\n","   - NEDA (class 0): 0.6486\n","   - EDA  (class 1): 2.1825\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 9: Initialize Tokenizer and Model\n","# ============================================================================\n","print(\"\\nü§ñ Loading Funnel Transformer model and tokenizer...\")\n","\n","MODEL_NAME = \"funnel-transformer/medium\"\n","\n","tokenizer = FunnelTokenizer.from_pretrained(MODEL_NAME)\n","model = FunnelForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id\n",")\n","\n","# Count parameters\n","n_params = sum(p.numel() for p in model.parameters())\n","print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n","print(f\"‚úÖ Number of parameters: {n_params:,}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["0b071b77f099496380f5c052dadb8e50","e6d3fd882ee74fbd8ba0777ca3c453fa","1b8f007f10e6461e9551763ace551e9a","4bb3256e2dd244d2867597f664bf2ec9","e984294c3551479c95a725363b7dbdcd","213104e6629b47698f228fa604954923","2cc58a34ddf24339920ca04d0a44090b","9df5c2491ea04638bb588f3ac06eb77f","e76bd766b28c40f893a90c227dadc0f5","2053549cd6664ea380839419e725d930","b59bf15db4f745bb94e0b4617bff2555","c80ad1c844644c92a75e8950b7072429","b070bf3ea4124399a726dee1ff13e7be","9fd469420e1741649ce8ddbb59dc2107","13fd5ecdd3c2403ba5655f2b16096e40","db7f5cf204324ae7aa0f0c00d6a0a35e","0c5592bf59c546dab94c685cee05da26","f24832e9232f4be381b204ea0f851555","bfa0dd5128534d3ab335d27c7dfdb4ac","041d27281c93475a9f9628b8ce7e0714","c81faaead6f5458fa9497dac0496b3f6","4c6e2731685f4518b72d66b7eec2817f","c26af6eb2667469183105f1a79237c2d","bb03dbb3cdc94ccaa6883f1e4b98c3ff","c2400bf5731647dc9dae18d2bd6995f1","f3e9e4ab86774f5790925ef378518255","d719b8b630ea42e38b992221930e264b","99c5266e81af4eb19a85e33a85ef1e23","0a55151d57534a1b9a81ce419d109c3e","34b50ef6145a4f28ab77f6b62db0ff0b","94fb6b75b5004d649c4f8c6c7a73dbb6","350aaa30492a4029a4380cff2d5c89a5","f2731e9b76044dc98ef75c7d675fba88","dada0322fb704b03b1a661ee0857543f","84309166c1d64bc28c3f1a9ea6631291","8d16d8e6f625460ab6eff9d6d72dd29f","83ee1101b52f4e3482edb2f7b5361fcd","07d145452418413fb02dbfaf769e03ba","36c2db40da6643cb932f49008d3ddaaf","53bdb3b2609444ae959e234a81e21ef0","ad2a5b794a3341a8aa3751a0ddda617c","b64f2ba5b88e42f1965ca2cf2d0d7cd0","c4e9d1ae03ad424b95dbb6dc283b798d","2cda36319f36450e84dd0c21d13da4ec","05ea978a36ee4bcd9e90fbcb28afe5a6","422ec6f158f142039679bc1b098246fa","bccea44c98db47cba0615c081affe4bf","7e05ec43567445db8788cbbfafa809dd","7009c7a4fb064742ae968535a2a45a7d","5cb8cbb8bdcc42bfabc5f00ce3e97100","8bed9841eb51432cad24f0a5a4247283","4d9df9c7a6154ad8b0c77790b7d75391","d2bb72a00dd8408b9a92dea4b4ba926e","24615d51363341f081f007c65ea4d503","324cc7d1d03e4973ae7b9cc2a09922aa","83aad3d747554e72a61930bd4792d539","40785c5da62a46fe95b0bd8476fd05c3","83c0e3e5290e4357821f49bf6fe34d3e","b4561d718d834ef0b9f67128a5374aba","1162e3e16b4640a2bc00ebebea725ea5","3929b3be15954ed7a9c53d0c09087967","0c602f0850ae47febbde3c8fd217e753","70731d7698ca4ad7afd1c036c4c47cd1","9d8e5a243223480695fcc8bdd3f29c9d","58dbd01df3eb43059f19cef0c788a463","3136a41bd1364f0c8d4424216f2dfd46"]},"id":"ZeaAFw--Isk0","executionInfo":{"status":"ok","timestamp":1761745328673,"user_tz":-120,"elapsed":17350,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"cca96adc-1550-4f09-b1fb-178090625025"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ü§ñ Loading Funnel Transformer model and tokenizer...\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b071b77f099496380f5c052dadb8e50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c80ad1c844644c92a75e8950b7072429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/153 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c26af6eb2667469183105f1a79237c2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dada0322fb704b03b1a661ee0857543f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ea978a36ee4bcd9e90fbcb28afe5a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/524M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83aad3d747554e72a61930bd4792d539"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of FunnelForSequenceClassification were not initialized from the model checkpoint at funnel-transformer/medium and are newly initialized: ['classifier.linear_hidden.bias', 'classifier.linear_hidden.weight', 'classifier.linear_out.bias', 'classifier.linear_out.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Model loaded: funnel-transformer/medium\n","‚úÖ Number of parameters: 116,203,778\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 10: Tokenize Data\n","# ============================================================================\n","print(\"\\nüî§ Tokenizing data...\")\n","\n","def tokenize_function(examples):\n","    \"\"\"Tokenize input texts\"\"\"\n","    return tokenizer(\n","        examples['input'],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=256\n","    )\n","\n","# Convert to Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(train_data[['input', 'label']])\n","val_dataset = Dataset.from_pandas(val_data[['input', 'label']])\n","test_dataset = Dataset.from_pandas(test_df[['input', 'label']])\n","\n","# Tokenize datasets\n","print(\"   Tokenizing training set...\")\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","print(\"   Tokenizing validation set...\")\n","val_dataset = val_dataset.map(tokenize_function, batched=True)\n","print(\"   Tokenizing test set...\")\n","test_dataset = test_dataset.map(tokenize_function, batched=True)\n","\n","# Set format for PyTorch\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","print(f\"‚úÖ Tokenization complete!\")\n","print(f\"   - Training dataset:   {len(train_dataset)} samples\")\n","print(f\"   - Validation dataset: {len(val_dataset)} samples\")\n","print(f\"   - Test dataset:       {len(test_dataset)} samples\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["aa6528fe769d42eaa03bc4c7140d80a7","e2f8114d15de4aa0a0ece6f1875e8d7a","708fb4079a464708a576ae1a458276e2","42b17a8c263c491a8a68821e94fb9003","0be0a6dc0987401fb25a536be3a84a68","bd4a23b6be604e919f80c571bd6797f2","a625b3bb98734308aa36823b5b9a862e","cffb9c3c9ba3442aa683de6400829e20","e194b5caa67a4b42b8ca05cd85254189","18c75d7b37914618b16f5e75c5043e6c","e083dfe9f1ad4c23820495aa758f3ec1","4f8b4b54f5454ff48a156213d00c94d2","f0d6291933444ffc94bbea2d8f50005b","57802854b82b4f0b98259925c8a7bc92","ff52bce181464320b5933d802960f7f9","22f9ad0b772f44a59d95afcf2bee8eee","8343c8cde5984f50a7bcaecfea107871","ae6ced32f8f44576a6af1df4cfeb412a","7aec6e219cad43da8304b35a20f96548","8a29759238a9479d85e13b0a6cc1b075","d3c78cbde84b4bf999e5dd161f27ea35","e6f6f3b8cfe84b31b27387b1cfb1ef11","5c38ae808dd34a688c96cfb8e8ae0849","9139d5c68c184434bd845f9973452930","87847c0765ef4f639dddcb65ad89ff28","9aa9e300c6f5425ca172e318042ee3ee","89100890014a4661a4b355f23e6b9745","c337b187b4e74ce88bd9a5b72c4d86d4","e066aa232c594f13b8f1e975ad07864d","426cf4c49b32452398e05c0334fa9920","0b3fbbf6b57b4be29693cbe0ef4a529e","c7a2a9d596b84419a4311c08173df51b","6b7fb887bf6f48f2bde3de5799bc8768","a38b87b5fbb543a2a5386f8bb1416c04","fa694ff800a6490782da3a987e6d8b46","c9cf8fdecc2e4376b5d8eaa56308e164","7267ce7a35a44de3b8e8db4bcf010255","c0a65e099e6f4264b333f0d5f0ea0052","ff68c3e019ae47a0bb633420d9fb3c10","c4334c12734a4fe99489aedeb40a9579","4a612e53dd3c4d2aaaef409c1c922b77","934dee3b81a3483e93572a33de1e4149","9cc874aab13e4c12be46f4aa120ecd52","7bf2b982fb05461594ada1dd65040f79"]},"id":"InYRagQzIqrO","executionInfo":{"status":"ok","timestamp":1761745363289,"user_tz":-120,"elapsed":34612,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"99b17de3-d2c8-4663-f8c2-8cbdc22ee579"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üî§ Tokenizing data...\n","   Tokenizing training set...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5177 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa6528fe769d42eaa03bc4c7140d80a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/524M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f8b4b54f5454ff48a156213d00c94d2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   Tokenizing validation set...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1295 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c38ae808dd34a688c96cfb8e8ae0849"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   Tokenizing test set...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a38b87b5fbb543a2a5386f8bb1416c04"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Tokenization complete!\n","   - Training dataset:   5177 samples\n","   - Validation dataset: 1295 samples\n","   - Test dataset:       3373 samples\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 11: Define Evaluation Metrics\n","# ============================================================================\n","print(\"\\nüìä Setting up evaluation metrics...\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"Compute metrics for evaluation\"\"\"\n","    logits, labels = eval_pred\n","\n","    # Convert logits to tensor if needed\n","    logits = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits\n","\n","    # Get predictions\n","    predictions = torch.argmax(logits, axis=-1).cpu().numpy()\n","    labels = labels if isinstance(labels, np.ndarray) else labels.cpu().numpy()\n","\n","    # Compute metrics\n","    accuracy = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels, predictions, average='binary', zero_division=0\n","    )\n","    cm = confusion_matrix(labels, predictions)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","print(\"‚úÖ Evaluation metrics configured!\")\n","\n","\n","print(\"‚úÖ Custom trainer class created!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zq-b09agIovh","executionInfo":{"status":"ok","timestamp":1761745363324,"user_tz":-120,"elapsed":32,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"c5d00628-f72c-4c99-9614-782fcc34e73a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä Setting up evaluation metrics...\n","‚úÖ Evaluation metrics configured!\n","‚úÖ Custom trainer class created!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 12: Create Custom Trainer with Weighted Loss\n","# ============================================================================\n","print(\"\\nüéØ Creating custom trainer with weighted loss...\")\n","\n","class WeightedLossTrainer(Trainer):\n","    \"\"\"Custom Trainer with weighted cross-entropy loss\"\"\"\n","\n","    def __init__(self, *args, class_weights=None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.class_weights = class_weights\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","\n","        # Use weighted cross-entropy loss\n","        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","\n","        return (loss, outputs) if return_outputs else loss\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbQBYwSBInLL","executionInfo":{"status":"ok","timestamp":1761745363348,"user_tz":-120,"elapsed":11,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"a7368ab5-3f1b-4feb-9dae-45b1470f8b87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üéØ Creating custom trainer with weighted loss...\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 13: Setup Training Arguments\n","# ============================================================================\n","print(\"\\n‚öôÔ∏è Configuring training arguments...\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    greater_is_better=True,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',\n","    push_to_hub=False,\n","    warmup_ratio=0.2,\n","    lr_scheduler_type='linear',\n","    seed=42,\n","    gradient_accumulation_steps=2,\n","    max_grad_norm=1.0,\n",")\n","\n","print(\"‚úÖ Training arguments configured!\")\n","print(f\"   - Learning rate: {training_args.learning_rate}\")\n","print(f\"   - Batch size: {training_args.per_device_train_batch_size}\")\n","print(f\"   - Epochs: {training_args.num_train_epochs}\")\n","print(f\"   - Warmup ratio: {training_args.warmup_ratio}\")\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bzf1tziIlri","executionInfo":{"status":"ok","timestamp":1761745363473,"user_tz":-120,"elapsed":123,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"15392cbf-63be-4b28-f340-ddb885088388"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚öôÔ∏è Configuring training arguments...\n","‚úÖ Training arguments configured!\n","   - Learning rate: 2e-05\n","   - Batch size: 32\n","   - Epochs: 30\n","   - Warmup ratio: 0.2\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 14: Initialize Trainer\n","# ============================================================================\n","print(\"\\nüéØ Initializing weighted trainer...\")\n","\n","trainer = WeightedLossTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,  # Use validation set during training\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    class_weights=class_weights_tensor,\n",")\n","\n","print(\"‚úÖ Trainer initialized successfully!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8xgzbmuIkTh","executionInfo":{"status":"ok","timestamp":1761745363612,"user_tz":-120,"elapsed":134,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"33f40087-b048-4f25-8ce1-449ff88b89fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üéØ Initializing weighted trainer...\n","‚úÖ Trainer initialized successfully!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 15: Train the Model\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ STARTING TRAINING\")\n","print(\"=\"*70)\n","print(\"\\nThis may take a while. Training progress will be shown below...\")\n","print(\"-\"*70)\n","\n","train_result = trainer.train()\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ TRAINING COMPLETED!\")\n","print(\"=\"*70)\n","print(f\"üìä Final Training Loss: {train_result.training_loss:.4f}\")\n","print(f\"‚è±Ô∏è Training Time: {train_result.metrics['train_runtime']:.2f} seconds\")\n","print(f\"‚ö° Training Speed: {train_result.metrics['train_samples_per_second']:.2f} samples/sec\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Og4nuh0dIi-A","executionInfo":{"status":"ok","timestamp":1761747465195,"user_tz":-120,"elapsed":2101566,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"32dc12ff-3391-403f-c8ce-ff53383e01a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 97, 'bos_token_id': 96, 'pad_token_id': 0}.\n"]},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üöÄ STARTING TRAINING\n","======================================================================\n","\n","This may take a while. Training progress will be shown below...\n","----------------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2430/2430 34:59, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.693700</td>\n","      <td>0.689956</td>\n","      <td>0.611583</td>\n","      <td>0.288934</td>\n","      <td>0.474747</td>\n","      <td>0.359236</td>\n","      <td>[[651, 347], [156, 141]]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.683600</td>\n","      <td>0.677108</td>\n","      <td>0.499614</td>\n","      <td>0.271186</td>\n","      <td>0.700337</td>\n","      <td>0.390977</td>\n","      <td>[[439, 559], [89, 208]]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.678500</td>\n","      <td>0.664724</td>\n","      <td>0.542085</td>\n","      <td>0.293296</td>\n","      <td>0.707071</td>\n","      <td>0.414610</td>\n","      <td>[[492, 506], [87, 210]]</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.647000</td>\n","      <td>0.672585</td>\n","      <td>0.665637</td>\n","      <td>0.334146</td>\n","      <td>0.461279</td>\n","      <td>0.387553</td>\n","      <td>[[725, 273], [160, 137]]</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.665500</td>\n","      <td>0.695137</td>\n","      <td>0.702703</td>\n","      <td>0.360759</td>\n","      <td>0.383838</td>\n","      <td>0.371941</td>\n","      <td>[[796, 202], [183, 114]]</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.683900</td>\n","      <td>0.699404</td>\n","      <td>0.731274</td>\n","      <td>0.411150</td>\n","      <td>0.397306</td>\n","      <td>0.404110</td>\n","      <td>[[829, 169], [179, 118]]</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.691300</td>\n","      <td>0.729864</td>\n","      <td>0.751351</td>\n","      <td>0.420382</td>\n","      <td>0.222222</td>\n","      <td>0.290749</td>\n","      <td>[[907, 91], [231, 66]]</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.637100</td>\n","      <td>0.663823</td>\n","      <td>0.711197</td>\n","      <td>0.368601</td>\n","      <td>0.363636</td>\n","      <td>0.366102</td>\n","      <td>[[813, 185], [189, 108]]</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.634000</td>\n","      <td>0.668686</td>\n","      <td>0.674131</td>\n","      <td>0.359551</td>\n","      <td>0.538721</td>\n","      <td>0.431267</td>\n","      <td>[[713, 285], [137, 160]]</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.614000</td>\n","      <td>0.659359</td>\n","      <td>0.636293</td>\n","      <td>0.333333</td>\n","      <td>0.585859</td>\n","      <td>0.424908</td>\n","      <td>[[650, 348], [123, 174]]</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.577000</td>\n","      <td>0.666547</td>\n","      <td>0.693436</td>\n","      <td>0.371134</td>\n","      <td>0.484848</td>\n","      <td>0.420438</td>\n","      <td>[[754, 244], [153, 144]]</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.615000</td>\n","      <td>0.663324</td>\n","      <td>0.648649</td>\n","      <td>0.340726</td>\n","      <td>0.569024</td>\n","      <td>0.426230</td>\n","      <td>[[671, 327], [128, 169]]</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.624900</td>\n","      <td>0.699733</td>\n","      <td>0.682625</td>\n","      <td>0.353093</td>\n","      <td>0.461279</td>\n","      <td>0.400000</td>\n","      <td>[[747, 251], [160, 137]]</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.573700</td>\n","      <td>0.681380</td>\n","      <td>0.678764</td>\n","      <td>0.353808</td>\n","      <td>0.484848</td>\n","      <td>0.409091</td>\n","      <td>[[735, 263], [153, 144]]</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.544300</td>\n","      <td>0.751237</td>\n","      <td>0.698842</td>\n","      <td>0.367521</td>\n","      <td>0.434343</td>\n","      <td>0.398148</td>\n","      <td>[[776, 222], [168, 129]]</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.559000</td>\n","      <td>0.692852</td>\n","      <td>0.626255</td>\n","      <td>0.329690</td>\n","      <td>0.609428</td>\n","      <td>0.427896</td>\n","      <td>[[630, 368], [116, 181]]</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.510900</td>\n","      <td>0.756375</td>\n","      <td>0.630116</td>\n","      <td>0.328947</td>\n","      <td>0.589226</td>\n","      <td>0.422195</td>\n","      <td>[[641, 357], [122, 175]]</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.480700</td>\n","      <td>0.756122</td>\n","      <td>0.646332</td>\n","      <td>0.332640</td>\n","      <td>0.538721</td>\n","      <td>0.411311</td>\n","      <td>[[677, 321], [137, 160]]</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.487300</td>\n","      <td>0.791588</td>\n","      <td>0.636293</td>\n","      <td>0.331395</td>\n","      <td>0.575758</td>\n","      <td>0.420664</td>\n","      <td>[[653, 345], [126, 171]]</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.460000</td>\n","      <td>0.808375</td>\n","      <td>0.707336</td>\n","      <td>0.392105</td>\n","      <td>0.501684</td>\n","      <td>0.440177</td>\n","      <td>[[767, 231], [148, 149]]</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.464500</td>\n","      <td>0.809459</td>\n","      <td>0.666409</td>\n","      <td>0.350333</td>\n","      <td>0.531987</td>\n","      <td>0.422460</td>\n","      <td>[[705, 293], [139, 158]]</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.478300</td>\n","      <td>0.811007</td>\n","      <td>0.685714</td>\n","      <td>0.369048</td>\n","      <td>0.521886</td>\n","      <td>0.432357</td>\n","      <td>[[733, 265], [142, 155]]</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.350800</td>\n","      <td>0.946326</td>\n","      <td>0.694981</td>\n","      <td>0.375635</td>\n","      <td>0.498316</td>\n","      <td>0.428365</td>\n","      <td>[[752, 246], [149, 148]]</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.352800</td>\n","      <td>0.953000</td>\n","      <td>0.686486</td>\n","      <td>0.366748</td>\n","      <td>0.505051</td>\n","      <td>0.424929</td>\n","      <td>[[739, 259], [147, 150]]</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.335100</td>\n","      <td>0.964556</td>\n","      <td>0.694208</td>\n","      <td>0.374684</td>\n","      <td>0.498316</td>\n","      <td>0.427746</td>\n","      <td>[[751, 247], [149, 148]]</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.321200</td>\n","      <td>0.989749</td>\n","      <td>0.680309</td>\n","      <td>0.366133</td>\n","      <td>0.538721</td>\n","      <td>0.435967</td>\n","      <td>[[721, 277], [137, 160]]</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.315400</td>\n","      <td>1.027848</td>\n","      <td>0.713514</td>\n","      <td>0.397222</td>\n","      <td>0.481481</td>\n","      <td>0.435312</td>\n","      <td>[[781, 217], [154, 143]]</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.279100</td>\n","      <td>1.049417</td>\n","      <td>0.684942</td>\n","      <td>0.368794</td>\n","      <td>0.525253</td>\n","      <td>0.433333</td>\n","      <td>[[731, 267], [141, 156]]</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.262400</td>\n","      <td>1.096592</td>\n","      <td>0.700386</td>\n","      <td>0.378016</td>\n","      <td>0.474747</td>\n","      <td>0.420896</td>\n","      <td>[[766, 232], [156, 141]]</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.264100</td>\n","      <td>1.088988</td>\n","      <td>0.693436</td>\n","      <td>0.375622</td>\n","      <td>0.508418</td>\n","      <td>0.432046</td>\n","      <td>[[747, 251], [146, 151]]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","‚úÖ TRAINING COMPLETED!\n","======================================================================\n","üìä Final Training Loss: 0.5233\n","‚è±Ô∏è Training Time: 2101.13 seconds\n","‚ö° Training Speed: 73.92 samples/sec\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 16: Evaluate on Validation Set\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìä VALIDATION SET EVALUATION\")\n","print(\"=\"*70)\n","\n","val_results = trainer.evaluate(val_dataset)\n","\n","print(f\"\\n‚úÖ Validation Accuracy:  {val_results['eval_accuracy']:.4f}\")\n","print(f\"‚úÖ Validation Precision: {val_results['eval_precision']:.4f}\")\n","print(f\"‚úÖ Validation Recall:    {val_results['eval_recall']:.4f}\")\n","print(f\"‚úÖ Validation F1 Score:  {val_results['eval_f1']:.4f}\")\n","print(f\"\\nüìä Validation Confusion Matrix:\")\n","cm = val_results['eval_confusion_matrix']\n","print(f\"                  Predicted NEDA | Predicted EDA\")\n","print(f\"Actual NEDA:      {cm[0][0]:>14} | {cm[0][1]:>13}\")\n","print(f\"Actual EDA:       {cm[1][0]:>14} | {cm[1][1]:>13}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z64TC1NXIhrM","executionInfo":{"status":"ok","timestamp":1761747470459,"user_tz":-120,"elapsed":4918,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"196fccc4-6d0c-415d-dc5a-182e57bef93a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üìä VALIDATION SET EVALUATION\n","======================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41/41 00:05]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Validation Accuracy:  0.7073\n","‚úÖ Validation Precision: 0.3921\n","‚úÖ Validation Recall:    0.5017\n","‚úÖ Validation F1 Score:  0.4402\n","\n","üìä Validation Confusion Matrix:\n","                  Predicted NEDA | Predicted EDA\n","Actual NEDA:                 767 |           231\n","Actual EDA:                  148 |           149\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 17: Final Evaluation on Test Set (Held-Out Data)\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéØ FINAL TEST SET EVALUATION (HELD-OUT DATA)\")\n","print(\"=\"*70)\n","\n","test_results = trainer.evaluate(test_dataset)\n","\n","print(f\"\\n‚úÖ Test Accuracy:  {test_results['eval_accuracy']:.4f}\")\n","print(f\"‚úÖ Test Precision: {test_results['eval_precision']:.4f}\")\n","print(f\"‚úÖ Test Recall:    {test_results['eval_recall']:.4f}\")\n","print(f\"‚úÖ Test F1 Score:  {test_results['eval_f1']:.4f}\")\n","print(f\"\\nüìä Test Confusion Matrix:\")\n","cm = test_results['eval_confusion_matrix']\n","print(f\"                  Predicted NEDA | Predicted EDA\")\n","print(f\"Actual NEDA:      {cm[0][0]:>14} | {cm[0][1]:>13}\")\n","print(f\"Actual EDA:       {cm[1][0]:>14} | {cm[1][1]:>13}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yfN-QqCuIgOq","executionInfo":{"status":"ok","timestamp":1761747483875,"user_tz":-120,"elapsed":13332,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"09fc936b-301c-43df-8f72-c846cb21994f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üéØ FINAL TEST SET EVALUATION (HELD-OUT DATA)\n","======================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='147' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41/41 00:18]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Test Accuracy:  0.6537\n","‚úÖ Test Precision: 0.3141\n","‚úÖ Test Recall:    0.4832\n","‚úÖ Test F1 Score:  0.3807\n","\n","üìä Test Confusion Matrix:\n","                  Predicted NEDA | Predicted EDA\n","Actual NEDA:                1846 |           784\n","Actual EDA:                  384 |           359\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 18: Save the Best Model\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üíæ SAVING MODEL\")\n","print(\"=\"*70)\n","\n","# Save model locally\n","save_path = './best_funnel_model'\n","trainer.save_model(save_path)\n","tokenizer.save_pretrained(save_path)\n","\n","print(f\"‚úÖ Model saved to: {save_path}\")\n","print(f\"‚úÖ Tokenizer saved to: {save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uB_rb64FIeCX","executionInfo":{"status":"ok","timestamp":1761747484691,"user_tz":-120,"elapsed":799,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"6bbf8e8c-f76a-4e00-acf8-4b28647d6f02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üíæ SAVING MODEL\n","======================================================================\n","‚úÖ Model saved to: ./best_funnel_model\n","‚úÖ Tokenizer saved to: ./best_funnel_model\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 19: Summary\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéâ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n","print(\"=\"*70)\n","print(f\"\\nüìä Final Results Summary:\")\n","print(f\"   Training samples:   {len(train_dataset)}\")\n","print(f\"   Validation samples: {len(val_dataset)}\")\n","print(f\"   Test samples:       {len(test_dataset)}\")\n","print(f\"\\n   Test Accuracy:  {test_results['eval_accuracy']:.4f}\")\n","print(f\"   Test Precision: {test_results['eval_precision']:.4f}\")\n","print(f\"   Test Recall:    {test_results['eval_recall']:.4f}\")\n","print(f\"   Test F1 Score:  {test_results['eval_f1']:.4f}\")\n","print(f\"\\nüíæ Model saved at: {save_path}\")\n","print(\"=\"*70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HgZst1j7Ibmf","executionInfo":{"status":"ok","timestamp":1761747484704,"user_tz":-120,"elapsed":10,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"7c9e15ea-75bc-4f90-dea6-f0e79dd9ee5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üéâ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\n","======================================================================\n","\n","üìä Final Results Summary:\n","   Training samples:   5177\n","   Validation samples: 1295\n","   Test samples:       3373\n","\n","   Test Accuracy:  0.6537\n","   Test Precision: 0.3141\n","   Test Recall:    0.4832\n","   Test F1 Score:  0.3807\n","\n","üíæ Model saved at: ./best_funnel_model\n","======================================================================\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"COPiELFcI4--"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##ModernBERT"],"metadata":{"id":"2i7cimtTf2TY"}},{"cell_type":"code","source":["\n","# ============================================================================\n","# STEP 1: Install Required Libraries\n","# ============================================================================\n","print(\"üì¶ Installing required libraries...\")\n","!pip install -q transformers datasets openpyxl scikit-learn huggingface_hub accelerate\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751803346,"user_tz":-120,"elapsed":6592,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"34dfed89-7d91-496e-cbab-2464e0575c35","id":"Bx1m6qozgt_e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing required libraries...\n"]}]},{"cell_type":"code","source":["\n","# ============================================================================\n","# STEP 2: Import Libraries\n","# ============================================================================\n","print(\"\\nüìö Importing libraries...\")\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from google.colab import files, userdata\n","from transformers import (\n","    FunnelTokenizer,\n","    FunnelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer\n",")\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","from sklearn.utils.class_weight import compute_class_weight\n","from huggingface_hub import login\n","import warnings\n","warnings.filterwarnings('ignore')\n","from transformers import PreTrainedTokenizerFast, BertForSequenceClassification\n","\n","\n","print(\"‚úÖ Libraries imported successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751976482,"user_tz":-120,"elapsed":53,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"eb3e6c43-3f95-47f7-c64f-f9b68d17cb27","id":"5lN2OpQigt_f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìö Importing libraries...\n","‚úÖ Libraries imported successfully!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 3: Login to Hugging Face (Optional but Recommended)\n","# ============================================================================\n","print(\"\\nüîê Logging into Hugging Face...\")\n","\n","try:\n","    HF_TOKEN = userdata.get('HF_TOKEN')\n","    login(token=HF_TOKEN)\n","    print(\"‚úÖ Successfully logged into Hugging Face!\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not login to HF: {e}\")\n","    print(\"Continuing without HF login...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751824253,"user_tz":-120,"elapsed":665,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"d158fa17-9257-4f01-da01-7cd66bacbc18","id":"Ie_P0XyHhChw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîê Logging into Hugging Face...\n","‚úÖ Successfully logged into Hugging Face!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 4: Upload Training and Testing Files\n","# ============================================================================\n","print(\"\\nüìÅ Please upload your Excel files...\")\n","print(\"Expected format: 'input' column (text) and 'output' column (labels)\")\n","\n","# Check if files already exist\n","if not os.path.exists('/content/train.xlsx'):\n","    print(\"\\nüì§ Upload TRAINING file (train.xlsx):\")\n","    train_uploaded = files.upload()\n","else:\n","    print(\"‚úÖ Training file already exists!\")\n","\n","if not os.path.exists('/content/test.xlsx'):\n","    print(\"\\nüì§ Upload TESTING file (test.xlsx):\")\n","    test_uploaded = files.upload()\n","else:\n","    print(\"‚úÖ Testing file already exists!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751841594,"user_tz":-120,"elapsed":17338,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"4510a8c8-d2ff-4286-a03e-ad5bcf01f060","id":"jqstSbsVhChw"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìÅ Please upload your Excel files...\n","Expected format: 'input' column (text) and 'output' column (labels)\n","\n","üì§ Upload TRAINING file (train.xlsx):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6e9aa675-205c-410d-bbee-f92344ec4004\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6e9aa675-205c-410d-bbee-f92344ec4004\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train.xlsx to train.xlsx\n","\n","üì§ Upload TESTING file (test.xlsx):\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8358a591-9a0e-4a09-9eb3-f995eaf664c7\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8358a591-9a0e-4a09-9eb3-f995eaf664c7\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test.xlsx to test.xlsx\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 5: Load Data from Excel Files\n","# ============================================================================\n","print(\"\\nüìä Loading data from Excel files...\")\n","\n","train_df = pd.read_excel('/content/train.xlsx')\n","test_df = pd.read_excel('/content/test.xlsx')\n","\n","print(f\"‚úÖ Training data loaded: {train_df.shape[0]} rows, {train_df.shape[1]} columns\")\n","print(f\"‚úÖ Testing data loaded: {test_df.shape[0]} rows, {test_df.shape[1]} columns\")\n","\n","# Preview data\n","print(\"\\nüìã Training data preview:\")\n","print(train_df.head())\n","print(\"\\nüìã Testing data preview:\")\n","print(test_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751842529,"user_tz":-120,"elapsed":918,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"8eaed277-506b-4635-a5e2-0e2a0993e352","id":"tniTNR9_hChx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä Loading data from Excel files...\n","‚úÖ Training data loaded: 6472 rows, 3 columns\n","‚úÖ Testing data loaded: 3373 rows, 3 columns\n","\n","üìã Training data preview:\n","   MSC research database ID  \\\n","0                         1   \n","1                         1   \n","2                         1   \n","3                         1   \n","4                         1   \n","\n","                                               input  \\\n","0  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","1  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","2  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","3  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","4  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","\n","                                        output  \n","0  After 7 months the patient will be in NEDA.  \n","1   After 7 months the patient will be in EDA.  \n","2   After 0 months the patient will be in EDA.  \n","3   After 4 months the patient will be in EDA.  \n","4  After 6 months the patient will be in NEDA.  \n","\n","üìã Testing data preview:\n","   MSC research database ID  \\\n","0                         7   \n","1                         7   \n","2                         7   \n","3                         7   \n","4                         7   \n","\n","                                               input  \\\n","0  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","1  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","2  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","3  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","4  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","\n","                                        output  \n","0  After 9 months the patient will be in NEDA.  \n","1  After 6 months the patient will be in NEDA.  \n","2  After 5 months the patient will be in NEDA.  \n","3  After 6 months the patient will be in NEDA.  \n","4  After 6 months the patient will be in NEDA.  \n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 6: Process Labels\n","# ============================================================================\n","print(\"\\nüè∑Ô∏è Processing labels...\")\n","\n","def extract_label(output_text):\n","    \"\"\"Extract NEDA or EDA from output text\"\"\"\n","    output_text = str(output_text).upper()\n","    if 'NEDA' in output_text:\n","        return 'NEDA'\n","    elif 'EDA' in output_text:\n","        return 'EDA'\n","    else:\n","        return None\n","\n","# Apply label extraction\n","train_df['label_text'] = train_df['output'].apply(extract_label)\n","test_df['label_text'] = test_df['output'].apply(extract_label)\n","\n","# Remove rows with None labels\n","train_df = train_df[train_df['label_text'].notna()].reset_index(drop=True)\n","test_df = test_df[test_df['label_text'].notna()].reset_index(drop=True)\n","\n","# Create label mapping\n","label2id = {'NEDA': 0, 'EDA': 1}\n","id2label = {0: 'NEDA', 1: 'EDA'}\n","\n","# Convert to numeric labels\n","train_df['label'] = train_df['label_text'].map(label2id)\n","test_df['label'] = test_df['label_text'].map(label2id)\n","\n","print(f\"‚úÖ Labels extracted successfully!\")\n","print(f\"\\nüìä Training set: {len(train_df)} samples\")\n","print(f\"   - NEDA: {sum(train_df['label']==0)} ({sum(train_df['label']==0)/len(train_df)*100:.1f}%)\")\n","print(f\"   - EDA:  {sum(train_df['label']==1)} ({sum(train_df['label']==1)/len(train_df)*100:.1f}%)\")\n","print(f\"\\nüìä Testing set: {len(test_df)} samples\")\n","print(f\"   - NEDA: {sum(test_df['label']==0)} ({sum(test_df['label']==0)/len(test_df)*100:.1f}%)\")\n","print(f\"   - EDA:  {sum(test_df['label']==1)} ({sum(test_df['label']==1)/len(test_df)*100:.1f}%)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751842588,"user_tz":-120,"elapsed":31,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"e54c8d17-d53f-4615-d7d3-983ea16babee","id":"MWWFvjojhChx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üè∑Ô∏è Processing labels...\n","‚úÖ Labels extracted successfully!\n","\n","üìä Training set: 6472 samples\n","   - NEDA: 4989 (77.1%)\n","   - EDA:  1483 (22.9%)\n","\n","üìä Testing set: 3373 samples\n","   - NEDA: 2630 (78.0%)\n","   - EDA:  743 (22.0%)\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 7: Split Training Data into Train and Validation Sets\n","# ============================================================================\n","print(\"\\n‚úÇÔ∏è Splitting training data into train and validation sets...\")\n","\n","train_data, val_data = train_test_split(\n","    train_df,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=train_df['label']  # Maintain class balance\n",")\n","\n","print(f\"‚úÖ Final split:\")\n","print(f\"   - Training:   {len(train_data)} samples\")\n","print(f\"   - Validation: {len(val_data)} samples\")\n","print(f\"   - Testing:    {len(test_df)} samples\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751842609,"user_tz":-120,"elapsed":18,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"b6fff8cb-a9b5-489f-ea5a-e900477e1d20","id":"FmozYqUmhChx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚úÇÔ∏è Splitting training data into train and validation sets...\n","‚úÖ Final split:\n","   - Training:   5177 samples\n","   - Validation: 1295 samples\n","   - Testing:    3373 samples\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 8: Compute Class Weights for Imbalanced Data\n","# ============================================================================\n","print(\"\\n‚öñÔ∏è Computing class weights to handle class imbalance...\")\n","\n","train_labels = train_data['label'].values\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(train_labels),\n","    y=train_labels\n",")\n","class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n","\n","print(f\"‚úÖ Class weights computed:\")\n","print(f\"   - NEDA (class 0): {class_weights[0]:.4f}\")\n","print(f\"   - EDA  (class 1): {class_weights[1]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751842621,"user_tz":-120,"elapsed":11,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"d6c910e9-bed5-4604-bb41-42270ab55ee8","id":"cuLDc9HKhChx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚öñÔ∏è Computing class weights to handle class imbalance...\n","‚úÖ Class weights computed:\n","   - NEDA (class 0): 0.6486\n","   - EDA  (class 1): 2.1825\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 9: Initialize Tokenizer and Model\n","# ============================================================================\n","print(\"\\nü§ñ Loading Funnel Transformer model and tokenizer...\")\n","\n","MODEL_NAME = \"answerdotai/ModernBERT-base\"\n","\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME)\n","model = BertForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id\n",")\n","\n","\n","# Count parameters\n","n_params = sum(p.numel() for p in model.parameters())\n","print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n","print(f\"‚úÖ Number of parameters: {n_params:,}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["f42adaa0627148868aa862260e2271c2","30fc686812fa4eda939372be7ae572b3","d254dd1fff6240059c2fb5315b627a6c","564dd95f4d47428ba1def0ceb93a6916","747bb7a31b044580a0e7a2103c78ca30","12326ec25abf46a8aa4ebc13b82b8b74","59cb7b863b6f45e68f5542137591e0a7","3c8cf2a41cfa41ddb1571597bee81378","6ed21897683c41b1a5584c02a19eaab1","25a467054b3543359537a752ae1b880b","4408d592a6b54d29984bd2297ab8c2ea"]},"executionInfo":{"status":"ok","timestamp":1761751985716,"user_tz":-120,"elapsed":3599,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"4bf73b4d-49bc-4b38-a7d3-e694439c52d7","id":"0PVHaPKthChy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ü§ñ Loading Funnel Transformer model and tokenizer...\n"]},{"output_type":"stream","name":"stderr","text":["You are using a model of type modernbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f42adaa0627148868aa862260e2271c2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.12.attention.output.LayerNorm.bias', 'bert.encoder.layer.12.attention.output.LayerNorm.weight', 'bert.encoder.layer.12.attention.output.dense.bias', 'bert.encoder.layer.12.attention.output.dense.weight', 'bert.encoder.layer.12.attention.self.key.bias', 'bert.encoder.layer.12.attention.self.key.weight', 'bert.encoder.layer.12.attention.self.query.bias', 'bert.encoder.layer.12.attention.self.query.weight', 'bert.encoder.layer.12.attention.self.value.bias', 'bert.encoder.layer.12.attention.self.value.weight', 'bert.encoder.layer.12.intermediate.dense.bias', 'bert.encoder.layer.12.intermediate.dense.weight', 'bert.encoder.layer.12.output.LayerNorm.bias', 'bert.encoder.layer.12.output.LayerNorm.weight', 'bert.encoder.layer.12.output.dense.bias', 'bert.encoder.layer.12.output.dense.weight', 'bert.encoder.layer.13.attention.output.LayerNorm.bias', 'bert.encoder.layer.13.attention.output.LayerNorm.weight', 'bert.encoder.layer.13.attention.output.dense.bias', 'bert.encoder.layer.13.attention.output.dense.weight', 'bert.encoder.layer.13.attention.self.key.bias', 'bert.encoder.layer.13.attention.self.key.weight', 'bert.encoder.layer.13.attention.self.query.bias', 'bert.encoder.layer.13.attention.self.query.weight', 'bert.encoder.layer.13.attention.self.value.bias', 'bert.encoder.layer.13.attention.self.value.weight', 'bert.encoder.layer.13.intermediate.dense.bias', 'bert.encoder.layer.13.intermediate.dense.weight', 'bert.encoder.layer.13.output.LayerNorm.bias', 'bert.encoder.layer.13.output.LayerNorm.weight', 'bert.encoder.layer.13.output.dense.bias', 'bert.encoder.layer.13.output.dense.weight', 'bert.encoder.layer.14.attention.output.LayerNorm.bias', 'bert.encoder.layer.14.attention.output.LayerNorm.weight', 'bert.encoder.layer.14.attention.output.dense.bias', 'bert.encoder.layer.14.attention.output.dense.weight', 'bert.encoder.layer.14.attention.self.key.bias', 'bert.encoder.layer.14.attention.self.key.weight', 'bert.encoder.layer.14.attention.self.query.bias', 'bert.encoder.layer.14.attention.self.query.weight', 'bert.encoder.layer.14.attention.self.value.bias', 'bert.encoder.layer.14.attention.self.value.weight', 'bert.encoder.layer.14.intermediate.dense.bias', 'bert.encoder.layer.14.intermediate.dense.weight', 'bert.encoder.layer.14.output.LayerNorm.bias', 'bert.encoder.layer.14.output.LayerNorm.weight', 'bert.encoder.layer.14.output.dense.bias', 'bert.encoder.layer.14.output.dense.weight', 'bert.encoder.layer.15.attention.output.LayerNorm.bias', 'bert.encoder.layer.15.attention.output.LayerNorm.weight', 'bert.encoder.layer.15.attention.output.dense.bias', 'bert.encoder.layer.15.attention.output.dense.weight', 'bert.encoder.layer.15.attention.self.key.bias', 'bert.encoder.layer.15.attention.self.key.weight', 'bert.encoder.layer.15.attention.self.query.bias', 'bert.encoder.layer.15.attention.self.query.weight', 'bert.encoder.layer.15.attention.self.value.bias', 'bert.encoder.layer.15.attention.self.value.weight', 'bert.encoder.layer.15.intermediate.dense.bias', 'bert.encoder.layer.15.intermediate.dense.weight', 'bert.encoder.layer.15.output.LayerNorm.bias', 'bert.encoder.layer.15.output.LayerNorm.weight', 'bert.encoder.layer.15.output.dense.bias', 'bert.encoder.layer.15.output.dense.weight', 'bert.encoder.layer.16.attention.output.LayerNorm.bias', 'bert.encoder.layer.16.attention.output.LayerNorm.weight', 'bert.encoder.layer.16.attention.output.dense.bias', 'bert.encoder.layer.16.attention.output.dense.weight', 'bert.encoder.layer.16.attention.self.key.bias', 'bert.encoder.layer.16.attention.self.key.weight', 'bert.encoder.layer.16.attention.self.query.bias', 'bert.encoder.layer.16.attention.self.query.weight', 'bert.encoder.layer.16.attention.self.value.bias', 'bert.encoder.layer.16.attention.self.value.weight', 'bert.encoder.layer.16.intermediate.dense.bias', 'bert.encoder.layer.16.intermediate.dense.weight', 'bert.encoder.layer.16.output.LayerNorm.bias', 'bert.encoder.layer.16.output.LayerNorm.weight', 'bert.encoder.layer.16.output.dense.bias', 'bert.encoder.layer.16.output.dense.weight', 'bert.encoder.layer.17.attention.output.LayerNorm.bias', 'bert.encoder.layer.17.attention.output.LayerNorm.weight', 'bert.encoder.layer.17.attention.output.dense.bias', 'bert.encoder.layer.17.attention.output.dense.weight', 'bert.encoder.layer.17.attention.self.key.bias', 'bert.encoder.layer.17.attention.self.key.weight', 'bert.encoder.layer.17.attention.self.query.bias', 'bert.encoder.layer.17.attention.self.query.weight', 'bert.encoder.layer.17.attention.self.value.bias', 'bert.encoder.layer.17.attention.self.value.weight', 'bert.encoder.layer.17.intermediate.dense.bias', 'bert.encoder.layer.17.intermediate.dense.weight', 'bert.encoder.layer.17.output.LayerNorm.bias', 'bert.encoder.layer.17.output.LayerNorm.weight', 'bert.encoder.layer.17.output.dense.bias', 'bert.encoder.layer.17.output.dense.weight', 'bert.encoder.layer.18.attention.output.LayerNorm.bias', 'bert.encoder.layer.18.attention.output.LayerNorm.weight', 'bert.encoder.layer.18.attention.output.dense.bias', 'bert.encoder.layer.18.attention.output.dense.weight', 'bert.encoder.layer.18.attention.self.key.bias', 'bert.encoder.layer.18.attention.self.key.weight', 'bert.encoder.layer.18.attention.self.query.bias', 'bert.encoder.layer.18.attention.self.query.weight', 'bert.encoder.layer.18.attention.self.value.bias', 'bert.encoder.layer.18.attention.self.value.weight', 'bert.encoder.layer.18.intermediate.dense.bias', 'bert.encoder.layer.18.intermediate.dense.weight', 'bert.encoder.layer.18.output.LayerNorm.bias', 'bert.encoder.layer.18.output.LayerNorm.weight', 'bert.encoder.layer.18.output.dense.bias', 'bert.encoder.layer.18.output.dense.weight', 'bert.encoder.layer.19.attention.output.LayerNorm.bias', 'bert.encoder.layer.19.attention.output.LayerNorm.weight', 'bert.encoder.layer.19.attention.output.dense.bias', 'bert.encoder.layer.19.attention.output.dense.weight', 'bert.encoder.layer.19.attention.self.key.bias', 'bert.encoder.layer.19.attention.self.key.weight', 'bert.encoder.layer.19.attention.self.query.bias', 'bert.encoder.layer.19.attention.self.query.weight', 'bert.encoder.layer.19.attention.self.value.bias', 'bert.encoder.layer.19.attention.self.value.weight', 'bert.encoder.layer.19.intermediate.dense.bias', 'bert.encoder.layer.19.intermediate.dense.weight', 'bert.encoder.layer.19.output.LayerNorm.bias', 'bert.encoder.layer.19.output.LayerNorm.weight', 'bert.encoder.layer.19.output.dense.bias', 'bert.encoder.layer.19.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.20.attention.output.LayerNorm.bias', 'bert.encoder.layer.20.attention.output.LayerNorm.weight', 'bert.encoder.layer.20.attention.output.dense.bias', 'bert.encoder.layer.20.attention.output.dense.weight', 'bert.encoder.layer.20.attention.self.key.bias', 'bert.encoder.layer.20.attention.self.key.weight', 'bert.encoder.layer.20.attention.self.query.bias', 'bert.encoder.layer.20.attention.self.query.weight', 'bert.encoder.layer.20.attention.self.value.bias', 'bert.encoder.layer.20.attention.self.value.weight', 'bert.encoder.layer.20.intermediate.dense.bias', 'bert.encoder.layer.20.intermediate.dense.weight', 'bert.encoder.layer.20.output.LayerNorm.bias', 'bert.encoder.layer.20.output.LayerNorm.weight', 'bert.encoder.layer.20.output.dense.bias', 'bert.encoder.layer.20.output.dense.weight', 'bert.encoder.layer.21.attention.output.LayerNorm.bias', 'bert.encoder.layer.21.attention.output.LayerNorm.weight', 'bert.encoder.layer.21.attention.output.dense.bias', 'bert.encoder.layer.21.attention.output.dense.weight', 'bert.encoder.layer.21.attention.self.key.bias', 'bert.encoder.layer.21.attention.self.key.weight', 'bert.encoder.layer.21.attention.self.query.bias', 'bert.encoder.layer.21.attention.self.query.weight', 'bert.encoder.layer.21.attention.self.value.bias', 'bert.encoder.layer.21.attention.self.value.weight', 'bert.encoder.layer.21.intermediate.dense.bias', 'bert.encoder.layer.21.intermediate.dense.weight', 'bert.encoder.layer.21.output.LayerNorm.bias', 'bert.encoder.layer.21.output.LayerNorm.weight', 'bert.encoder.layer.21.output.dense.bias', 'bert.encoder.layer.21.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Model loaded: answerdotai/ModernBERT-base\n","‚úÖ Number of parameters: 136,579,586\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 10: Tokenize Data\n","# ============================================================================\n","print(\"\\nüî§ Tokenizing data...\")\n","\n","def tokenize_function(examples):\n","    \"\"\"Tokenize input texts\"\"\"\n","    return tokenizer(\n","        examples['input'],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=256\n","    )\n","\n","# Convert to Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(train_data[['input', 'label']])\n","val_dataset = Dataset.from_pandas(val_data[['input', 'label']])\n","test_dataset = Dataset.from_pandas(test_df[['input', 'label']])\n","\n","# Tokenize datasets\n","print(\"   Tokenizing training set...\")\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","print(\"   Tokenizing validation set...\")\n","val_dataset = val_dataset.map(tokenize_function, batched=True)\n","print(\"   Tokenizing test set...\")\n","test_dataset = test_dataset.map(tokenize_function, batched=True)\n","\n","# Set format for PyTorch\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","print(f\"‚úÖ Tokenization complete!\")\n","print(f\"   - Training dataset:   {len(train_dataset)} samples\")\n","print(f\"   - Validation dataset: {len(val_dataset)} samples\")\n","print(f\"   - Test dataset:       {len(test_dataset)} samples\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["03276f01aada4601aaaca93c2c6c12fb","88d2bd49039343d59398f35ac1f45ce1","0f90eaa106144988a69afb34ac0fd249","cd17a76e44fd4f4faf8835df9e4fbc2d","9283e6be68da4c1a89faa07506390f25","105e75daa26d4719a532586e6b02d97b","8acecb9c778e405bbe0d681e119158c0","39a118a2652a4060a03026b880cedec4","491a6bb0e23e46e0841247d3e90c04ae","c9ce846a10564d03a9f70907a7c59619","79ac9cdec3ae4f14ba279cecd19df1f8","ed578abdd2074334abbef48ae96d1cfa","e1b074be799440e1afce270b06785265","d6be80b2091047f9806ebf143e79533a","eb99e5cb8e7c4663b05b7cb5055bf0b5","0de0d7048f37448fae0a5a1a20357635","e24fb0be54bc4417bbbb2a7b208c9452","888158ebd2e44c599eed8ba19f47a78d","8bf9fdbd09ce436c862bd51534e647dc","9f61c81852c04a48b45738279a4fde05","bd21c7f01f3b4db1b491f22a2ee20556","5de16125e43a46448290e31b8024d327","e21a99cb3396467d90afaca7688d6260","7b3187038b89492180df9b42ded98a89","7a9209ba012147fdabe0549324b36260","7dd12de412104ff2bcda8c9dd1e96492","ce134881bd964a4f812874614dd9921a","42cb141a4c9f4ccbbb268ab918de8d8b","6ec46d7209d344669d9f44d25fd275f6","363eeaf36c8546e28b5fac6e1ea85fdd","ff6fbea349e54c61bc60babc96dade7b","bf4a274e06674d459d871a70d82eac93","7672a5a863d546269f50645d4adbd05c"]},"executionInfo":{"status":"ok","timestamp":1761751991570,"user_tz":-120,"elapsed":2704,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"10339780-8e87-4a30-881c-3b3e15fe25c7","id":"ASUuk0TyhChy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üî§ Tokenizing data...\n","   Tokenizing training set...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5177 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03276f01aada4601aaaca93c2c6c12fb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   Tokenizing validation set...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1295 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed578abdd2074334abbef48ae96d1cfa"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["   Tokenizing test set...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e21a99cb3396467d90afaca7688d6260"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Tokenization complete!\n","   - Training dataset:   5177 samples\n","   - Validation dataset: 1295 samples\n","   - Test dataset:       3373 samples\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 11: Define Evaluation Metrics\n","# ============================================================================\n","print(\"\\nüìä Setting up evaluation metrics...\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"Compute metrics for evaluation\"\"\"\n","    logits, labels = eval_pred\n","\n","    # Convert logits to tensor if needed\n","    logits = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits\n","\n","    # Get predictions\n","    predictions = torch.argmax(logits, axis=-1).cpu().numpy()\n","    labels = labels if isinstance(labels, np.ndarray) else labels.cpu().numpy()\n","\n","    # Compute metrics\n","    accuracy = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels, predictions, average='binary', zero_division=0\n","    )\n","    cm = confusion_matrix(labels, predictions)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","print(\"‚úÖ Evaluation metrics configured!\")\n","\n","\n","print(\"‚úÖ Custom trainer class created!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751993707,"user_tz":-120,"elapsed":7,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"67da3f18-d8f6-4f60-f4ef-967f23ae9823","id":"OZFep6gThChy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä Setting up evaluation metrics...\n","‚úÖ Evaluation metrics configured!\n","‚úÖ Custom trainer class created!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 12: Create Custom Trainer with Weighted Loss\n","# ============================================================================\n","print(\"\\nüéØ Creating custom trainer with weighted loss...\")\n","\n","class WeightedLossTrainer(Trainer):\n","    \"\"\"Custom Trainer with weighted cross-entropy loss\"\"\"\n","\n","    def __init__(self, *args, class_weights=None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.class_weights = class_weights\n","\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","\n","        # Use weighted cross-entropy loss\n","        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","\n","        return (loss, outputs) if return_outputs else loss\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761751995039,"user_tz":-120,"elapsed":12,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"a4642272-e394-47e7-a331-e6b1a92e8e70","id":"YAGmSTiAhChz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üéØ Creating custom trainer with weighted loss...\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 13: Setup Training Arguments\n","# ============================================================================\n","print(\"\\n‚öôÔ∏è Configuring training arguments...\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=1e-4,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    greater_is_better=True,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',\n","    push_to_hub=False,\n","    warmup_ratio=0.1,  # Adjust warmup ratio\n","    lr_scheduler_type='cosine',  # Use a different scheduler\n","    seed=42,\n","    gradient_accumulation_steps=1,  # Adjust gradient accumulation\n","    max_grad_norm=0.5,  # Reduce gradient clipping\n",")\n","\n","\n","print(\"‚úÖ Training arguments configured!\")\n","print(f\"   - Learning rate: {training_args.learning_rate}\")\n","print(f\"   - Batch size: {training_args.per_device_train_batch_size}\")\n","print(f\"   - Epochs: {training_args.num_train_epochs}\")\n","print(f\"   - Warmup ratio: {training_args.warmup_ratio}\")\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761752297209,"user_tz":-120,"elapsed":58,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"8ee84e6b-07d3-48f5-b195-6f3a88583190","id":"GKosIsU-hChz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚öôÔ∏è Configuring training arguments...\n","‚úÖ Training arguments configured!\n","   - Learning rate: 0.0001\n","   - Batch size: 16\n","   - Epochs: 10\n","   - Warmup ratio: 0.1\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 14: Initialize Trainer\n","# ============================================================================\n","print(\"\\nüéØ Initializing weighted trainer...\")\n","\n","trainer = WeightedLossTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,  # Use validation set during training\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    class_weights=class_weights_tensor,\n",")\n","\n","print(\"‚úÖ Trainer initialized successfully!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761752297579,"user_tz":-120,"elapsed":29,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"c3bb1d2d-dd2c-4cb2-c9ca-2bff6ca1a2c3","id":"e0I9X_F7hChz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üéØ Initializing weighted trainer...\n","‚úÖ Trainer initialized successfully!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 15: Train the Model\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ STARTING TRAINING\")\n","print(\"=\"*70)\n","print(\"\\nThis may take a while. Training progress will be shown below...\")\n","print(\"-\"*70)\n","\n","train_result = trainer.train()\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ TRAINING COMPLETED!\")\n","print(\"=\"*70)\n","print(f\"üìä Final Training Loss: {train_result.training_loss:.4f}\")\n","print(f\"‚è±Ô∏è Training Time: {train_result.metrics['train_runtime']:.2f} seconds\")\n","print(f\"‚ö° Training Speed: {train_result.metrics['train_samples_per_second']:.2f} samples/sec\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1761752506262,"user_tz":-120,"elapsed":207766,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"4417a198-1651-41de-877b-13512493300f","id":"nclra-HdhCh0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üöÄ STARTING TRAINING\n","======================================================================\n","\n","This may take a while. Training progress will be shown below...\n","----------------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='985' max='3240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 985/3240 03:27 < 07:55, 4.74 it/s, Epoch 3.04/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.750200</td>\n","      <td>0.713667</td>\n","      <td>0.770656</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[998, 0], [297, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.727700</td>\n","      <td>0.692187</td>\n","      <td>0.770656</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[998, 0], [297, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.688500</td>\n","      <td>0.749163</td>\n","      <td>0.229344</td>\n","      <td>0.229344</td>\n","      <td>1.000000</td>\n","      <td>0.373116</td>\n","      <td>[[0, 998], [0, 297]]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2747714388.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2616\u001b[0m                 \u001b[0mupdate_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m                 \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupdate_step\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_updates\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2619\u001b[0m                 \u001b[0;31m# Store the number of batches for current gradient accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m                 \u001b[0;31m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5652\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5653\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5654\u001b[0;31m                 \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5655\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5656\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mcurrent_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         batch = pad_without_fast_tokenizer_warning(\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpad_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpad_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Restore the state of the warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3455\u001b[0m                 \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3459\u001b[0m     def create_token_type_ids_from_sequences(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0;31m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msub_arr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 16: Evaluate on Validation Set\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìä VALIDATION SET EVALUATION\")\n","print(\"=\"*70)\n","\n","val_results = trainer.evaluate(val_dataset)\n","\n","print(f\"\\n‚úÖ Validation Accuracy:  {val_results['eval_accuracy']:.4f}\")\n","print(f\"‚úÖ Validation Precision: {val_results['eval_precision']:.4f}\")\n","print(f\"‚úÖ Validation Recall:    {val_results['eval_recall']:.4f}\")\n","print(f\"‚úÖ Validation F1 Score:  {val_results['eval_f1']:.4f}\")\n","print(f\"\\nüìä Validation Confusion Matrix:\")\n","cm = val_results['eval_confusion_matrix']\n","print(f\"                  Predicted NEDA | Predicted EDA\")\n","print(f\"Actual NEDA:      {cm[0][0]:>14} | {cm[0][1]:>13}\")\n","print(f\"Actual EDA:       {cm[1][0]:>14} | {cm[1][1]:>13}\")\n","\n"],"metadata":{"id":"RwoBdPDjhCh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 17: Final Evaluation on Test Set (Held-Out Data)\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéØ FINAL TEST SET EVALUATION (HELD-OUT DATA)\")\n","print(\"=\"*70)\n","\n","test_results = trainer.evaluate(test_dataset)\n","\n","print(f\"\\n‚úÖ Test Accuracy:  {test_results['eval_accuracy']:.4f}\")\n","print(f\"‚úÖ Test Precision: {test_results['eval_precision']:.4f}\")\n","print(f\"‚úÖ Test Recall:    {test_results['eval_recall']:.4f}\")\n","print(f\"‚úÖ Test F1 Score:  {test_results['eval_f1']:.4f}\")\n","print(f\"\\nüìä Test Confusion Matrix:\")\n","cm = test_results['eval_confusion_matrix']\n","print(f\"                  Predicted NEDA | Predicted EDA\")\n","print(f\"Actual NEDA:      {cm[0][0]:>14} | {cm[0][1]:>13}\")\n","print(f\"Actual EDA:       {cm[1][0]:>14} | {cm[1][1]:>13}\")\n","\n"],"metadata":{"id":"KxGdSfWVhCh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 18: Save the Best Model\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üíæ SAVING MODEL\")\n","print(\"=\"*70)\n","\n","# Save model locally\n","save_path = './best_funnel_model'\n","trainer.save_model(save_path)\n","tokenizer.save_pretrained(save_path)\n","\n","print(f\"‚úÖ Model saved to: {save_path}\")\n","print(f\"‚úÖ Tokenizer saved to: {save_path}\")\n"],"metadata":{"id":"VFnZw7rHhCh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 19: Summary\n","# ============================================================================\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéâ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n","print(\"=\"*70)\n","print(f\"\\nüìä Final Results Summary:\")\n","print(f\"   Training samples:   {len(train_dataset)}\")\n","print(f\"   Validation samples: {len(val_dataset)}\")\n","print(f\"   Test samples:       {len(test_dataset)}\")\n","print(f\"\\n   Test Accuracy:  {test_results['eval_accuracy']:.4f}\")\n","print(f\"   Test Precision: {test_results['eval_precision']:.4f}\")\n","print(f\"   Test Recall:    {test_results['eval_recall']:.4f}\")\n","print(f\"   Test F1 Score:  {test_results['eval_f1']:.4f}\")\n","print(f\"\\nüíæ Model saved at: {save_path}\")\n","print(\"=\"*70)"],"metadata":{"id":"_XfSGjZ1hCh0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Gemma 3n"],"metadata":{"id":"A5DiddqrvP0v"}},{"cell_type":"code","source":["# Install necessary libraries\n","!pip install -q transformers datasets openpyxl scikit-learn\n","import numpy as np\n","import os\n","import pandas as pd\n","from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n","from datasets import Dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","import torch\n","from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n","\n","# Check if the required files exist and load them\n","train_file = '/content/train.xlsx'\n","test_file = '/content/test.xlsx'\n","\n","# Ensure files are uploaded\n","if not os.path.exists(train_file) or not os.path.exists(test_file):\n","    print(\"Please upload 'train.xlsx' and 'test.xlsx'.\")\n","else:\n","    # Load the training and testing data\n","    train_df = pd.read_excel(train_file)\n","    test_df = pd.read_excel(test_file)\n","\n","    # Rename columns to match the expected format (text, label)\n","    train_df = train_df.rename(columns={'input': 'text', 'output': 'label'})\n","    test_df = test_df.rename(columns={'input': 'text', 'output': 'label'})\n","\n","    # Convert labels to numeric values\n","    train_df['label'] = train_df['label'].astype('category').cat.codes\n","    test_df['label'] = test_df['label'].astype('category').cat.codes\n","\n","    # Split the test dataset into validation and test sets\n","    test_df, val_df = train_test_split(test_df, test_size=0.2, random_state=42)\n","\n","    # Convert the DataFrames to datasets\n","    train_dataset = Dataset.from_pandas(train_df)\n","    test_dataset = Dataset.from_pandas(test_df)\n","    val_dataset = Dataset.from_pandas(val_df)\n","\n","    # Combine the datasets into a DatasetDict for easier handling\n","    datasets = DatasetDict({\n","        'train': train_dataset,\n","        'test': test_dataset,\n","        'validation': val_dataset\n","    })\n","\n","    # Initialize the tokenizer and model\n","    model_name = \"google/gemma-3-1b-it\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(train_df['label'].unique()))\n","\n","    # Tokenize the dataset with a fixed max_length\n","    def tokenize_function(examples):\n","        return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=128)\n","\n","    tokenized_datasets = datasets.map(tokenize_function, batched=True)\n","\n","    # Remove unnecessary columns\n","    tokenized_datasets = tokenized_datasets.remove_columns(['text'])\n","\n","    # Define training arguments\n","    training_args = TrainingArguments(\n","        output_dir='./results',\n","        eval_strategy='epoch',\n","        save_strategy='epoch',\n","        learning_rate=1e-4,\n","        per_device_train_batch_size=16,\n","        per_device_eval_batch_size=16,\n","        num_train_epochs=10,\n","        weight_decay=0.01,\n","        load_best_model_at_end=True,\n","        metric_for_best_model='f1',\n","        greater_is_better=True,\n","        logging_dir='./logs',\n","        logging_steps=10,\n","        save_total_limit=2,\n","        report_to='none',\n","        push_to_hub=False,\n","        warmup_ratio=0.1,  # Adjust warmup ratio\n","        lr_scheduler_type='cosine',  # Use a different scheduler\n","        seed=42,\n","        gradient_accumulation_steps=1,  # Adjust gradient accumulation\n","        max_grad_norm=0.5,  # Reduce gradient clipping\n","    )\n","\n","    # Define a compute_metrics function for multiple metrics\n","    # Define a compute_metrics function for multiple metrics\n","    def compute_metrics(p):\n","        predictions, labels = p\n","        # Ensure predictions are a tensor before applying torch.argmax\n","        predictions = torch.tensor(predictions) if isinstance(predictions, np.ndarray) else predictions\n","        predictions = torch.argmax(predictions, axis=-1)\n","\n","        # Calculate metrics\n","        accuracy = accuracy_score(labels, predictions)\n","        precision = precision_score(labels, predictions, average='weighted')\n","        recall = recall_score(labels, predictions, average='weighted')\n","        f1 = f1_score(labels, predictions, average='weighted')\n","\n","        return {\n","            'accuracy': accuracy,\n","            'precision': precision,\n","            'recall': recall,\n","            'f1': f1\n","        }\n","\n","\n","    # Initialize Trainer\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_datasets['train'],\n","        eval_dataset=tokenized_datasets['validation'],\n","        compute_metrics=compute_metrics\n","    )\n","\n","    # Train the model\n","    print(\"\\nüöÄ Starting training...\")\n","    trainer.train()\n","\n","    # Save the trained model\n","    trainer.save_model('./final_model')\n","\n","    # Evaluate on the test set manually\n","    print(\"\\nüöÄ Evaluating on the test dataset...\")\n","    results = trainer.evaluate(tokenized_datasets['test'])\n","    print(f\"Test Results: {results}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":802,"referenced_widgets":["96ca1b283c084a7a82a81f783d9afe47","13f033c841d740478e3f83c2c6c7afce","79cd2eedcf1948bd89125edfedd44f02","e206341ec3af43278eb2970e8441bc4d","10c2d00a00f24167abe18e9ee241c851","2cdbeea7f0934be697cba3e4d43742b0","8f0bd4e0937a4a76ab6543373eef863a","7c035ee8cc4c441892071fee7ec07f63","bc4562d221b2409fb060d455b1d9cc16","24836cad99b64c8e87bf9573d6765044","f8dfa86e7da0452f8f3f6ec2d0e3c56c","ac71f8b87b534edd8cabd98380637ad1","e31b7c80d115471da0d152e50b373af5","0835017442b841cfa7687cfb0b61bdea","8dd7476ad2f744db82649b73e54fab5c","692560f67b1c4f82822b788cf912491d","76d91ae635c5494dba4d75bb4776eabc","bc4402b9e4904f498508715b32ca3ec8","760a47d719604c2e9af5ca6400276329","5840ed16726d459ebb5243c9cb1a6b32","853b8a8e996646f981614f0481381586","52bd1d892f8143c49d467aaf7bd78ed9","2113bab311fa4da584ccc4aacbd50726","49cda0995d094898b0f27a097d9b4052","5e9957edccba4a72b61ea363d8d5eb3d","a30eba83c4214a40a151d3ba1695ba8d","d3dd4528c3194159a2f5672ed4016957","e73d585989924147b4019fae0fca6bae","438d16a9d4b74d62925ea4caeb2c4c5e","25b958daf2a149ae8af65c5b6b2a8ce0","c8039c119fd94e8386a288307ce443ea","fc104e5496ba400da62ef8a47f15b36a","4bb57b066d3e403283210f921548f319"]},"id":"7ilUTpDwy2iS","executionInfo":{"status":"error","timestamp":1761761525099,"user_tz":-120,"elapsed":796948,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"f3d3a944-6f7c-4d34-8fc8-6f9d5d839430"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of Gemma3TextForSequenceClassification were not initialized from the model checkpoint at google/gemma-3-1b-it and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6472 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96ca1b283c084a7a82a81f783d9afe47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2698 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac71f8b87b534edd8cabd98380637ad1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/675 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2113bab311fa4da584ccc4aacbd50726"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","üöÄ Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1184' max='4050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1184/4050 13:03 < 31:39, 1.51 it/s, Epoch 2.92/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>3.561200</td>\n","      <td>7.025692</td>\n","      <td>0.001481</td>\n","      <td>0.000049</td>\n","      <td>0.001481</td>\n","      <td>0.000096</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.472600</td>\n","      <td>7.084282</td>\n","      <td>0.005926</td>\n","      <td>0.000035</td>\n","      <td>0.005926</td>\n","      <td>0.000070</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1728849381.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüöÄ Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# Save the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     )\n\u001b[1;32m   2673\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4020\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4022\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   4108\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4109\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4110\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4111\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTransformersKwargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     ) -> SequenceClassifierOutputWithPast:\n\u001b[0;32m--> 124\u001b[0;31m         transformer_outputs: BaseModelOutputWithPast = getattr(self, self.base_model_prefix)(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_embeddings_global\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/gemma3/modeling_gemma3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_feedforward_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_feedforward_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1947\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"IhaKwi70y39L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Longformer"],"metadata":{"id":"hRhE8endrYMo"}},{"cell_type":"code","source":["# ============================================================================\n","# STEP 1: Install Required Libraries\n","# ============================================================================\n","print(\"üì¶ Installing required libraries...\")\n","!pip install -q transformers datasets openpyxl scikit-learn huggingface_hub\n","\n","# ============================================================================\n","# STEP 2: Import Libraries\n","# ============================================================================\n","import os\n","import pandas as pd\n","import torch\n","from google.colab import files, userdata\n","from transformers import LongformerTokenizer, LongformerForSequenceClassification, TrainingArguments, Trainer\n","from datasets import Dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","\n","\n","# ============================================================================\n","# STEP 3: Check if the Files are Uploaded\n","# ============================================================================\n","if not os.path.exists('/mnt/data/train.xlsx') or not os.path.exists('/mnt/data/test.xlsx'):\n","    print(\"üìÅ Please upload the training and test Excel files...\")\n","    train_uploaded = files.upload()\n","    test_uploaded = files.upload()\n","else:\n","    print(\"‚úÖ Files already uploaded!\")\n","\n","# ============================================================================\n","# STEP 4: Load Data from Excel Files\n","# ============================================================================\n","train_df = pd.read_excel('/content/train.xlsx')\n","test_df = pd.read_excel('/content/test.xlsx')\n","\n","print(f\"‚úÖ Training data shape: {train_df.shape}\")\n","print(f\"‚úÖ Test data shape: {test_df.shape}\")\n","\n","# Inspect the first few rows to ensure data is loaded correctly\n","print(\"\\nüìã Training data preview:\")\n","print(train_df.head())\n","print(\"\\nüìã Test data preview:\")\n","print(test_df.head())\n","\n","# ============================================================================\n","# STEP 5: Process Labels\n","# ============================================================================\n","print(\"\\nüè∑Ô∏è Processing labels...\")\n","\n","# Ensure columns 'input' and 'output' are present in your dataset\n","def extract_label(output_text):\n","    \"\"\"Extract NEDA or EDA from output text\"\"\"\n","    output_text = str(output_text).upper()\n","    if 'NEDA' in output_text:\n","        return 'NEDA'\n","    elif 'EDA' in output_text:\n","        return 'EDA'\n","    else:\n","        return None\n","\n","# Apply label extraction\n","train_df['label_text'] = train_df['output'].apply(extract_label)\n","test_df['label_text'] = test_df['output'].apply(extract_label)\n","\n","# Remove rows with None labels\n","train_df = train_df[train_df['label_text'].notna()].reset_index(drop=True)\n","test_df = test_df[test_df['label_text'].notna()].reset_index(drop=True)\n","\n","# Create label mapping\n","label2id = {'NEDA': 0, 'EDA': 1}\n","id2label = {0: 'NEDA', 1: 'EDA'}\n","\n","# Convert to numeric labels\n","train_df['label'] = train_df['label_text'].map(label2id)\n","test_df['label'] = test_df['label_text'].map(label2id)\n","\n","print(f\"‚úÖ Labels extracted successfully!\")\n","print(f\"üìä Training set after label extraction: {len(train_df)} samples\")\n","print(f\"üìä Test set after label extraction: {len(test_df)} samples\")\n","\n","# ============================================================================\n","# STEP 6: Train-Test Split (for Validation)\n","# ============================================================================\n","print(\"\\nüìä Splitting training data into training and validation sets...\")\n","\n","train_dataset, val_dataset = train_test_split(train_df, test_size=0.1, random_state=42)\n","\n","# Convert to Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(train_dataset[['input', 'label']])\n","val_dataset = Dataset.from_pandas(val_dataset[['input', 'label']])\n","test_dataset = Dataset.from_pandas(test_df[['input', 'label']])\n","\n","# ============================================================================\n","# STEP 7: Initialize Tokenizer and Model (Longformer)\n","# ============================================================================\n","print(\"\\nü§ñ Loading Longformer model and tokenizer...\")\n","\n","MODEL_NAME = \"allenai/longformer-base-4096\"\n","\n","tokenizer = LongformerTokenizer.from_pretrained(MODEL_NAME)\n","model = LongformerForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2,\n","    id2label=id2label,\n","    label2id=label2id\n",")\n","\n","# Count parameters\n","n_params = sum(p.numel() for p in model.parameters())\n","print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n","print(f\"‚úÖ Number of parameters: {n_params:,}\")\n","\n","# ============================================================================\n","# STEP 8: Tokenize Data\n","# ============================================================================\n","print(\"\\nüî§ Tokenizing data...\")\n","\n","def tokenize_function(examples):\n","    \"\"\"Tokenize input texts\"\"\"\n","    return tokenizer(\n","        examples['input'],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=1024   # Longformer-friendly max length\n","    )\n","\n","# Tokenize datasets\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","val_dataset = val_dataset.map(tokenize_function, batched=True)\n","test_dataset = test_dataset.map(tokenize_function, batched=True)\n","\n","# Set format for PyTorch\n","train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n","\n","print(f\"‚úÖ Training dataset: {len(train_dataset)} samples\")\n","print(f\"‚úÖ Validation dataset: {len(val_dataset)} samples\")\n","print(f\"‚úÖ Test dataset: {len(test_dataset)} samples\")\n","\n","# ============================================================================\n","# STEP 9: Define Evaluation Metrics\n","# ============================================================================\n","print(\"\\nüìä Setting up evaluation metrics...\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"Compute metrics for evaluation\"\"\"\n","    logits, labels = eval_pred\n","\n","    # Convert logits to tensor (if they are numpy arrays)\n","    logits = torch.tensor(logits) if isinstance(logits, np.ndarray) else logits\n","\n","    # Get predictions by applying argmax on logits\n","    predictions = torch.argmax(logits, axis=-1)\n","\n","    # Compute accuracy, precision, recall, and F1 score\n","    accuracy = accuracy_score(labels, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        labels, predictions, average='binary', zero_division=0\n","    )\n","    cm = confusion_matrix(labels, predictions)\n","\n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'confusion_matrix': cm.tolist()\n","    }\n","\n","\n","print(\"‚úÖ Evaluation metrics configured!\")\n","\n","# ============================================================================\n","# STEP 10: Setup Training Arguments\n","# ============================================================================\n","print(\"\\n‚öôÔ∏è Configuring training arguments...\")\n","\n","# Adjusted batch size and sequence length\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=4,  # Reduced batch size\n","    per_device_eval_batch_size=4,   # Reduced eval batch size\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',  # Disable wandb/tensorboard\n","    push_to_hub=False,  # Set to True if you want to push to Hub\n","    optim='adamw_torch',  # Use AdamW optimizer (Adam with weight decay)\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    fp16=True,  # Enable mixed precision\n","    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps\n",")\n","\n","print(\"‚úÖ Training arguments configured!\")\n","\n","# ============================================================================\n","# STEP 11: Initialize Trainer\n","# ============================================================================\n","print(\"\\nüéØ Initializing Trainer...\")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n","\n","print(\"‚úÖ Trainer initialized successfully!\")\n","\n","# ============================================================================\n","# STEP 12: Train the Model\n","# ============================================================================\n","print(\"\\nüöÄ Starting training...\")\n","\n","train_result = trainer.train()\n","\n","print(\"\\n‚úÖ Training completed!\")\n","print(f\"üìä Training Loss: {train_result.training_loss:.4f}\")\n","print(f\"‚è±Ô∏è Training Time: {train_result.metrics['train_runtime']:.2f} seconds\")\n","\n","# ============================================================================\n","# STEP 13: Evaluate on Test Set\n","# ============================================================================\n","print(\"\\nüìà Evaluating on test set...\")\n","\n","eval_results = trainer.evaluate()\n","\n","print(\"\\nüìä EVALUATION RESULTS\")\n","print(f\"‚úÖ Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n","print(f\"‚úÖ Precision: {eval_results['eval_precision']:.4f}\")\n","print(f\"‚úÖ Recall:    {eval_results['eval_recall']:.4f}\")\n","print(f\"‚úÖ F1 Score:  {eval_results['eval_f1']:.4f}\")\n","print(f\"üéØ Confusion Matrix:\")\n","print(f\"   {eval_results['eval_confusion_matrix']}\")\n","\n","# ============================================================================\n","# STEP 14: Save Model\n","# ============================================================================\n","print(\"\\nüíæ Saving fine-tuned model...\")\n","\n","model_save_path = './longformer_neda_eda_classifier'\n","trainer.save_model(model_save_path)\n","tokenizer.save_pretrained(model_save_path)\n","\n","print(f\"‚úÖ Model saved to: {model_save_path}\")\n","\n","# ============================================================================\n","# STEP 15: Download Trained Model\n","# ============================================================================\n","print(\"\\nüíæ Would you like to download the trained model? (y/n)\")\n","download_choice = input().lower().strip()\n","\n","if download_choice == 'y':\n","    print(\"\\nüì¶ Creating zip file...\")\n","    !zip -r longformer_neda_eda_classifier.zip {model_save_path}\n","    print(\"‚¨áÔ∏è Downloading model...\")\n","    files.download('longformer_neda_eda_classifier.zip')\n","    print(\"‚úÖ Model downloaded successfully!\")\n","\n","print(\"\\nüéâ ALL DONE!\")\n"],"metadata":{"id":"BzQ_Z2VArqwo","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a13a134f4f7943ea9a8c6c7892ccc4ad","19f28320fd0a400d8cc3d08b48525d23","5b7f4cc4e40a4c47bfca13e1a9b9456c","9bf2e91711944ead9209393dea7dd1e4","8b670280d6734605861cebeda9b7b7e6","46fbe78a495940b7a376785891e1449b","0d558a87bf34466794a6ceab466ddb85","7e74fd49f1fb4e938513845b0de1bec8","ea37c4d5817245f5a9837afc906e261d","d5212295356c4288ad0646c0b42dc839","4f6d7a050e514240b6d4347d9d89dc35","9da224e587db4d36a657544c14bfcec0","9826b8835a0545c9b158d47e9f861803","bd3e318741194404bd10935474c2cda4","ff17767b662449e09909a09eef82515c","432058237fa1472a9bd1f57e913584a2","1d8fa3e44ff943a1bfe96d9a2ca0f718","a9578929340748728ff15584706d92fe","82e7abbf9ed2467ab597aa8ff7beed0d","bdc58993bb7c483abbbb933b07c2860f","9982e2b35f6b4984a1af301f7377862a","61ab039e52df44fca5f334775c339f71","a8bed90029724e2aa9ba8b231e53337c","4c51d04bc1174a19ae6778a457b5a626","8c5d193505254dbd8a11a72be462137b","4734f0b2a8474661bebb23c8ee559d5c","f1548c9bace044e2b0198023b9ea91a6","f9667110c11d46f893864dba96f65d45","ef91122b292440a6a7e3814d2bcdc039","35c4b6e45cc4444b8601b6e6a472134b","9210a51dffdf4b29b14379c0e1d99cba","cc52b889a7924b8f898922f77a14d348","96587e21cab64cefbf18ccbe4313a00e"]},"executionInfo":{"status":"ok","timestamp":1761852680532,"user_tz":-120,"elapsed":11264319,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"86732159-855f-40bc-e741-201bbd36576f","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ Installing required libraries...\n","üìÅ Please upload the training and test Excel files...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-994416f9-ea03-44d3-b3ee-ca09bb4ff6e0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-994416f9-ea03-44d3-b3ee-ca09bb4ff6e0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-9a9d8ed1-6f2b-492c-ae7c-6834c12f2801\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-9a9d8ed1-6f2b-492c-ae7c-6834c12f2801\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Training data shape: (6472, 3)\n","‚úÖ Test data shape: (3373, 3)\n","\n","üìã Training data preview:\n","   MSC research database ID  \\\n","0                         1   \n","1                         1   \n","2                         1   \n","3                         1   \n","4                         1   \n","\n","                                               input  \\\n","0  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","1  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","2  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","3  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","4  Age:31.  Gender:female.  Diagnosis:rrms. Has n...   \n","\n","                                        output  \n","0  After 7 months the patient will be in NEDA.  \n","1   After 7 months the patient will be in EDA.  \n","2   After 0 months the patient will be in EDA.  \n","3   After 4 months the patient will be in EDA.  \n","4  After 6 months the patient will be in NEDA.  \n","\n","üìã Test data preview:\n","   MSC research database ID  \\\n","0                         7   \n","1                         7   \n","2                         7   \n","3                         7   \n","4                         7   \n","\n","                                               input  \\\n","0  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","1  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","2  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","3  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","4  Age:54.  Gender:female.  Diagnosis:spms. Conve...   \n","\n","                                        output  \n","0  After 9 months the patient will be in NEDA.  \n","1  After 6 months the patient will be in NEDA.  \n","2  After 5 months the patient will be in NEDA.  \n","3  After 6 months the patient will be in NEDA.  \n","4  After 6 months the patient will be in NEDA.  \n","\n","üè∑Ô∏è Processing labels...\n","‚úÖ Labels extracted successfully!\n","üìä Training set after label extraction: 6472 samples\n","üìä Test set after label extraction: 3373 samples\n","\n","üìä Splitting training data into training and validation sets...\n","\n","ü§ñ Loading Longformer model and tokenizer...\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Model loaded: allenai/longformer-base-4096\n","‚úÖ Number of parameters: 148,660,994\n","\n","üî§ Tokenizing data...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5824 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13a134f4f7943ea9a8c6c7892ccc4ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/648 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9da224e587db4d36a657544c14bfcec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8bed90029724e2aa9ba8b231e53337c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Training dataset: 5824 samples\n","‚úÖ Validation dataset: 648 samples\n","‚úÖ Test dataset: 3373 samples\n","\n","üìä Setting up evaluation metrics...\n","‚úÖ Evaluation metrics configured!\n","\n","‚öôÔ∏è Configuring training arguments...\n","‚úÖ Training arguments configured!\n","\n","üéØ Initializing Trainer...\n","‚úÖ Trainer initialized successfully!\n","\n","üöÄ Starting training...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='21840' max='21840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [21840/21840 3:05:50, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Confusion Matrix</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.476500</td>\n","      <td>0.619023</td>\n","      <td>0.736111</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[477, 0], [171, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.523700</td>\n","      <td>0.555857</td>\n","      <td>0.733025</td>\n","      <td>0.375000</td>\n","      <td>0.017544</td>\n","      <td>0.033520</td>\n","      <td>[[472, 5], [168, 3]]</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.477700</td>\n","      <td>0.572686</td>\n","      <td>0.734568</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[476, 1], [171, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.589000</td>\n","      <td>0.564108</td>\n","      <td>0.731481</td>\n","      <td>0.434783</td>\n","      <td>0.058480</td>\n","      <td>0.103093</td>\n","      <td>[[464, 13], [161, 10]]</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.553900</td>\n","      <td>0.581070</td>\n","      <td>0.736111</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>[[477, 0], [171, 0]]</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.480300</td>\n","      <td>0.568499</td>\n","      <td>0.734568</td>\n","      <td>0.466667</td>\n","      <td>0.040936</td>\n","      <td>0.075269</td>\n","      <td>[[469, 8], [164, 7]]</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.473600</td>\n","      <td>0.591706</td>\n","      <td>0.734568</td>\n","      <td>0.466667</td>\n","      <td>0.040936</td>\n","      <td>0.075269</td>\n","      <td>[[469, 8], [164, 7]]</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.558000</td>\n","      <td>0.563879</td>\n","      <td>0.742284</td>\n","      <td>0.543478</td>\n","      <td>0.146199</td>\n","      <td>0.230415</td>\n","      <td>[[456, 21], [146, 25]]</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.291400</td>\n","      <td>0.647210</td>\n","      <td>0.736111</td>\n","      <td>0.500000</td>\n","      <td>0.040936</td>\n","      <td>0.075676</td>\n","      <td>[[470, 7], [164, 7]]</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.481000</td>\n","      <td>0.555791</td>\n","      <td>0.734568</td>\n","      <td>0.466667</td>\n","      <td>0.040936</td>\n","      <td>0.075269</td>\n","      <td>[[469, 8], [164, 7]]</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.504700</td>\n","      <td>0.587451</td>\n","      <td>0.742284</td>\n","      <td>0.600000</td>\n","      <td>0.070175</td>\n","      <td>0.125654</td>\n","      <td>[[469, 8], [159, 12]]</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.447900</td>\n","      <td>0.576630</td>\n","      <td>0.737654</td>\n","      <td>0.516129</td>\n","      <td>0.093567</td>\n","      <td>0.158416</td>\n","      <td>[[462, 15], [155, 16]]</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.399800</td>\n","      <td>0.614759</td>\n","      <td>0.731481</td>\n","      <td>0.476190</td>\n","      <td>0.175439</td>\n","      <td>0.256410</td>\n","      <td>[[444, 33], [141, 30]]</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.435900</td>\n","      <td>0.632397</td>\n","      <td>0.745370</td>\n","      <td>0.593750</td>\n","      <td>0.111111</td>\n","      <td>0.187192</td>\n","      <td>[[464, 13], [152, 19]]</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.342700</td>\n","      <td>0.678713</td>\n","      <td>0.739198</td>\n","      <td>0.511628</td>\n","      <td>0.257310</td>\n","      <td>0.342412</td>\n","      <td>[[435, 42], [127, 44]]</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.456500</td>\n","      <td>0.704780</td>\n","      <td>0.722222</td>\n","      <td>0.432836</td>\n","      <td>0.169591</td>\n","      <td>0.243697</td>\n","      <td>[[439, 38], [142, 29]]</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.372100</td>\n","      <td>0.652690</td>\n","      <td>0.720679</td>\n","      <td>0.424242</td>\n","      <td>0.163743</td>\n","      <td>0.236287</td>\n","      <td>[[439, 38], [143, 28]]</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.501000</td>\n","      <td>0.724259</td>\n","      <td>0.722222</td>\n","      <td>0.441558</td>\n","      <td>0.198830</td>\n","      <td>0.274194</td>\n","      <td>[[434, 43], [137, 34]]</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.419100</td>\n","      <td>0.758719</td>\n","      <td>0.716049</td>\n","      <td>0.435644</td>\n","      <td>0.257310</td>\n","      <td>0.323529</td>\n","      <td>[[420, 57], [127, 44]]</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.356400</td>\n","      <td>0.930416</td>\n","      <td>0.699074</td>\n","      <td>0.380000</td>\n","      <td>0.222222</td>\n","      <td>0.280443</td>\n","      <td>[[415, 62], [133, 38]]</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.360900</td>\n","      <td>0.911304</td>\n","      <td>0.725309</td>\n","      <td>0.459770</td>\n","      <td>0.233918</td>\n","      <td>0.310078</td>\n","      <td>[[430, 47], [131, 40]]</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.225000</td>\n","      <td>1.009799</td>\n","      <td>0.714506</td>\n","      <td>0.431373</td>\n","      <td>0.257310</td>\n","      <td>0.322344</td>\n","      <td>[[419, 58], [127, 44]]</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.439800</td>\n","      <td>1.042921</td>\n","      <td>0.722222</td>\n","      <td>0.448276</td>\n","      <td>0.228070</td>\n","      <td>0.302326</td>\n","      <td>[[429, 48], [132, 39]]</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.344700</td>\n","      <td>1.016841</td>\n","      <td>0.722222</td>\n","      <td>0.450549</td>\n","      <td>0.239766</td>\n","      <td>0.312977</td>\n","      <td>[[427, 50], [130, 41]]</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.510100</td>\n","      <td>1.009258</td>\n","      <td>0.731481</td>\n","      <td>0.484536</td>\n","      <td>0.274854</td>\n","      <td>0.350746</td>\n","      <td>[[427, 50], [124, 47]]</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.324600</td>\n","      <td>1.141049</td>\n","      <td>0.728395</td>\n","      <td>0.474747</td>\n","      <td>0.274854</td>\n","      <td>0.348148</td>\n","      <td>[[425, 52], [124, 47]]</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.292000</td>\n","      <td>1.170724</td>\n","      <td>0.722222</td>\n","      <td>0.448276</td>\n","      <td>0.228070</td>\n","      <td>0.302326</td>\n","      <td>[[429, 48], [132, 39]]</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.378600</td>\n","      <td>1.286574</td>\n","      <td>0.719136</td>\n","      <td>0.442105</td>\n","      <td>0.245614</td>\n","      <td>0.315789</td>\n","      <td>[[424, 53], [129, 42]]</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.508500</td>\n","      <td>1.394640</td>\n","      <td>0.709877</td>\n","      <td>0.412371</td>\n","      <td>0.233918</td>\n","      <td>0.298507</td>\n","      <td>[[420, 57], [131, 40]]</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.306900</td>\n","      <td>1.377478</td>\n","      <td>0.711420</td>\n","      <td>0.421569</td>\n","      <td>0.251462</td>\n","      <td>0.315018</td>\n","      <td>[[418, 59], [128, 43]]</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ Training completed!\n","üìä Training Loss: 0.4215\n","‚è±Ô∏è Training Time: 11151.35 seconds\n","\n","üìà Evaluating on test set...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [162/162 00:13]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","üìä EVALUATION RESULTS\n","‚úÖ Accuracy:  0.7315\n","‚úÖ Precision: 0.4845\n","‚úÖ Recall:    0.2749\n","‚úÖ F1 Score:  0.3507\n","üéØ Confusion Matrix:\n","   [[427, 50], [124, 47]]\n","\n","üíæ Saving fine-tuned model...\n","‚úÖ Model saved to: ./longformer_neda_eda_classifier\n","\n","üíæ Would you like to download the trained model? (y/n)\n","n\n","\n","üéâ ALL DONE!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yG4CllDn1CXI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##T5"],"metadata":{"id":"5AjT5XVOnsm9"}},{"cell_type":"code","source":["# Install the necessary libraries\n","!pip install transformers datasets evaluate huggingface_hub\n","\n","# Import required libraries\n","import torch\n","from datasets import Dataset\n","from transformers import (\n","    T5ForConditionalGeneration,\n","    T5Tokenizer,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorForSeq2Seq,\n",")\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","import pandas as pd\n","import os\n","from huggingface_hub import login\n","from google.colab import userdata\n","import gc\n","\n","# --- Authentication using Hugging Face Token ---\n","hf_token = userdata.get('HF_TOKEN')  # Assuming your HF_TOKEN is saved in Colab's secret storage\n","\n","if hf_token:\n","    login(token=hf_token)  # Login using the Hugging Face token\n","else:\n","    print(\"Hugging Face token not found!\")\n","\n","# --- LOAD DATA ---\n","train_data = pd.read_excel('/content/train.xlsx')  # Replace with your correct file path\n","test_data = pd.read_excel('/content/test.xlsx')  # Replace with your correct file path\n","\n","# --- PREPROCESS ---\n","def preprocess_data(df):\n","    return pd.DataFrame({\n","        'input_text': df['input'],\n","        'labels': df['output'].apply(lambda x: 'EDA' if 'EDA' in x else 'NEDA')  # Use text labels for T5\n","    })\n","\n","train_df = preprocess_data(train_data)\n","test_df = preprocess_data(test_data)\n","\n","train_dataset = Dataset.from_pandas(train_df)\n","test_dataset = Dataset.from_pandas(test_df)\n","\n","split = train_dataset.train_test_split(test_size=0.2)\n","train_dataset, val_dataset = split[\"train\"], split[\"test\"]\n","\n","# --- TOKENIZER ---\n","tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")  # Corrected model path\n","\n","def tokenize_fn(batch):\n","    inputs = tokenizer(batch['input_text'], padding=\"max_length\", truncation=True, max_length=128)  # Reduced max_length\n","    labels = tokenizer(batch['labels'], padding=\"max_length\", truncation=True, max_length=128)  # Reduced max_length\n","    inputs['labels'] = labels['input_ids']  # Set the 'labels' to the tokenized labels\n","    return inputs\n","\n","train_dataset = train_dataset.map(tokenize_fn, batched=True)\n","val_dataset = val_dataset.map(tokenize_fn, batched=True)\n","test_dataset = test_dataset.map(tokenize_fn, batched=True)\n","\n","# --- MODEL ---\n","model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")  # Corrected model path\n","\n","# --- DATA COLLATOR ---\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# --- METRICS ---\n","def compute_metrics(eval_pred):\n","    preds, labels = eval_pred\n","    preds = torch.argmax(torch.tensor(preds), dim=-1)[:, 0]  # Get the first token prediction for classification\n","    accuracy = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","# --- TRAINING ARGS ---\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',  # We evaluate every epoch now\n","    save_strategy='epoch',  # Save after every epoch\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=1,  # Adjusted to 1 to fit in memory\n","    per_device_eval_batch_size=1,   # Adjusted to 1 to fit in memory\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',  # Disable wandb/tensorboard\n","    push_to_hub=False,  # Set to True if you want to push to Hugging Face Hub\n","    optim='adamw_torch',  # Use AdamW optimizer (Adam with weight decay)\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    fp16=True,  # Enable mixed precision\n","    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps\n",")\n","\n","# --- TRAINER ---\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# --- CLEAR GPU CACHE BEFORE TRAIN ---\n","torch.cuda.empty_cache()  # Clear GPU cache\n","gc.collect()  # Collect unreferenced memory\n","\n","# --- TRAIN ---\n","trainer.train()\n","\n","# --- EVALUATE ---\n","test_results = trainer.evaluate(test_dataset)\n","print(test_results)\n","\n","# --- SAVE MODEL ---\n","model.save_pretrained(\"./fine_tuned_t5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["837886731ea04534a86fd85e0de37b6e","1e60075fca014d838c533e50d449ed73","89a1c91b4bfe4e5b81a7f5fd3bad88ee","668a6dabbc2944c59bb8dbb8e9559567","2ee72180977b4db2a42199f576d5bb7b","ee726db9030c41a5a076bef331a462c0","847d659bb21848798b104d6fb4d4e017","b6c78f71e23b4a77bc9502070b1124c4","4b62c45f9006438186917e27b5c9f997","a03371509521479dbb9379dc258afc55","f7ab4769cd7442db94438d6d6dee3af5","dd57684582d24cceb95ca0f9325c7fc8","4032f30663794fb3a82243c4b483a7da","5184eb9752c945a2b39ddc6a778d9152","9299fc98af544a758e488e01349a4322","7f686aeb2e8f4a2d9989e2783c0af69e","9c235a1d20c54e5fa8b454344671cd62","fa8222d671ce47b0a4045869a8eb15f7","11522d6ff089459ca0b0a5d26042c4bb","df8045306eeb44029be486e281e91ba4","fd02d84ea9b44c678d836bdb09bddb59","bc31083d46d54e129977ce7f78781383","a32522a8fe814b2a9398024698e0bed5","2fc775cf8d504e909e31410eb2ab5c8e","864e450fcfc143698009794f5ce5b49f","4f4b2c5f21ae4684a5727f53775de045","54065d06e88940359f124964865d166b","7d347658e21849618d0057bf8ef8282a","e0b523232a3346d48d828c1fcec93e3b","4608845377d64143890623216e7b2f92","149cff8f3dcc419b8d6bcc3d8fe306be","200882a929fd48f9909b85e2d3fbaad2","effcc51be37e4890ab161518845e9e00","c34e654d9e954c44b1a410295a7585de","7e34b836fc374d7bb09c9b06d1fb4c1f","bac4819e46e043b6b0069033a08e5831","7f1f577fae1a4457b5e09edd15e70fa5","d95d9525ff8a4424a65564de31f7487a","fef65a4a16674066bd4bbacbaa766a5c","e95c4bdc31794407922e06e3233a5dbd","7e32b1a39e7e43b89bf276612955e3b1","8c70723e335e40e2959e5733cc55d661","c39036a97c384e558498af94ab7db98d","06b72903d2464d1ab021d697824fa9cf","779361e4f7d649d2b32a16e5985b2677","e0e495662dfe4853a250c594a18c20b4","d6bcb71a408e4c13aaf9397c8300b9da","5e12edd539a64f6b8763d5452d4b50b8","c6881bc2b8f5428d9ecec1b272614795","b004a075b8f54942916458fb8474de9f","284637d9ccf7498d8e3e994779de455f","9e49c3cb75f946e29f0376bc738f6fb5","bc7219b6a0c2458384589df0f7227a4a","fd833771ee944d15beaa811f4d2f633e","c297a1fd793440bc8f261c9b2eab8f0a","cf9c9fbc56914aaeae651b59b9ddd920","5704321149554d8ab2320b1455fa728f","531a5feac20445e3a1c41d829dce40d4","921ce617e7154da69631bdd7d1002adf","d0162fd3274c492a8517e625f63ad005","070dbe2248b14699be6e8402c9e3b65e","fee1f3a5b6454d96aa2526bc29a53e78","3ef3a83848ce4f0ab73f4c8791079de6","65e8d5598cd2439ea5f1cc87cd7e8e0b","2274072634394ce99cd5aa2b62f14c4e","db130e7af4454f849882f0b42be1cb76","190f6dd4cc2e45bfb27ead7212f86500","5b973bf6035f404d9dceca301f5b1f71","8d9fff6fd8fd4a5d8f5397b4652a7f97","79eccd030c0f4d898d1dbc12a088f5b6","6bec665b2f2c454895e110ed1127ee1a","3681235850b5462890754fd67805b6ec","592c80bf9e8c4e388164bc8bd411373d","993320e62ac74cb58935fdaa06e56769","faf5acf2da5d4e1598e50cee9b42c679","ad8c47aedf004f078a7c01c3e85060c8","05abd1e9fd0643ffbce0c664b0a4bd87","6c71b56e4d134b84a0e39839c6197ff1","a19e00a074ef44efad41a918ad3c550e","f52658795bce4b978510586190f576fc","78dbd1306b0a416da49da9f454fa1fed","0d21ba244af04367913d9cf4a55bf6c0","e05ba2ab586b4382ac790a8710cbde32","f5934522ca1644e0bd6db212f1f53cf6","a22fa68b8b3f40ed82a6d163feee7dac","9e9636781ea24bd4a20e30c92fbfff26","e49fded42a1b485b837d8eac290eca5b","09b160e03f124d37ad3cf354fb49f3d0","dd58077164124b5d960e797aa4614bdf","8a200b7086ac4faf988b8e6942c91d55","43bad56de5974313b595d2281f4e48d7","68c9b20f4ee64947a273ea6e2c1028d3","ca25eb32a33742d494421306e8e30df2","617f57c01c9943abb8474612ced1bafd","969bf95783544ad69ba0bbf728eb63d2","d0af500c9870452d926e2302316a69eb","56010cda6ab74cf2a3d56e28b772b6d1","dfbc2886cbd14320b330140b89855b09","371f0c6ac5d4499c8e856607a09dc795"]},"id":"mrXAqhGxntsR","executionInfo":{"status":"error","timestamp":1762515716021,"user_tz":-120,"elapsed":748325,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"e4015ca8-c74f-4295-cd84-86002aee9d7d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"837886731ea04534a86fd85e0de37b6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd57684582d24cceb95ca0f9325c7fc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a32522a8fe814b2a9398024698e0bed5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5177 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c34e654d9e954c44b1a410295a7585de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1295 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779361e4f7d649d2b32a16e5985b2677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf9c9fbc56914aaeae651b59b9ddd920"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"190f6dd4cc2e45bfb27ead7212f86500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c71b56e4d134b84a0e39839c6197ff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd58077164124b5d960e797aa4614bdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2590' max='77670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 2590/77670 06:00 < 2:54:27, 7.17 it/s, Epoch 1/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='1215' max='1295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1215/1295 06:05 < 00:24, 3.32 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 18.63 GiB. GPU 0 has a total capacity of 39.56 GiB of which 18.62 GiB is free. Process 17776 has 20.93 GiB memory in use. Of the allocated memory 19.62 GiB is allocated by PyTorch, and 826.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2194320562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# --- TRAIN ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# --- EVALUATE ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2791\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4710\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_eval_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4712\u001b[0;31m                     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4714\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         return type(tensors)(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Let's figure out the new shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.63 GiB. GPU 0 has a total capacity of 39.56 GiB of which 18.62 GiB is free. Process 17776 has 20.93 GiB memory in use. Of the allocated memory 19.62 GiB is allocated by PyTorch, and 826.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"markdown","source":["###T5-Small with LoRA"],"metadata":{"id":"nJVNNJYX2X-2"}},{"cell_type":"code","source":["# Install necessary libraries\n","!pip install transformers datasets evaluate huggingface_hub peft bitsandbytes accelerate\n","\n","# Import required libraries\n","import torch\n","from datasets import Dataset\n","from transformers import (\n","    T5ForConditionalGeneration,\n","    T5Tokenizer,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorForSeq2Seq,\n","    BitsAndBytesConfig,\n","    TrainerCallback,\n",")\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","import pandas as pd\n","import os\n","from huggingface_hub import login\n","from google.colab import userdata\n","import gc\n","from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n","\n","# --- Authentication using Hugging Face Token ---\n","hf_token = userdata.get('HF_TOKEN')\n","\n","if hf_token:\n","    login(token=hf_token)\n","else:\n","    print(\"Hugging Face token not found!\")\n","\n","# --- LOAD DATA ---\n","train_data = pd.read_excel('/content/train.xlsx')\n","test_data = pd.read_excel('/content/test.xlsx')\n","\n","# --- PREPROCESS ---\n","def preprocess_data(df):\n","    return pd.DataFrame({\n","        'input_text': df['input'],\n","        'labels': df['output'].apply(lambda x: 'EDA' if 'EDA' in x else 'NEDA')\n","    })\n","\n","train_df = preprocess_data(train_data)\n","test_df = preprocess_data(test_data)\n","\n","train_dataset = Dataset.from_pandas(train_df)\n","test_dataset = Dataset.from_pandas(test_df)\n","\n","split = train_dataset.train_test_split(test_size=0.2)\n","train_dataset, val_dataset = split[\"train\"], split[\"test\"]\n","\n","# --- TOKENIZER ---\n","tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n","\n","def tokenize_fn(batch):\n","    inputs = tokenizer(\n","        batch['input_text'],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=128\n","    )\n","    labels = tokenizer(\n","        batch['labels'],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=128\n","    )\n","    # Replace padding token ids with -100 so they're ignored in loss\n","    labels['input_ids'] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in label]\n","        for label in labels['input_ids']\n","    ]\n","    inputs['labels'] = labels['input_ids']\n","    return inputs\n","\n","train_dataset = train_dataset.map(tokenize_fn, batched=True)\n","val_dataset = val_dataset.map(tokenize_fn, batched=True)\n","test_dataset = test_dataset.map(tokenize_fn, batched=True)\n","\n","# --- QLoRA Configuration ---\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16  # Changed to bfloat16 for better stability\n",")\n","\n","# --- MODEL ---\n","model = T5ForConditionalGeneration.from_pretrained(\n","    \"google-t5/t5-small\",\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")\n","\n","# Prepare model for k-bit training (CRITICAL for QLoRA)\n","model = prepare_model_for_kbit_training(model)\n","\n","# Configure LoRA\n","lora_config = LoraConfig(\n","    r=8,  # Increased for better performance\n","    lora_alpha=32,  # 4x the rank\n","    target_modules=[\"q\", \"v\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=TaskType.SEQ_2_SEQ_LM\n",")\n","\n","# Apply LoRA to the model\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()\n","\n","# --- DATA COLLATOR ---\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# --- METRICS ---\n","def compute_metrics(eval_pred):\n","    preds, labels = eval_pred\n","\n","    # Replace -100 with pad_token_id for decoding\n","    preds = [[token if token != -100 else tokenizer.pad_token_id for token in pred] for pred in preds]\n","    labels = [[token if token != -100 else tokenizer.pad_token_id for token in label] for label in labels]\n","\n","    # Decode predictions\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Convert to binary (EDA=1, NEDA=0)\n","    pred_binary = [1 if 'EDA' in pred.upper() else 0 for pred in decoded_preds]\n","    label_binary = [1 if 'EDA' in label.upper() else 0 for label in decoded_labels]\n","\n","    accuracy = accuracy_score(label_binary, pred_binary)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        label_binary, pred_binary, average='binary', zero_division=0\n","    )\n","    return {\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1\n","    }\n","\n","# --- MEMORY CLEANUP CALLBACK ---\n","class MemoryCleanupCallback(TrainerCallback):\n","    def on_epoch_end(self, args, state, control, **kwargs):\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","# --- TRAINING ARGS ---\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=3e-4,  # Higher LR for LoRA\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=8,  # Can be higher for eval\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',\n","    push_to_hub=False,\n","    optim='adamw_torch',\n","    fp16=False,\n","    bf16=True,  # Use bf16 with quantization\n","    gradient_accumulation_steps=2,\n","    gradient_checkpointing=False,  # DISABLED - incompatible with quantized models\n","    max_grad_norm=1.0,\n","    dataloader_pin_memory=True,\n","    dataloader_num_workers=2,\n","    warmup_steps=100,  # Added warmup\n",")\n","\n","# --- TRAINER ---\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    callbacks=[MemoryCleanupCallback()],\n",")\n","\n","# --- CLEAR GPU CACHE BEFORE TRAIN ---\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","# --- TRAIN ---\n","print(\"Starting training...\")\n","trainer.train()\n","\n","# --- EVALUATE ---\n","print(\"\\nEvaluating on test set...\")\n","test_results = trainer.evaluate(test_dataset)\n","print(test_results)\n","\n","# --- SAVE MODEL ---\n","print(\"\\nSaving model...\")\n","model.save_pretrained(\"./fine_tuned_t5_lora\")\n","tokenizer.save_pretrained(\"./fine_tuned_t5_lora\")\n","print(\"Training complete!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e1a3b707e7de4a858dba1245c05e293d","c2b4d69fba314e199abd1833ecf668b4","509395b40e724b1bab087e2477da3187","7a9d165677a04d92a6055bfc2f24bcb3","e57f49d9a7ca4227aa0de4cf2f70a3ae","4a6ac4df69134224b2794b4d307fdf45","a950e4ffff214724805215e94e9e3999","08c351fab0ad42fe9845dee03e6e9173","fb1b8d4167294800b50905cad942189f","8bbf9bdb7a4f435bbfa65e22fd319fb2","95ac26a68c1147a3a9560d91d39a4e03","b186036747f34791b37c980a70afb34f","f3262831c7894c119c96b2b4b116ba98","99906d8f884546fdab217fe8de50a814","d2023704d7d8450b98529bfb7ee0ca59","57f81472b5574f0d8e09fa1351bf24df","6392dd6dc3604e508003a1c3e0400226","174618d1ef1d4bb39a059d6796110216","61806ca89af24a4abad3f5f5063eefdb","8bada6003025457799a6e75b9788d35f","c3670cda40584ea7b55280ee3996c519","2a24b2834b62400b8e8242f838d993ca","8d1ef59d5f2e483f98f3e7f7dc86eae9","eee327eae7a64f91847d7a9f18cabcd8","83ca040b8f5845c081ba726fc696684c","898e7cf2a0344a68bb48b98e0e864060","1936c1c434bc43fd9e1c7c58d8330c83","0bbed47540464015962f9d322d009206","1b3df1c31ee14af29bcb0b8b2f5ceedd","fa4abd237bf3483ba6f2be54e076a81c","c5c32272bfa94f4b96740ecfd6a2a4f4","6074264ab2244303821b768d7f950796","bf9aba9fe61649768b737b71890e1f01"]},"id":"HA6KYagqONEE","executionInfo":{"status":"error","timestamp":1762538385239,"user_tz":-120,"elapsed":317162,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"56c482ec-21fd-4b72-fcc0-6602227cdb92"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5177 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1a3b707e7de4a858dba1245c05e293d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1295 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b186036747f34791b37c980a70afb34f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d1ef59d5f2e483f98f3e7f7dc86eae9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850\n","Starting training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  return fn(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='649' max='19440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  649/19440 04:06 < 1:59:07, 2.63 it/s, Epoch 1/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='146' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [146/162 00:45 < 00:04, 3.21 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 18.02 GiB. GPU 0 has a total capacity of 39.56 GiB of which 17.95 GiB is free. Process 17714 has 21.60 GiB memory in use. Of the allocated memory 18.54 GiB is allocated by PyTorch, and 2.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1444823231.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# --- TRAIN ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;31m# --- EVALUATE ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2791\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4710\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_eval_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4712\u001b[0;31m                     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4714\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         return type(tensors)(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Let's figure out the new shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.02 GiB. GPU 0 has a total capacity of 39.56 GiB of which 17.95 GiB is free. Process 17714 has 21.60 GiB memory in use. Of the allocated memory 18.54 GiB is allocated by PyTorch, and 2.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["# Install necessary libraries\n","!pip install transformers datasets evaluate huggingface_hub peft bitsandbytes accelerate\n","\n","# Import required libraries\n","import torch\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSeq2SeqLM,\n","    Trainer,\n","    TrainingArguments,\n","    DataCollatorForSeq2Seq,\n","    BitsAndBytesConfig,\n","    TrainerCallback,\n",")\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","import pandas as pd\n","import os\n","from huggingface_hub import login\n","from google.colab import userdata\n","import gc\n","from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n","import evaluate\n","\n","# --- Authentication using Hugging Face Token ---\n","hf_token = userdata.get('HF_TOKEN')\n","\n","if hf_token:\n","    login(token=hf_token)\n","else:\n","    print(\"Hugging Face token not found!\")\n","\n","# --- LOAD DATA ---\n","train_data = pd.read_excel('/content/train.xlsx')\n","test_data = pd.read_excel('/content/test.xlsx')\n","\n","# --- PREPROCESS DATA ---\n","def preprocess_data(df):\n","    \"\"\"\n","    Preprocess data for DistilT5\n","    Adjust based on your task:\n","    - For classification: input ‚Üí label\n","    - For text generation: input ‚Üí output\n","    - For summarization: document ‚Üí summary\n","    \"\"\"\n","    processed_data = []\n","\n","    for idx, row in df.iterrows():\n","        # Adjust the input format based on your task\n","        # Example formats:\n","        # Classification: \"classify: <text>\"\n","        # Summarization: \"summarize: <text>\"\n","        # Translation: \"translate English to French: <text>\"\n","        # Question Answering: \"question: <question> context: <context>\"\n","\n","        # For your EDA/NEDA classification task:\n","        input_text = f\"classify: {row['input']}\"\n","        target_text = 'EDA' if 'EDA' in str(row['output']) else 'NEDA'\n","\n","        processed_data.append({\n","            'input_text': input_text,\n","            'target_text': target_text\n","        })\n","\n","    return pd.DataFrame(processed_data)\n","\n","train_df = preprocess_data(train_data)\n","test_df = preprocess_data(test_data)\n","\n","print(f\"Training samples: {len(train_df)}\")\n","print(f\"Test samples: {len(test_df)}\")\n","print(f\"\\nSample input: {train_df['input_text'].iloc[0][:100]}...\")\n","print(f\"Sample target: {train_df['target_text'].iloc[0]}\")\n","\n","train_dataset = Dataset.from_pandas(train_df)\n","test_dataset = Dataset.from_pandas(test_df)\n","\n","# Create validation split\n","split = train_dataset.train_test_split(test_size=0.2, seed=42)\n","train_dataset, val_dataset = split[\"train\"], split[\"test\"]\n","\n","print(f\"\\nTrain: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n","\n","# --- TOKENIZER ---\n","# Use the model name from the previously successful T5 attempt\n","model_name = \"valhalla/distilt5-qg-hl-6-4\"\n","print(f\"\\nLoading tokenizer: {model_name}\")\n","# Set extra_ids=0 to prevent conflict with existing special tokens\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, extra_ids=0)\n","\n","# Define tokenization parameters\n","max_input_length = 512\n","max_target_length = 128\n","\n","def tokenize_fn(batch):\n","    \"\"\"Tokenize inputs and targets\"\"\"\n","    # Tokenize inputs\n","    model_inputs = tokenizer(\n","        batch['input_text'],\n","        max_length=max_input_length,\n","        padding=\"max_length\",\n","        truncation=True,\n","    )\n","\n","    # Tokenize targets\n","    labels = tokenizer(\n","        batch['target_text'],\n","        max_length=max_target_length,\n","        padding=\"max_length\",\n","        truncation=True,\n","    )\n","\n","    # Replace padding token id with -100 (ignored in loss computation)\n","    labels['input_ids'] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in label]\n","        for label in labels['input_ids']\n","    ]\n","\n","    model_inputs['labels'] = labels['input_ids']\n","    return model_inputs\n","\n","# Apply tokenization\n","print(\"\\nTokenizing datasets...\")\n","train_dataset = train_dataset.map(tokenize_fn, batched=True, remove_columns=['input_text', 'target_text'])\n","val_dataset = val_dataset.map(tokenize_fn, batched=True, remove_columns=['input_text', 'target_text'])\n","test_dataset = test_dataset.map(tokenize_fn, batched=True, remove_columns=['input_text', 'target_text'])\n","print(\"Tokenization complete!\")\n","\n","# --- QLoRA CONFIGURATION ---\n","print(\"\\nConfiguring QLoRA...\")\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","# --- MODEL LOADING ---\n","print(f\"\\nLoading model: {model_name}\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","print(\"Model loaded successfully!\")\n","print(f\"Model device: {model.device}\")\n","\n","# Prepare model for k-bit training\n","print(\"\\nPreparing model for k-bit training...\")\n","model = prepare_model_for_kbit_training(model)\n","\n","# --- LoRA CONFIGURATION ---\n","print(\"\\nConfiguring LoRA...\")\n","lora_config = LoraConfig(\n","    r=16,  # Rank - adjust based on task complexity (8-32)\n","    lora_alpha=32,  # Alpha - typically 2-4x the rank\n","    target_modules=[\"q\", \"v\"],  # Target attention layers (can add \"k\", \"o\" for more params)\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=TaskType.SEQ_2_SEQ_LM,\n","    inference_mode=False,\n",")\n","\n","# Apply LoRA\n","model = get_peft_model(model, lora_config)\n","print(\"\\nTrainable parameters:\")\n","model.print_trainable_parameters()\n","\n","# --- DATA COLLATOR ---\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer,\n","    model=model,\n","    padding=True,\n",")\n","\n","# --- METRICS ---\n","def compute_metrics(eval_pred):\n","    \"\"\"Compute metrics for classification\"\"\"\n","    predictions, labels = eval_pred\n","\n","    # Replace -100 with pad_token_id\n","    predictions = [[token if token != -100 else tokenizer.pad_token_id for token in pred] for pred in predictions]\n","    labels = [[token if token != -100 else tokenizer.pad_token_id for token in label] for label in labels]\n","\n","    # Decode\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Clean up predictions and labels\n","    decoded_preds = [pred.strip().upper() for pred in decoded_preds]\n","    decoded_labels = [label.strip().upper() for label in decoded_labels]\n","\n","    # Convert to binary for classification (EDA=1, NEDA=0)\n","    pred_binary = [1 if 'EDA' in pred else 0 for pred in decoded_preds]\n","    label_binary = [1 if 'EDA' in label else 0 for label in decoded_labels]\n","\n","    # Compute metrics\n","    accuracy = accuracy_score(label_binary, pred_binary)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        label_binary, pred_binary, average='binary', zero_division=0\n","    )\n","\n","    return {\n","        \"accuracy\": accuracy,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1\": f1,\n","    }\n","\n","# --- MEMORY CLEANUP CALLBACK ---\n","class MemoryCleanupCallback(TrainerCallback):\n","    def on_epoch_end(self, args, state, control, **kwargs):\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","\n","    def on_log(self, args, state, control, logs=None, **kwargs):\n","        if state.global_step % 100 == 0:\n","            gc.collect()\n","            torch.cuda.empty_cache()\n","\n","# --- TRAINING ARGUMENTS ---\n","print(\"\\nSetting up training arguments...\")\n","training_args = TrainingArguments(\n","    output_dir='./results_distilt5',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=5e-4,  # Higher LR for LoRA (3e-4 to 1e-3)\n","    per_device_train_batch_size=4,  # Adjust based on your GPU memory\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=20,  # Adjust based on dataset size\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    greater_is_better=True,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_total_limit=2,\n","    report_to='none',\n","    push_to_hub=False,\n","    optim='adamw_torch', # Changed optimizer back\n","    fp16=False, # Keep as False if using bf16\n","    bf16=True,  # Use bf16 with quantization\n","    gradient_accumulation_steps=2,  # Effective batch size = 4 * 2 = 8\n","    gradient_checkpointing=True,  # Enable gradient checkpointing to save memory\n","    max_grad_norm=1.0, # Keep max_grad_norm\n","    dataloader_pin_memory=True,\n","    dataloader_num_workers=2,\n","    warmup_steps=100,\n","    warmup_ratio=0.1,\n","    lr_scheduler_type='cosine',\n","    seed=42,\n",")\n","\n","# --- TRAINER ---\n","print(\"\\nInitializing Trainer...\")\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    callbacks=[MemoryCleanupCallback()],\n",")\n","\n","# --- CLEAR GPU CACHE ---\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","# --- TRAIN ---\n","print(\"\\n\" + \"=\"*60)\n","print(\"STARTING TRAINING\")\n","print(\"=\"*60)\n","trainer.train()\n","\n","# --- EVALUATE ON TEST SET ---\n","print(\"\\n\" + \"=\"*60)\n","print(\"EVALUATING ON TEST SET\")\n","print(\"=\"*60)\n","test_results = trainer.evaluate(test_dataset)\n","print(\"\\nTest Results:\")\n","for key, value in test_results.items():\n","    print(f\"  {key}: {value:.4f}\")\n","\n","# --- SAVE MODEL ---\n","print(\"\\n\" + \"=\"*60)\n","print(\"SAVING MODEL\")\n","print(\"=\"*60)\n","output_dir = \"./fine_tuned_distilt5_lora\"\n","model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","print(f\"‚úÖ LoRA adapters saved to: {output_dir}\")\n","\n","# Save merged model (optional - combines LoRA weights with base model)\n","print(\"\\nSaving merged model...\")\n","try:\n","    merged_model = model.merge_and_unload()\n","    merged_output_dir = f\"{output_dir}_merged\"\n","    merged_model.save_pretrained(merged_output_dir)\n","    tokenizer.save_pretrained(merged_output_dir)\n","    print(f\"‚úÖ Merged model saved to: {merged_output_dir}\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è  Could not save merged model: {e}\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"TRAINING COMPLETE!\")\n","print(\"=\"*60)\n","\n","# --- INFERENCE EXAMPLE ---\n","print(\"\\n\" + \"=\"*60)\n","print(\"TESTING INFERENCE\")\n","print(\"=\"*60)\n","\n","def predict(text, max_length=128):\n","    \"\"\"Make a prediction on new text\"\"\"\n","    input_text = f\"classify: {text}\"\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n","    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_length=max_length,\n","            num_beams=4,\n","            early_stopping=True,\n","            no_repeat_ngram_size=2,\n","        )\n","\n","    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return prediction.strip()\n","\n","# Test on samples from test set\n","# Using train_df for sample inputs as test_df columns were removed after tokenization\n","if len(train_df) > 0:\n","    num_samples = min(3, len(train_df))\n","    print(f\"\\nTesting on {num_samples} random samples:\\n\")\n","\n","    # Get random indices from original train_df to get input text and target label\n","    sample_indices = np.random.choice(len(train_df), num_samples, replace=False)\n","\n","    for i in range(num_samples):\n","        idx = sample_indices[i]\n","        # Need to use original DataFrame structure to get input and target text\n","        sample_input = train_df['input_text'].iloc[idx].replace(\"classify: \", \"\")\n","        sample_target = train_df['target_text'].iloc[idx]\n","\n","        prediction = predict(sample_input)\n","\n","        print(f\"Sample {i+1}:\")\n","        print(f\"  Input: {sample_input[:100]}...\")\n","        print(f\"  Expected: {sample_target}\")\n","        print(f\"  Predicted: {prediction}\")\n","        print(f\"  Correct: {'‚úÖ' if prediction.upper() == sample_target.upper() else '‚ùå'}\")\n","        print()\n","\n","print(\"\\nüéâ All done!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["93fbb81db61546b2a1f66f6424bf08e6","9f2f89c428d54c199f2f64c97ab58293","931aa18bbff54ac4ba227928f1da4335","5ab02981a4d9488b85c59e88b0f41db4","848c996c62ec4ba1bd556ccae59a4979","ba4ff5a6f3cc43649bc4d4835d86cefb","6c790127e6c54817b190973b78f06376","98a102ab57d748c58e3a0746d9112ffe","f810d24f5a714b9589bd4cb55a9ca221","8655c7ddfc784e76b65f78deaaa11f61","7790894c2cdc4effbbdc31cedd6183dc","332064343df840929c9215fdb65ff5a3","32a0633f026941d5b80e39d593544f8b","3b92d011db7a4ac3954d9dbd3ffe6965","ae95509b1b994ff1890cb95d13ac4240","17090c1e4a864fb7bd0e8aab4b209ca1","3fc01dba1726444c8f14cf1e34dddca3","d57bb7226d44497ab9b9d092fad38d31","e70e8cf247894d849392c5caad7915fb","15b4c37abf8141f19f1724a1c365ccbf","f4b8fb237d4a485ca1932de9765d7f0c","f0edbc11e70e4b2ba89b2c9301b156f7","fcc953f5dd144ef49e6e9743e8a89c0d","5369ead89af8476985caebee55dd1081","493d1bdcf62b42fe857f86519d8cc360","78d8787661ea44a5818aef81de58457b","21ab7660500d469aa956acd8585798a7","65785fd5fa8e49e3afa55f424779e9c5","5fc1522a6cde4bfd98ee913e29d2fd1a","747956f199fb40abaa7ddf0b66ac152d","c90d5debec7242449fb4f01d3483ae12","b0b6985a0470409a94b13480daf1457c","5b415c2a831940aba5d3b765a351e7c7","8a5855cd745242cf9449d60942068214","ca858e85db9e4f7e892e05e486951260","3f0bccaa08324b2d9bbdc8e41eb711e4","a179974394c54d6ea862ff52e459403d","857018c85ea4484fb1e21ae13ea7044e","7c5403ae70b84763ab089884e8d53e4c","b4b9d80d9db347e6a3561b1d525eaa74","9e30a03608544736ac473700d75a5209","e0bfd1e558034230a46ac911104e6618","c2af401078a444d09879f4fb2d1a43e8","8a23d987e1dc41bfa6830577776bdcb8","3f662b23be99446eafe969c9f7ef022b","c2b4069c833b4089a8be05dd846b0935","df8999a76a104736830fc103d89567e0","b461b9df2a314ef7b96de6eb05635305","f4d87ec0e9484d19b7600750f40f5134","5a29dae7e4a747dda0e5014246ad4201","25ff99ba32c444a4876518170b0896bf","0a6d35c7d42b4a5a9889bf5b1503dcf8","9aa3e735d6ea470f933e49e282e062d0","5cadc84cd9c44429a43a356350e17b8c","0ccb4361ee1c4460aa3eaf9a337e8cd3"]},"id":"ZnUjxgoCGyUH","executionInfo":{"status":"error","timestamp":1762540159526,"user_tz":-120,"elapsed":280102,"user":{"displayName":"Aline Hassan","userId":"07212649028289720153"}},"outputId":"7d96580c-7f58-4052-e7a5-c3e6ba510ca0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n","Training samples: 6472\n","Test samples: 3373\n","\n","Sample input: classify: Age:31.  Gender:female.  Diagnosis:rrms. Has not converted to SPMS. Initial presentation c...\n","Sample target: EDA\n","\n","Train: 5177, Val: 1295, Test: 3373\n","\n","Loading tokenizer: valhalla/distilt5-qg-hl-6-4\n"]},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"output_type":"stream","name":"stdout","text":["\n","Tokenizing datasets...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5177 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93fbb81db61546b2a1f66f6424bf08e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1295 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332064343df840929c9215fdb65ff5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/3373 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcc953f5dd144ef49e6e9743e8a89c0d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenization complete!\n","\n","Configuring QLoRA...\n","\n","Loading model: valhalla/distilt5-qg-hl-6-4\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/208M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a5855cd745242cf9449d60942068214"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/208M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f662b23be99446eafe969c9f7ef022b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n","Model device: cuda:0\n","\n","Preparing model for k-bit training...\n","\n","Configuring LoRA...\n","\n","Trainable parameters:\n","trainable params: 458,752 || all params: 52,560,384 || trainable%: 0.8728\n","\n","Setting up training arguments...\n","\n","Initializing Trainer...\n","\n","============================================================\n","STARTING TRAINING\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='649' max='12960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [  649/12960 03:22 < 1:04:13, 3.20 it/s, Epoch 1/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='142' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [142/162 00:41 < 00:05, 3.37 it/s]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 39.56 GiB of which 17.44 GiB is free. Process 49861 has 22.11 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 2.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2964455249.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STARTING TRAINING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;31m# --- EVALUATE ON TEST SET ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2791\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4710\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_eval_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4712\u001b[0;31m                     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4714\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_nested_concat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_pad_and_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         return type(tensors)(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_pt_utils.py\u001b[0m in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtensor1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Let's figure out the new shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 17.51 GiB. GPU 0 has a total capacity of 39.56 GiB of which 17.44 GiB is free. Process 49861 has 22.11 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 2.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4Mbzfi-6g8JY"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"collapsed_sections":["qrnXIyrb2V7y","xwR88AnjUVh-","tRQLTvjf_QNW","2i7cimtTf2TY","A5DiddqrvP0v","hRhE8endrYMo"],"mount_file_id":"1-5h5-opqzc_MZJETqoB34KI3Q_i7-3jv","authorship_tag":"ABX9TyMqUSyVfoMD/XCiBEe+9rHd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03c7c0538ad0469fb55b7b9902662862":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04c2ebf382ac4cd9b608c19ab968305f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26f42274caf546d8af44ee2617ed60b1","IPY_MODEL_e7a5592ab86a456784018812fee11537","IPY_MODEL_8e3cbf6a7f814bd092a312e1fd8a4f63"],"layout":"IPY_MODEL_26abaf092ac645a8af180e956364aec9"}},"096e435e0c244e4ab9888a6ec4ee8abf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5579d0645fb1412f8a6a68d1e513e789","placeholder":"‚Äã","style":"IPY_MODEL_ae30904af6934731ab2aa7fb019a6aef","value":"tokenizer.json:‚Äá100%"}},"0ead3fdcd6c34b20b8168dbaec99d373":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18727f1d39fb4da995d0951100175e4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c6b5e42f8e147b0aca4c5826e7ea98f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_caec450cf4514404ae7f9f34ef84ac49","max":760289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3cc4a0ba1f44a3580e4b52904ec40de","value":760289}},"226c1c684586489093f6754c6c8f328a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27fb9d6f1b95457790d7e30d35334d39","placeholder":"‚Äã","style":"IPY_MODEL_7d56812b9a3e42f2b00a0dacfa7e6949","value":"‚Äá47.4M/47.4M‚Äá[00:01&lt;00:00,‚Äá32.2MB/s]"}},"2388be90c1a54fb190364235bc50a021":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb989660c5df44acb59a6f1e42c31b1d","placeholder":"‚Äã","style":"IPY_MODEL_fa2334be5f32453f9d2893d4680cedf0","value":"model.safetensors:‚Äá100%"}},"26abaf092ac645a8af180e956364aec9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26f42274caf546d8af44ee2617ed60b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_987c83f9ae8e41caac17e0d3878c80b6","placeholder":"‚Äã","style":"IPY_MODEL_a96dc792ec16466696bc1dca8344ce09","value":"Map:‚Äá100%"}},"277f90d071834752961268addfe1d862":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27fb9d6f1b95457790d7e30d35334d39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b4b97855d10405ab070fdfd1a94fe74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85c7cdaed31e430c98bfaa53c922ec15","IPY_MODEL_51336ce99fad4acf91bc9b9b5e5a2c5c","IPY_MODEL_a30551dd672b44bfbafc8c4b76b7cfc1"],"layout":"IPY_MODEL_79b25194457b42d7a723cd2581f9b740"}},"2cc6683cd8224983bbd49004eaf3e58b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"311ad8ee6369473ab5eed73bf0698932":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_657c38841d274459a8c7b60c216c21cd","IPY_MODEL_3e8922867dd94bb2853c305a0b29500a","IPY_MODEL_c5c44c78211b4aaf81be8fab2b9ed4c3"],"layout":"IPY_MODEL_947f1ce68e154471be21ad6a3c18a12d"}},"3ca2d12652574408a593639a7cc71680":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e8922867dd94bb2853c305a0b29500a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7537bca305a64bcf8ea563c7a4db7472","max":684,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4fa913e4bb4d4c499fce56b941a5fb12","value":684}},"4050fae0063f4cb0bac0d422c6b7c5ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40ca89c9f4024d95a472c3b9bed8e31f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40ec891fac5347e3b56828a2e3a318d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42d0bc4541fc4e6cb30c608052055d3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a36c46d6389040d3808cb6cf498b2dd5","max":1312669,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40ca89c9f4024d95a472c3b9bed8e31f","value":1312669}},"46ead435f72c47108fe6e2f29d2fbac8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"498fc5ebd93d47fa88af5885ebc3f266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fa913e4bb4d4c499fce56b941a5fb12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"506c672ddafd4a50be5ceb48b9dd5973":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_096e435e0c244e4ab9888a6ec4ee8abf","IPY_MODEL_42d0bc4541fc4e6cb30c608052055d3b","IPY_MODEL_f27aa427c5af435c98b3b10ed49bf4a8"],"layout":"IPY_MODEL_b5930620dfdf4f4a865d71d96aaba07b"}},"51336ce99fad4acf91bc9b9b5e5a2c5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4050fae0063f4cb0bac0d422c6b7c5ad","max":6472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82c21b5ce1c14932b6ba97a035977385","value":6472}},"54bb36e698094c20a906aefe97f74171":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5579d0645fb1412f8a6a68d1e513e789":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e0aa0e2b3d4abda0f9a20c5bb06b68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61e94eab8f9c4ddbb9f72db1f387db56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"657c38841d274459a8c7b60c216c21cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb17d2cc2921446f8a49a731d3be62e4","placeholder":"‚Äã","style":"IPY_MODEL_6e47b14aa55046a99e050c0ea88eb9d8","value":"config.json:‚Äá100%"}},"6e47b14aa55046a99e050c0ea88eb9d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70d618901f01412885b1fa121ac7e484":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7537bca305a64bcf8ea563c7a4db7472":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79b25194457b42d7a723cd2581f9b740":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c36ace12e03476d9c2318081e4f0a64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e94eab8f9c4ddbb9f72db1f387db56","placeholder":"‚Äã","style":"IPY_MODEL_a0b04db43f0343678b1746755ce87308","value":"tokenizer_config.json:‚Äá100%"}},"7d56812b9a3e42f2b00a0dacfa7e6949":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fef952b5514444cb3a79270ccde3da1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"826124241c1b47279117b6441f671bec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18727f1d39fb4da995d0951100175e4c","placeholder":"‚Äã","style":"IPY_MODEL_a228dc72b2824522a721011075088ae4","value":"spiece.model:‚Äá100%"}},"82c21b5ce1c14932b6ba97a035977385":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85c7cdaed31e430c98bfaa53c922ec15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4c24bb3e1bc42d7a08f7b5c89a8ff4c","placeholder":"‚Äã","style":"IPY_MODEL_3ca2d12652574408a593639a7cc71680","value":"Map:‚Äá100%"}},"8e3b04e44ab24f1693c6d64a6fc8aa69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f677be442b4ba691c8243f2b9d61ae","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff2e5d6107fc44dc8443682b70d86101","value":25}},"8e3cbf6a7f814bd092a312e1fd8a4f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4b6c531c99c4e0e93c8188a165f24e2","placeholder":"‚Äã","style":"IPY_MODEL_0ead3fdcd6c34b20b8168dbaec99d373","value":"‚Äá3373/3373‚Äá[00:06&lt;00:00,‚Äá562.20‚Äáexamples/s]"}},"947f1ce68e154471be21ad6a3c18a12d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e65f9efbbf45a2bf8dec4cd7f60dd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2388be90c1a54fb190364235bc50a021","IPY_MODEL_d7042e99182c4b7bbdfb95233869fcaf","IPY_MODEL_226c1c684586489093f6754c6c8f328a"],"layout":"IPY_MODEL_a2c0bb04485945b3b339e59d4cb12a39"}},"987c83f9ae8e41caac17e0d3878c80b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0b04db43f0343678b1746755ce87308":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0e20b8d09a84fde976061225ed23448":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a228dc72b2824522a721011075088ae4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a2c0bb04485945b3b339e59d4cb12a39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a30551dd672b44bfbafc8c4b76b7cfc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40ec891fac5347e3b56828a2e3a318d2","placeholder":"‚Äã","style":"IPY_MODEL_46ead435f72c47108fe6e2f29d2fbac8","value":"‚Äá6472/6472‚Äá[00:11&lt;00:00,‚Äá548.39‚Äáexamples/s]"}},"a36c46d6389040d3808cb6cf498b2dd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3cc4a0ba1f44a3580e4b52904ec40de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a96dc792ec16466696bc1dca8344ce09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae30904af6934731ab2aa7fb019a6aef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b44535fac2024ad79f9b76a9b0e984f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_826124241c1b47279117b6441f671bec","IPY_MODEL_1c6b5e42f8e147b0aca4c5826e7ea98f","IPY_MODEL_f896360945394f48bfddc6b1451087f9"],"layout":"IPY_MODEL_e464abe04e8749b2bb1b15adf365112b"}},"b5930620dfdf4f4a865d71d96aaba07b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4b6c531c99c4e0e93c8188a165f24e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c44c78211b4aaf81be8fab2b9ed4c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e0aa0e2b3d4abda0f9a20c5bb06b68","placeholder":"‚Äã","style":"IPY_MODEL_2cc6683cd8224983bbd49004eaf3e58b","value":"‚Äá684/684‚Äá[00:00&lt;00:00,‚Äá98.5kB/s]"}},"c944af58a8b14eb48a1cfd49bf43955a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caec450cf4514404ae7f9f34ef84ac49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb989660c5df44acb59a6f1e42c31b1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d25196f38bc14ea0ad06702dd30771cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5f677be442b4ba691c8243f2b9d61ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7042e99182c4b7bbdfb95233869fcaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_277f90d071834752961268addfe1d862","max":47372894,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03c7c0538ad0469fb55b7b9902662862","value":47372894}},"dd81abd6309a4f79b6acd1eeb8f517aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e464abe04e8749b2bb1b15adf365112b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4c24bb3e1bc42d7a08f7b5c89a8ff4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7a5592ab86a456784018812fee11537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff2d9cbf049b499da0df0b98d7c32e8c","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0e20b8d09a84fde976061225ed23448","value":3373}},"e7ea349499f440fd9204185769693582":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70d618901f01412885b1fa121ac7e484","placeholder":"‚Äã","style":"IPY_MODEL_7fef952b5514444cb3a79270ccde3da1","value":"‚Äá25.0/25.0‚Äá[00:00&lt;00:00,‚Äá3.32kB/s]"}},"f27aa427c5af435c98b3b10ed49bf4a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd81abd6309a4f79b6acd1eeb8f517aa","placeholder":"‚Äã","style":"IPY_MODEL_d25196f38bc14ea0ad06702dd30771cf","value":"‚Äá1.31M/1.31M‚Äá[00:00&lt;00:00,‚Äá5.75MB/s]"}},"f896360945394f48bfddc6b1451087f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c944af58a8b14eb48a1cfd49bf43955a","placeholder":"‚Äã","style":"IPY_MODEL_498fc5ebd93d47fa88af5885ebc3f266","value":"‚Äá760k/760k‚Äá[00:00&lt;00:00,‚Äá3.30MB/s]"}},"f98dbcabd58041b995fb59bc0fda48ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c36ace12e03476d9c2318081e4f0a64","IPY_MODEL_8e3b04e44ab24f1693c6d64a6fc8aa69","IPY_MODEL_e7ea349499f440fd9204185769693582"],"layout":"IPY_MODEL_54bb36e698094c20a906aefe97f74171"}},"fa2334be5f32453f9d2893d4680cedf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb17d2cc2921446f8a49a731d3be62e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff2d9cbf049b499da0df0b98d7c32e8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff2e5d6107fc44dc8443682b70d86101":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e1fa6e80ab34ce7aa14655c07f78d2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e9e45c2b6d54f1ca085e8cbfee81697","IPY_MODEL_3d9d09fcaf5e47059e0dd6a734a78ce8","IPY_MODEL_9eacbf8b844548289ce30fb0e3dd866a"],"layout":"IPY_MODEL_db0a6fbd58f743e69d2cddc874be71e2"}},"9e9e45c2b6d54f1ca085e8cbfee81697":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f7156d0abe64efd9e31c495d47afa1f","placeholder":"‚Äã","style":"IPY_MODEL_3e865a810e9c42d4860cb3d379fca2f7","value":"Map:‚Äá100%"}},"3d9d09fcaf5e47059e0dd6a734a78ce8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88c838515838441eb005d7514db57172","max":6472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad293daf28444776a531509849ef7535","value":6472}},"9eacbf8b844548289ce30fb0e3dd866a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dfce3eef7e546d38e930efb66140897","placeholder":"‚Äã","style":"IPY_MODEL_aa6563cd1ff44c3eac0836532c9ae96a","value":"‚Äá6472/6472‚Äá[00:01&lt;00:00,‚Äá3951.81‚Äáexamples/s]"}},"db0a6fbd58f743e69d2cddc874be71e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f7156d0abe64efd9e31c495d47afa1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e865a810e9c42d4860cb3d379fca2f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88c838515838441eb005d7514db57172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad293daf28444776a531509849ef7535":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0dfce3eef7e546d38e930efb66140897":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa6563cd1ff44c3eac0836532c9ae96a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd807bfdfa814ebb8e9a6a47e8ac0046":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7b30f123a094f17b92088df05f5cb3f","IPY_MODEL_d024a48e4bd1413c8806cb625abe167e","IPY_MODEL_80cd098b8a0a421cadfc95d718b5b9b2"],"layout":"IPY_MODEL_1df8f4b8584e42cdb62e1fb2f4f2fbe8"}},"a7b30f123a094f17b92088df05f5cb3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2b161432774c5db3049f9c6e443ee8","placeholder":"‚Äã","style":"IPY_MODEL_81cd439fdebb48dd8c7debf130595c42","value":"Map:‚Äá100%"}},"d024a48e4bd1413c8806cb625abe167e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b937f6a1fa147999341005362f0df28","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc8778eb7ce24752a60342709c5f928a","value":3373}},"80cd098b8a0a421cadfc95d718b5b9b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b768ddd3cfd74fd4b6eef98fb107fca9","placeholder":"‚Äã","style":"IPY_MODEL_77fb09fa32354456aca69760f28a7d23","value":"‚Äá3373/3373‚Äá[00:00&lt;00:00,‚Äá3919.81‚Äáexamples/s]"}},"1df8f4b8584e42cdb62e1fb2f4f2fbe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd2b161432774c5db3049f9c6e443ee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81cd439fdebb48dd8c7debf130595c42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b937f6a1fa147999341005362f0df28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc8778eb7ce24752a60342709c5f928a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b768ddd3cfd74fd4b6eef98fb107fca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77fb09fa32354456aca69760f28a7d23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b071b77f099496380f5c052dadb8e50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6d3fd882ee74fbd8ba0777ca3c453fa","IPY_MODEL_1b8f007f10e6461e9551763ace551e9a","IPY_MODEL_4bb3256e2dd244d2867597f664bf2ec9"],"layout":"IPY_MODEL_e984294c3551479c95a725363b7dbdcd"}},"e6d3fd882ee74fbd8ba0777ca3c453fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_213104e6629b47698f228fa604954923","placeholder":"‚Äã","style":"IPY_MODEL_2cc58a34ddf24339920ca04d0a44090b","value":"tokenizer_config.json:‚Äá100%"}},"1b8f007f10e6461e9551763ace551e9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9df5c2491ea04638bb588f3ac06eb77f","max":201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e76bd766b28c40f893a90c227dadc0f5","value":201}},"4bb3256e2dd244d2867597f664bf2ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2053549cd6664ea380839419e725d930","placeholder":"‚Äã","style":"IPY_MODEL_b59bf15db4f745bb94e0b4617bff2555","value":"‚Äá201/201‚Äá[00:00&lt;00:00,‚Äá28.2kB/s]"}},"e984294c3551479c95a725363b7dbdcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"213104e6629b47698f228fa604954923":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc58a34ddf24339920ca04d0a44090b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9df5c2491ea04638bb588f3ac06eb77f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e76bd766b28c40f893a90c227dadc0f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2053549cd6664ea380839419e725d930":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59bf15db4f745bb94e0b4617bff2555":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80ad1c844644c92a75e8950b7072429":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b070bf3ea4124399a726dee1ff13e7be","IPY_MODEL_9fd469420e1741649ce8ddbb59dc2107","IPY_MODEL_13fd5ecdd3c2403ba5655f2b16096e40"],"layout":"IPY_MODEL_db7f5cf204324ae7aa0f0c00d6a0a35e"}},"b070bf3ea4124399a726dee1ff13e7be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c5592bf59c546dab94c685cee05da26","placeholder":"‚Äã","style":"IPY_MODEL_f24832e9232f4be381b204ea0f851555","value":"vocab.txt:‚Äá"}},"9fd469420e1741649ce8ddbb59dc2107":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfa0dd5128534d3ab335d27c7dfdb4ac","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_041d27281c93475a9f9628b8ce7e0714","value":1}},"13fd5ecdd3c2403ba5655f2b16096e40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c81faaead6f5458fa9497dac0496b3f6","placeholder":"‚Äã","style":"IPY_MODEL_4c6e2731685f4518b72d66b7eec2817f","value":"‚Äá231k/?‚Äá[00:00&lt;00:00,‚Äá11.2MB/s]"}},"db7f5cf204324ae7aa0f0c00d6a0a35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5592bf59c546dab94c685cee05da26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f24832e9232f4be381b204ea0f851555":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfa0dd5128534d3ab335d27c7dfdb4ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"041d27281c93475a9f9628b8ce7e0714":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c81faaead6f5458fa9497dac0496b3f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c6e2731685f4518b72d66b7eec2817f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c26af6eb2667469183105f1a79237c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb03dbb3cdc94ccaa6883f1e4b98c3ff","IPY_MODEL_c2400bf5731647dc9dae18d2bd6995f1","IPY_MODEL_f3e9e4ab86774f5790925ef378518255"],"layout":"IPY_MODEL_d719b8b630ea42e38b992221930e264b"}},"bb03dbb3cdc94ccaa6883f1e4b98c3ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99c5266e81af4eb19a85e33a85ef1e23","placeholder":"‚Äã","style":"IPY_MODEL_0a55151d57534a1b9a81ce419d109c3e","value":"special_tokens_map.json:‚Äá100%"}},"c2400bf5731647dc9dae18d2bd6995f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34b50ef6145a4f28ab77f6b62db0ff0b","max":153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94fb6b75b5004d649c4f8c6c7a73dbb6","value":153}},"f3e9e4ab86774f5790925ef378518255":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_350aaa30492a4029a4380cff2d5c89a5","placeholder":"‚Äã","style":"IPY_MODEL_f2731e9b76044dc98ef75c7d675fba88","value":"‚Äá153/153‚Äá[00:00&lt;00:00,‚Äá21.1kB/s]"}},"d719b8b630ea42e38b992221930e264b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99c5266e81af4eb19a85e33a85ef1e23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a55151d57534a1b9a81ce419d109c3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34b50ef6145a4f28ab77f6b62db0ff0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94fb6b75b5004d649c4f8c6c7a73dbb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"350aaa30492a4029a4380cff2d5c89a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2731e9b76044dc98ef75c7d675fba88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dada0322fb704b03b1a661ee0857543f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84309166c1d64bc28c3f1a9ea6631291","IPY_MODEL_8d16d8e6f625460ab6eff9d6d72dd29f","IPY_MODEL_83ee1101b52f4e3482edb2f7b5361fcd"],"layout":"IPY_MODEL_07d145452418413fb02dbfaf769e03ba"}},"84309166c1d64bc28c3f1a9ea6631291":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36c2db40da6643cb932f49008d3ddaaf","placeholder":"‚Äã","style":"IPY_MODEL_53bdb3b2609444ae959e234a81e21ef0","value":"tokenizer.json:‚Äá"}},"8d16d8e6f625460ab6eff9d6d72dd29f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad2a5b794a3341a8aa3751a0ddda617c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b64f2ba5b88e42f1965ca2cf2d0d7cd0","value":1}},"83ee1101b52f4e3482edb2f7b5361fcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4e9d1ae03ad424b95dbb6dc283b798d","placeholder":"‚Äã","style":"IPY_MODEL_2cda36319f36450e84dd0c21d13da4ec","value":"‚Äá466k/?‚Äá[00:00&lt;00:00,‚Äá11.1MB/s]"}},"07d145452418413fb02dbfaf769e03ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c2db40da6643cb932f49008d3ddaaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53bdb3b2609444ae959e234a81e21ef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad2a5b794a3341a8aa3751a0ddda617c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"b64f2ba5b88e42f1965ca2cf2d0d7cd0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4e9d1ae03ad424b95dbb6dc283b798d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cda36319f36450e84dd0c21d13da4ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05ea978a36ee4bcd9e90fbcb28afe5a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_422ec6f158f142039679bc1b098246fa","IPY_MODEL_bccea44c98db47cba0615c081affe4bf","IPY_MODEL_7e05ec43567445db8788cbbfafa809dd"],"layout":"IPY_MODEL_7009c7a4fb064742ae968535a2a45a7d"}},"422ec6f158f142039679bc1b098246fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cb8cbb8bdcc42bfabc5f00ce3e97100","placeholder":"‚Äã","style":"IPY_MODEL_8bed9841eb51432cad24f0a5a4247283","value":"config.json:‚Äá100%"}},"bccea44c98db47cba0615c081affe4bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9df9c7a6154ad8b0c77790b7d75391","max":700,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2bb72a00dd8408b9a92dea4b4ba926e","value":700}},"7e05ec43567445db8788cbbfafa809dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24615d51363341f081f007c65ea4d503","placeholder":"‚Äã","style":"IPY_MODEL_324cc7d1d03e4973ae7b9cc2a09922aa","value":"‚Äá700/700‚Äá[00:00&lt;00:00,‚Äá108kB/s]"}},"7009c7a4fb064742ae968535a2a45a7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb8cbb8bdcc42bfabc5f00ce3e97100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bed9841eb51432cad24f0a5a4247283":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d9df9c7a6154ad8b0c77790b7d75391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2bb72a00dd8408b9a92dea4b4ba926e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24615d51363341f081f007c65ea4d503":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324cc7d1d03e4973ae7b9cc2a09922aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83aad3d747554e72a61930bd4792d539":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40785c5da62a46fe95b0bd8476fd05c3","IPY_MODEL_83c0e3e5290e4357821f49bf6fe34d3e","IPY_MODEL_b4561d718d834ef0b9f67128a5374aba"],"layout":"IPY_MODEL_1162e3e16b4640a2bc00ebebea725ea5"}},"40785c5da62a46fe95b0bd8476fd05c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3929b3be15954ed7a9c53d0c09087967","placeholder":"‚Äã","style":"IPY_MODEL_0c602f0850ae47febbde3c8fd217e753","value":"pytorch_model.bin:‚Äá100%"}},"83c0e3e5290e4357821f49bf6fe34d3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70731d7698ca4ad7afd1c036c4c47cd1","max":523952829,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d8e5a243223480695fcc8bdd3f29c9d","value":523952829}},"b4561d718d834ef0b9f67128a5374aba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58dbd01df3eb43059f19cef0c788a463","placeholder":"‚Äã","style":"IPY_MODEL_3136a41bd1364f0c8d4424216f2dfd46","value":"‚Äá524M/524M‚Äá[00:08&lt;00:00,‚Äá154MB/s]"}},"1162e3e16b4640a2bc00ebebea725ea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3929b3be15954ed7a9c53d0c09087967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c602f0850ae47febbde3c8fd217e753":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70731d7698ca4ad7afd1c036c4c47cd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d8e5a243223480695fcc8bdd3f29c9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58dbd01df3eb43059f19cef0c788a463":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3136a41bd1364f0c8d4424216f2dfd46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa6528fe769d42eaa03bc4c7140d80a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2f8114d15de4aa0a0ece6f1875e8d7a","IPY_MODEL_708fb4079a464708a576ae1a458276e2","IPY_MODEL_42b17a8c263c491a8a68821e94fb9003"],"layout":"IPY_MODEL_0be0a6dc0987401fb25a536be3a84a68"}},"e2f8114d15de4aa0a0ece6f1875e8d7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd4a23b6be604e919f80c571bd6797f2","placeholder":"‚Äã","style":"IPY_MODEL_a625b3bb98734308aa36823b5b9a862e","value":"Map:‚Äá100%"}},"708fb4079a464708a576ae1a458276e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cffb9c3c9ba3442aa683de6400829e20","max":5177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e194b5caa67a4b42b8ca05cd85254189","value":5177}},"42b17a8c263c491a8a68821e94fb9003":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18c75d7b37914618b16f5e75c5043e6c","placeholder":"‚Äã","style":"IPY_MODEL_e083dfe9f1ad4c23820495aa758f3ec1","value":"‚Äá5177/5177‚Äá[00:18&lt;00:00,‚Äá288.46‚Äáexamples/s]"}},"0be0a6dc0987401fb25a536be3a84a68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd4a23b6be604e919f80c571bd6797f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a625b3bb98734308aa36823b5b9a862e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cffb9c3c9ba3442aa683de6400829e20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e194b5caa67a4b42b8ca05cd85254189":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18c75d7b37914618b16f5e75c5043e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e083dfe9f1ad4c23820495aa758f3ec1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f8b4b54f5454ff48a156213d00c94d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0d6291933444ffc94bbea2d8f50005b","IPY_MODEL_57802854b82b4f0b98259925c8a7bc92","IPY_MODEL_ff52bce181464320b5933d802960f7f9"],"layout":"IPY_MODEL_22f9ad0b772f44a59d95afcf2bee8eee"}},"f0d6291933444ffc94bbea2d8f50005b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8343c8cde5984f50a7bcaecfea107871","placeholder":"‚Äã","style":"IPY_MODEL_ae6ced32f8f44576a6af1df4cfeb412a","value":"model.safetensors:‚Äá100%"}},"57802854b82b4f0b98259925c8a7bc92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aec6e219cad43da8304b35a20f96548","max":523924224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a29759238a9479d85e13b0a6cc1b075","value":523924224}},"ff52bce181464320b5933d802960f7f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3c78cbde84b4bf999e5dd161f27ea35","placeholder":"‚Äã","style":"IPY_MODEL_e6f6f3b8cfe84b31b27387b1cfb1ef11","value":"‚Äá524M/524M‚Äá[00:07&lt;00:00,‚Äá146MB/s]"}},"22f9ad0b772f44a59d95afcf2bee8eee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8343c8cde5984f50a7bcaecfea107871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae6ced32f8f44576a6af1df4cfeb412a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aec6e219cad43da8304b35a20f96548":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a29759238a9479d85e13b0a6cc1b075":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3c78cbde84b4bf999e5dd161f27ea35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6f6f3b8cfe84b31b27387b1cfb1ef11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c38ae808dd34a688c96cfb8e8ae0849":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9139d5c68c184434bd845f9973452930","IPY_MODEL_87847c0765ef4f639dddcb65ad89ff28","IPY_MODEL_9aa9e300c6f5425ca172e318042ee3ee"],"layout":"IPY_MODEL_89100890014a4661a4b355f23e6b9745"}},"9139d5c68c184434bd845f9973452930":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c337b187b4e74ce88bd9a5b72c4d86d4","placeholder":"‚Äã","style":"IPY_MODEL_e066aa232c594f13b8f1e975ad07864d","value":"Map:‚Äá100%"}},"87847c0765ef4f639dddcb65ad89ff28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_426cf4c49b32452398e05c0334fa9920","max":1295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b3fbbf6b57b4be29693cbe0ef4a529e","value":1295}},"9aa9e300c6f5425ca172e318042ee3ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7a2a9d596b84419a4311c08173df51b","placeholder":"‚Äã","style":"IPY_MODEL_6b7fb887bf6f48f2bde3de5799bc8768","value":"‚Äá1295/1295‚Äá[00:04&lt;00:00,‚Äá300.10‚Äáexamples/s]"}},"89100890014a4661a4b355f23e6b9745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c337b187b4e74ce88bd9a5b72c4d86d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e066aa232c594f13b8f1e975ad07864d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"426cf4c49b32452398e05c0334fa9920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b3fbbf6b57b4be29693cbe0ef4a529e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7a2a9d596b84419a4311c08173df51b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b7fb887bf6f48f2bde3de5799bc8768":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a38b87b5fbb543a2a5386f8bb1416c04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa694ff800a6490782da3a987e6d8b46","IPY_MODEL_c9cf8fdecc2e4376b5d8eaa56308e164","IPY_MODEL_7267ce7a35a44de3b8e8db4bcf010255"],"layout":"IPY_MODEL_c0a65e099e6f4264b333f0d5f0ea0052"}},"fa694ff800a6490782da3a987e6d8b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff68c3e019ae47a0bb633420d9fb3c10","placeholder":"‚Äã","style":"IPY_MODEL_c4334c12734a4fe99489aedeb40a9579","value":"Map:‚Äá100%"}},"c9cf8fdecc2e4376b5d8eaa56308e164":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a612e53dd3c4d2aaaef409c1c922b77","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_934dee3b81a3483e93572a33de1e4149","value":3373}},"7267ce7a35a44de3b8e8db4bcf010255":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cc874aab13e4c12be46f4aa120ecd52","placeholder":"‚Äã","style":"IPY_MODEL_7bf2b982fb05461594ada1dd65040f79","value":"‚Äá3373/3373‚Äá[00:11&lt;00:00,‚Äá295.52‚Äáexamples/s]"}},"c0a65e099e6f4264b333f0d5f0ea0052":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff68c3e019ae47a0bb633420d9fb3c10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4334c12734a4fe99489aedeb40a9579":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a612e53dd3c4d2aaaef409c1c922b77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"934dee3b81a3483e93572a33de1e4149":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9cc874aab13e4c12be46f4aa120ecd52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf2b982fb05461594ada1dd65040f79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f42adaa0627148868aa862260e2271c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30fc686812fa4eda939372be7ae572b3","IPY_MODEL_d254dd1fff6240059c2fb5315b627a6c","IPY_MODEL_564dd95f4d47428ba1def0ceb93a6916"],"layout":"IPY_MODEL_747bb7a31b044580a0e7a2103c78ca30"}},"30fc686812fa4eda939372be7ae572b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12326ec25abf46a8aa4ebc13b82b8b74","placeholder":"‚Äã","style":"IPY_MODEL_59cb7b863b6f45e68f5542137591e0a7","value":"model.safetensors:‚Äá100%"}},"d254dd1fff6240059c2fb5315b627a6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c8cf2a41cfa41ddb1571597bee81378","max":598635032,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ed21897683c41b1a5584c02a19eaab1","value":598635032}},"564dd95f4d47428ba1def0ceb93a6916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25a467054b3543359537a752ae1b880b","placeholder":"‚Äã","style":"IPY_MODEL_4408d592a6b54d29984bd2297ab8c2ea","value":"‚Äá599M/599M‚Äá[00:01&lt;00:00,‚Äá360MB/s]"}},"747bb7a31b044580a0e7a2103c78ca30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12326ec25abf46a8aa4ebc13b82b8b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59cb7b863b6f45e68f5542137591e0a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c8cf2a41cfa41ddb1571597bee81378":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed21897683c41b1a5584c02a19eaab1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25a467054b3543359537a752ae1b880b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4408d592a6b54d29984bd2297ab8c2ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03276f01aada4601aaaca93c2c6c12fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88d2bd49039343d59398f35ac1f45ce1","IPY_MODEL_0f90eaa106144988a69afb34ac0fd249","IPY_MODEL_cd17a76e44fd4f4faf8835df9e4fbc2d"],"layout":"IPY_MODEL_9283e6be68da4c1a89faa07506390f25"}},"88d2bd49039343d59398f35ac1f45ce1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_105e75daa26d4719a532586e6b02d97b","placeholder":"‚Äã","style":"IPY_MODEL_8acecb9c778e405bbe0d681e119158c0","value":"Map:‚Äá100%"}},"0f90eaa106144988a69afb34ac0fd249":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39a118a2652a4060a03026b880cedec4","max":5177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_491a6bb0e23e46e0841247d3e90c04ae","value":5177}},"cd17a76e44fd4f4faf8835df9e4fbc2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9ce846a10564d03a9f70907a7c59619","placeholder":"‚Äã","style":"IPY_MODEL_79ac9cdec3ae4f14ba279cecd19df1f8","value":"‚Äá5177/5177‚Äá[00:01&lt;00:00,‚Äá3809.87‚Äáexamples/s]"}},"9283e6be68da4c1a89faa07506390f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"105e75daa26d4719a532586e6b02d97b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8acecb9c778e405bbe0d681e119158c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39a118a2652a4060a03026b880cedec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"491a6bb0e23e46e0841247d3e90c04ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9ce846a10564d03a9f70907a7c59619":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79ac9cdec3ae4f14ba279cecd19df1f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed578abdd2074334abbef48ae96d1cfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1b074be799440e1afce270b06785265","IPY_MODEL_d6be80b2091047f9806ebf143e79533a","IPY_MODEL_eb99e5cb8e7c4663b05b7cb5055bf0b5"],"layout":"IPY_MODEL_0de0d7048f37448fae0a5a1a20357635"}},"e1b074be799440e1afce270b06785265":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24fb0be54bc4417bbbb2a7b208c9452","placeholder":"‚Äã","style":"IPY_MODEL_888158ebd2e44c599eed8ba19f47a78d","value":"Map:‚Äá100%"}},"d6be80b2091047f9806ebf143e79533a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bf9fdbd09ce436c862bd51534e647dc","max":1295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f61c81852c04a48b45738279a4fde05","value":1295}},"eb99e5cb8e7c4663b05b7cb5055bf0b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd21c7f01f3b4db1b491f22a2ee20556","placeholder":"‚Äã","style":"IPY_MODEL_5de16125e43a46448290e31b8024d327","value":"‚Äá1295/1295‚Äá[00:00&lt;00:00,‚Äá4677.94‚Äáexamples/s]"}},"0de0d7048f37448fae0a5a1a20357635":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e24fb0be54bc4417bbbb2a7b208c9452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"888158ebd2e44c599eed8ba19f47a78d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bf9fdbd09ce436c862bd51534e647dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f61c81852c04a48b45738279a4fde05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd21c7f01f3b4db1b491f22a2ee20556":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5de16125e43a46448290e31b8024d327":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e21a99cb3396467d90afaca7688d6260":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b3187038b89492180df9b42ded98a89","IPY_MODEL_7a9209ba012147fdabe0549324b36260","IPY_MODEL_7dd12de412104ff2bcda8c9dd1e96492"],"layout":"IPY_MODEL_ce134881bd964a4f812874614dd9921a"}},"7b3187038b89492180df9b42ded98a89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42cb141a4c9f4ccbbb268ab918de8d8b","placeholder":"‚Äã","style":"IPY_MODEL_6ec46d7209d344669d9f44d25fd275f6","value":"Map:‚Äá100%"}},"7a9209ba012147fdabe0549324b36260":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_363eeaf36c8546e28b5fac6e1ea85fdd","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff6fbea349e54c61bc60babc96dade7b","value":3373}},"7dd12de412104ff2bcda8c9dd1e96492":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf4a274e06674d459d871a70d82eac93","placeholder":"‚Äã","style":"IPY_MODEL_7672a5a863d546269f50645d4adbd05c","value":"‚Äá3373/3373‚Äá[00:00&lt;00:00,‚Äá4532.16‚Äáexamples/s]"}},"ce134881bd964a4f812874614dd9921a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cb141a4c9f4ccbbb268ab918de8d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ec46d7209d344669d9f44d25fd275f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"363eeaf36c8546e28b5fac6e1ea85fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6fbea349e54c61bc60babc96dade7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf4a274e06674d459d871a70d82eac93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7672a5a863d546269f50645d4adbd05c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96ca1b283c084a7a82a81f783d9afe47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13f033c841d740478e3f83c2c6c7afce","IPY_MODEL_79cd2eedcf1948bd89125edfedd44f02","IPY_MODEL_e206341ec3af43278eb2970e8441bc4d"],"layout":"IPY_MODEL_10c2d00a00f24167abe18e9ee241c851"}},"13f033c841d740478e3f83c2c6c7afce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cdbeea7f0934be697cba3e4d43742b0","placeholder":"‚Äã","style":"IPY_MODEL_8f0bd4e0937a4a76ab6543373eef863a","value":"Map:‚Äá100%"}},"79cd2eedcf1948bd89125edfedd44f02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c035ee8cc4c441892071fee7ec07f63","max":6472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc4562d221b2409fb060d455b1d9cc16","value":6472}},"e206341ec3af43278eb2970e8441bc4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24836cad99b64c8e87bf9573d6765044","placeholder":"‚Äã","style":"IPY_MODEL_f8dfa86e7da0452f8f3f6ec2d0e3c56c","value":"‚Äá6472/6472‚Äá[00:00&lt;00:00,‚Äá6624.42‚Äáexamples/s]"}},"10c2d00a00f24167abe18e9ee241c851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cdbeea7f0934be697cba3e4d43742b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f0bd4e0937a4a76ab6543373eef863a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c035ee8cc4c441892071fee7ec07f63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc4562d221b2409fb060d455b1d9cc16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24836cad99b64c8e87bf9573d6765044":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8dfa86e7da0452f8f3f6ec2d0e3c56c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac71f8b87b534edd8cabd98380637ad1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e31b7c80d115471da0d152e50b373af5","IPY_MODEL_0835017442b841cfa7687cfb0b61bdea","IPY_MODEL_8dd7476ad2f744db82649b73e54fab5c"],"layout":"IPY_MODEL_692560f67b1c4f82822b788cf912491d"}},"e31b7c80d115471da0d152e50b373af5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76d91ae635c5494dba4d75bb4776eabc","placeholder":"‚Äã","style":"IPY_MODEL_bc4402b9e4904f498508715b32ca3ec8","value":"Map:‚Äá100%"}},"0835017442b841cfa7687cfb0b61bdea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_760a47d719604c2e9af5ca6400276329","max":2698,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5840ed16726d459ebb5243c9cb1a6b32","value":2698}},"8dd7476ad2f744db82649b73e54fab5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_853b8a8e996646f981614f0481381586","placeholder":"‚Äã","style":"IPY_MODEL_52bd1d892f8143c49d467aaf7bd78ed9","value":"‚Äá2698/2698‚Äá[00:00&lt;00:00,‚Äá5550.58‚Äáexamples/s]"}},"692560f67b1c4f82822b788cf912491d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76d91ae635c5494dba4d75bb4776eabc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc4402b9e4904f498508715b32ca3ec8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"760a47d719604c2e9af5ca6400276329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5840ed16726d459ebb5243c9cb1a6b32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"853b8a8e996646f981614f0481381586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52bd1d892f8143c49d467aaf7bd78ed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2113bab311fa4da584ccc4aacbd50726":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49cda0995d094898b0f27a097d9b4052","IPY_MODEL_5e9957edccba4a72b61ea363d8d5eb3d","IPY_MODEL_a30eba83c4214a40a151d3ba1695ba8d"],"layout":"IPY_MODEL_d3dd4528c3194159a2f5672ed4016957"}},"49cda0995d094898b0f27a097d9b4052":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e73d585989924147b4019fae0fca6bae","placeholder":"‚Äã","style":"IPY_MODEL_438d16a9d4b74d62925ea4caeb2c4c5e","value":"Map:‚Äá100%"}},"5e9957edccba4a72b61ea363d8d5eb3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25b958daf2a149ae8af65c5b6b2a8ce0","max":675,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8039c119fd94e8386a288307ce443ea","value":675}},"a30eba83c4214a40a151d3ba1695ba8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc104e5496ba400da62ef8a47f15b36a","placeholder":"‚Äã","style":"IPY_MODEL_4bb57b066d3e403283210f921548f319","value":"‚Äá675/675‚Äá[00:00&lt;00:00,‚Äá6032.75‚Äáexamples/s]"}},"d3dd4528c3194159a2f5672ed4016957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e73d585989924147b4019fae0fca6bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"438d16a9d4b74d62925ea4caeb2c4c5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25b958daf2a149ae8af65c5b6b2a8ce0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8039c119fd94e8386a288307ce443ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc104e5496ba400da62ef8a47f15b36a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bb57b066d3e403283210f921548f319":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a13a134f4f7943ea9a8c6c7892ccc4ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19f28320fd0a400d8cc3d08b48525d23","IPY_MODEL_5b7f4cc4e40a4c47bfca13e1a9b9456c","IPY_MODEL_9bf2e91711944ead9209393dea7dd1e4"],"layout":"IPY_MODEL_8b670280d6734605861cebeda9b7b7e6"}},"19f28320fd0a400d8cc3d08b48525d23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46fbe78a495940b7a376785891e1449b","placeholder":"‚Äã","style":"IPY_MODEL_0d558a87bf34466794a6ceab466ddb85","value":"Map:‚Äá100%"}},"5b7f4cc4e40a4c47bfca13e1a9b9456c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e74fd49f1fb4e938513845b0de1bec8","max":5824,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea37c4d5817245f5a9837afc906e261d","value":5824}},"9bf2e91711944ead9209393dea7dd1e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5212295356c4288ad0646c0b42dc839","placeholder":"‚Äã","style":"IPY_MODEL_4f6d7a050e514240b6d4347d9d89dc35","value":"‚Äá5824/5824‚Äá[00:10&lt;00:00,‚Äá546.51‚Äáexamples/s]"}},"8b670280d6734605861cebeda9b7b7e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46fbe78a495940b7a376785891e1449b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d558a87bf34466794a6ceab466ddb85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e74fd49f1fb4e938513845b0de1bec8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea37c4d5817245f5a9837afc906e261d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5212295356c4288ad0646c0b42dc839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f6d7a050e514240b6d4347d9d89dc35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9da224e587db4d36a657544c14bfcec0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9826b8835a0545c9b158d47e9f861803","IPY_MODEL_bd3e318741194404bd10935474c2cda4","IPY_MODEL_ff17767b662449e09909a09eef82515c"],"layout":"IPY_MODEL_432058237fa1472a9bd1f57e913584a2"}},"9826b8835a0545c9b158d47e9f861803":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d8fa3e44ff943a1bfe96d9a2ca0f718","placeholder":"‚Äã","style":"IPY_MODEL_a9578929340748728ff15584706d92fe","value":"Map:‚Äá100%"}},"bd3e318741194404bd10935474c2cda4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82e7abbf9ed2467ab597aa8ff7beed0d","max":648,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdc58993bb7c483abbbb933b07c2860f","value":648}},"ff17767b662449e09909a09eef82515c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9982e2b35f6b4984a1af301f7377862a","placeholder":"‚Äã","style":"IPY_MODEL_61ab039e52df44fca5f334775c339f71","value":"‚Äá648/648‚Äá[00:01&lt;00:00,‚Äá538.29‚Äáexamples/s]"}},"432058237fa1472a9bd1f57e913584a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d8fa3e44ff943a1bfe96d9a2ca0f718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9578929340748728ff15584706d92fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82e7abbf9ed2467ab597aa8ff7beed0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdc58993bb7c483abbbb933b07c2860f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9982e2b35f6b4984a1af301f7377862a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61ab039e52df44fca5f334775c339f71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8bed90029724e2aa9ba8b231e53337c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c51d04bc1174a19ae6778a457b5a626","IPY_MODEL_8c5d193505254dbd8a11a72be462137b","IPY_MODEL_4734f0b2a8474661bebb23c8ee559d5c"],"layout":"IPY_MODEL_f1548c9bace044e2b0198023b9ea91a6"}},"4c51d04bc1174a19ae6778a457b5a626":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9667110c11d46f893864dba96f65d45","placeholder":"‚Äã","style":"IPY_MODEL_ef91122b292440a6a7e3814d2bcdc039","value":"Map:‚Äá100%"}},"8c5d193505254dbd8a11a72be462137b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35c4b6e45cc4444b8601b6e6a472134b","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9210a51dffdf4b29b14379c0e1d99cba","value":3373}},"4734f0b2a8474661bebb23c8ee559d5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc52b889a7924b8f898922f77a14d348","placeholder":"‚Äã","style":"IPY_MODEL_96587e21cab64cefbf18ccbe4313a00e","value":"‚Äá3373/3373‚Äá[00:06&lt;00:00,‚Äá534.78‚Äáexamples/s]"}},"f1548c9bace044e2b0198023b9ea91a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9667110c11d46f893864dba96f65d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef91122b292440a6a7e3814d2bcdc039":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35c4b6e45cc4444b8601b6e6a472134b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9210a51dffdf4b29b14379c0e1d99cba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cc52b889a7924b8f898922f77a14d348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96587e21cab64cefbf18ccbe4313a00e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"837886731ea04534a86fd85e0de37b6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e60075fca014d838c533e50d449ed73","IPY_MODEL_89a1c91b4bfe4e5b81a7f5fd3bad88ee","IPY_MODEL_668a6dabbc2944c59bb8dbb8e9559567"],"layout":"IPY_MODEL_2ee72180977b4db2a42199f576d5bb7b"}},"1e60075fca014d838c533e50d449ed73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee726db9030c41a5a076bef331a462c0","placeholder":"‚Äã","style":"IPY_MODEL_847d659bb21848798b104d6fb4d4e017","value":"tokenizer_config.json:‚Äá"}},"89a1c91b4bfe4e5b81a7f5fd3bad88ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6c78f71e23b4a77bc9502070b1124c4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b62c45f9006438186917e27b5c9f997","value":1}},"668a6dabbc2944c59bb8dbb8e9559567":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a03371509521479dbb9379dc258afc55","placeholder":"‚Äã","style":"IPY_MODEL_f7ab4769cd7442db94438d6d6dee3af5","value":"‚Äá2.32k/?‚Äá[00:00&lt;00:00,‚Äá297kB/s]"}},"2ee72180977b4db2a42199f576d5bb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee726db9030c41a5a076bef331a462c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"847d659bb21848798b104d6fb4d4e017":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6c78f71e23b4a77bc9502070b1124c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4b62c45f9006438186917e27b5c9f997":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a03371509521479dbb9379dc258afc55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ab4769cd7442db94438d6d6dee3af5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd57684582d24cceb95ca0f9325c7fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4032f30663794fb3a82243c4b483a7da","IPY_MODEL_5184eb9752c945a2b39ddc6a778d9152","IPY_MODEL_9299fc98af544a758e488e01349a4322"],"layout":"IPY_MODEL_7f686aeb2e8f4a2d9989e2783c0af69e"}},"4032f30663794fb3a82243c4b483a7da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c235a1d20c54e5fa8b454344671cd62","placeholder":"‚Äã","style":"IPY_MODEL_fa8222d671ce47b0a4045869a8eb15f7","value":"spiece.model:‚Äá100%"}},"5184eb9752c945a2b39ddc6a778d9152":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11522d6ff089459ca0b0a5d26042c4bb","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df8045306eeb44029be486e281e91ba4","value":791656}},"9299fc98af544a758e488e01349a4322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd02d84ea9b44c678d836bdb09bddb59","placeholder":"‚Äã","style":"IPY_MODEL_bc31083d46d54e129977ce7f78781383","value":"‚Äá792k/792k‚Äá[00:00&lt;00:00,‚Äá11.3MB/s]"}},"7f686aeb2e8f4a2d9989e2783c0af69e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c235a1d20c54e5fa8b454344671cd62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa8222d671ce47b0a4045869a8eb15f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11522d6ff089459ca0b0a5d26042c4bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8045306eeb44029be486e281e91ba4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd02d84ea9b44c678d836bdb09bddb59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc31083d46d54e129977ce7f78781383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a32522a8fe814b2a9398024698e0bed5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fc775cf8d504e909e31410eb2ab5c8e","IPY_MODEL_864e450fcfc143698009794f5ce5b49f","IPY_MODEL_4f4b2c5f21ae4684a5727f53775de045"],"layout":"IPY_MODEL_54065d06e88940359f124964865d166b"}},"2fc775cf8d504e909e31410eb2ab5c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d347658e21849618d0057bf8ef8282a","placeholder":"‚Äã","style":"IPY_MODEL_e0b523232a3346d48d828c1fcec93e3b","value":"tokenizer.json:‚Äá"}},"864e450fcfc143698009794f5ce5b49f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4608845377d64143890623216e7b2f92","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_149cff8f3dcc419b8d6bcc3d8fe306be","value":1}},"4f4b2c5f21ae4684a5727f53775de045":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_200882a929fd48f9909b85e2d3fbaad2","placeholder":"‚Äã","style":"IPY_MODEL_effcc51be37e4890ab161518845e9e00","value":"‚Äá1.39M/?‚Äá[00:00&lt;00:00,‚Äá80.2MB/s]"}},"54065d06e88940359f124964865d166b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d347658e21849618d0057bf8ef8282a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b523232a3346d48d828c1fcec93e3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4608845377d64143890623216e7b2f92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"149cff8f3dcc419b8d6bcc3d8fe306be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"200882a929fd48f9909b85e2d3fbaad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"effcc51be37e4890ab161518845e9e00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c34e654d9e954c44b1a410295a7585de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e34b836fc374d7bb09c9b06d1fb4c1f","IPY_MODEL_bac4819e46e043b6b0069033a08e5831","IPY_MODEL_7f1f577fae1a4457b5e09edd15e70fa5"],"layout":"IPY_MODEL_d95d9525ff8a4424a65564de31f7487a"}},"7e34b836fc374d7bb09c9b06d1fb4c1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fef65a4a16674066bd4bbacbaa766a5c","placeholder":"‚Äã","style":"IPY_MODEL_e95c4bdc31794407922e06e3233a5dbd","value":"Map:‚Äá100%"}},"bac4819e46e043b6b0069033a08e5831":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e32b1a39e7e43b89bf276612955e3b1","max":5177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c70723e335e40e2959e5733cc55d661","value":5177}},"7f1f577fae1a4457b5e09edd15e70fa5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c39036a97c384e558498af94ab7db98d","placeholder":"‚Äã","style":"IPY_MODEL_06b72903d2464d1ab021d697824fa9cf","value":"‚Äá5177/5177‚Äá[00:05&lt;00:00,‚Äá996.52‚Äáexamples/s]"}},"d95d9525ff8a4424a65564de31f7487a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fef65a4a16674066bd4bbacbaa766a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e95c4bdc31794407922e06e3233a5dbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e32b1a39e7e43b89bf276612955e3b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c70723e335e40e2959e5733cc55d661":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c39036a97c384e558498af94ab7db98d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06b72903d2464d1ab021d697824fa9cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"779361e4f7d649d2b32a16e5985b2677":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0e495662dfe4853a250c594a18c20b4","IPY_MODEL_d6bcb71a408e4c13aaf9397c8300b9da","IPY_MODEL_5e12edd539a64f6b8763d5452d4b50b8"],"layout":"IPY_MODEL_c6881bc2b8f5428d9ecec1b272614795"}},"e0e495662dfe4853a250c594a18c20b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b004a075b8f54942916458fb8474de9f","placeholder":"‚Äã","style":"IPY_MODEL_284637d9ccf7498d8e3e994779de455f","value":"Map:‚Äá100%"}},"d6bcb71a408e4c13aaf9397c8300b9da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e49c3cb75f946e29f0376bc738f6fb5","max":1295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc7219b6a0c2458384589df0f7227a4a","value":1295}},"5e12edd539a64f6b8763d5452d4b50b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd833771ee944d15beaa811f4d2f633e","placeholder":"‚Äã","style":"IPY_MODEL_c297a1fd793440bc8f261c9b2eab8f0a","value":"‚Äá1295/1295‚Äá[00:01&lt;00:00,‚Äá996.27‚Äáexamples/s]"}},"c6881bc2b8f5428d9ecec1b272614795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b004a075b8f54942916458fb8474de9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"284637d9ccf7498d8e3e994779de455f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e49c3cb75f946e29f0376bc738f6fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc7219b6a0c2458384589df0f7227a4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd833771ee944d15beaa811f4d2f633e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c297a1fd793440bc8f261c9b2eab8f0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf9c9fbc56914aaeae651b59b9ddd920":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5704321149554d8ab2320b1455fa728f","IPY_MODEL_531a5feac20445e3a1c41d829dce40d4","IPY_MODEL_921ce617e7154da69631bdd7d1002adf"],"layout":"IPY_MODEL_d0162fd3274c492a8517e625f63ad005"}},"5704321149554d8ab2320b1455fa728f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_070dbe2248b14699be6e8402c9e3b65e","placeholder":"‚Äã","style":"IPY_MODEL_fee1f3a5b6454d96aa2526bc29a53e78","value":"Map:‚Äá100%"}},"531a5feac20445e3a1c41d829dce40d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ef3a83848ce4f0ab73f4c8791079de6","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65e8d5598cd2439ea5f1cc87cd7e8e0b","value":3373}},"921ce617e7154da69631bdd7d1002adf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2274072634394ce99cd5aa2b62f14c4e","placeholder":"‚Äã","style":"IPY_MODEL_db130e7af4454f849882f0b42be1cb76","value":"‚Äá3373/3373‚Äá[00:03&lt;00:00,‚Äá987.20‚Äáexamples/s]"}},"d0162fd3274c492a8517e625f63ad005":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"070dbe2248b14699be6e8402c9e3b65e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fee1f3a5b6454d96aa2526bc29a53e78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ef3a83848ce4f0ab73f4c8791079de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e8d5598cd2439ea5f1cc87cd7e8e0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2274072634394ce99cd5aa2b62f14c4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db130e7af4454f849882f0b42be1cb76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"190f6dd4cc2e45bfb27ead7212f86500":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b973bf6035f404d9dceca301f5b1f71","IPY_MODEL_8d9fff6fd8fd4a5d8f5397b4652a7f97","IPY_MODEL_79eccd030c0f4d898d1dbc12a088f5b6"],"layout":"IPY_MODEL_6bec665b2f2c454895e110ed1127ee1a"}},"5b973bf6035f404d9dceca301f5b1f71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3681235850b5462890754fd67805b6ec","placeholder":"‚Äã","style":"IPY_MODEL_592c80bf9e8c4e388164bc8bd411373d","value":"config.json:‚Äá"}},"8d9fff6fd8fd4a5d8f5397b4652a7f97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_993320e62ac74cb58935fdaa06e56769","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_faf5acf2da5d4e1598e50cee9b42c679","value":1}},"79eccd030c0f4d898d1dbc12a088f5b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad8c47aedf004f078a7c01c3e85060c8","placeholder":"‚Äã","style":"IPY_MODEL_05abd1e9fd0643ffbce0c664b0a4bd87","value":"‚Äá1.21k/?‚Äá[00:00&lt;00:00,‚Äá152kB/s]"}},"6bec665b2f2c454895e110ed1127ee1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3681235850b5462890754fd67805b6ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"592c80bf9e8c4e388164bc8bd411373d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"993320e62ac74cb58935fdaa06e56769":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"faf5acf2da5d4e1598e50cee9b42c679":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad8c47aedf004f078a7c01c3e85060c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05abd1e9fd0643ffbce0c664b0a4bd87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c71b56e4d134b84a0e39839c6197ff1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a19e00a074ef44efad41a918ad3c550e","IPY_MODEL_f52658795bce4b978510586190f576fc","IPY_MODEL_78dbd1306b0a416da49da9f454fa1fed"],"layout":"IPY_MODEL_0d21ba244af04367913d9cf4a55bf6c0"}},"a19e00a074ef44efad41a918ad3c550e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e05ba2ab586b4382ac790a8710cbde32","placeholder":"‚Äã","style":"IPY_MODEL_f5934522ca1644e0bd6db212f1f53cf6","value":"model.safetensors:‚Äá100%"}},"f52658795bce4b978510586190f576fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22fa68b8b3f40ed82a6d163feee7dac","max":242043056,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e9636781ea24bd4a20e30c92fbfff26","value":242043056}},"78dbd1306b0a416da49da9f454fa1fed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e49fded42a1b485b837d8eac290eca5b","placeholder":"‚Äã","style":"IPY_MODEL_09b160e03f124d37ad3cf354fb49f3d0","value":"‚Äá242M/242M‚Äá[00:01&lt;00:00,‚Äá199MB/s]"}},"0d21ba244af04367913d9cf4a55bf6c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05ba2ab586b4382ac790a8710cbde32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5934522ca1644e0bd6db212f1f53cf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a22fa68b8b3f40ed82a6d163feee7dac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e9636781ea24bd4a20e30c92fbfff26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e49fded42a1b485b837d8eac290eca5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b160e03f124d37ad3cf354fb49f3d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd58077164124b5d960e797aa4614bdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a200b7086ac4faf988b8e6942c91d55","IPY_MODEL_43bad56de5974313b595d2281f4e48d7","IPY_MODEL_68c9b20f4ee64947a273ea6e2c1028d3"],"layout":"IPY_MODEL_ca25eb32a33742d494421306e8e30df2"}},"8a200b7086ac4faf988b8e6942c91d55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_617f57c01c9943abb8474612ced1bafd","placeholder":"‚Äã","style":"IPY_MODEL_969bf95783544ad69ba0bbf728eb63d2","value":"generation_config.json:‚Äá100%"}},"43bad56de5974313b595d2281f4e48d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0af500c9870452d926e2302316a69eb","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56010cda6ab74cf2a3d56e28b772b6d1","value":147}},"68c9b20f4ee64947a273ea6e2c1028d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfbc2886cbd14320b330140b89855b09","placeholder":"‚Äã","style":"IPY_MODEL_371f0c6ac5d4499c8e856607a09dc795","value":"‚Äá147/147‚Äá[00:00&lt;00:00,‚Äá21.1kB/s]"}},"ca25eb32a33742d494421306e8e30df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"617f57c01c9943abb8474612ced1bafd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"969bf95783544ad69ba0bbf728eb63d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0af500c9870452d926e2302316a69eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56010cda6ab74cf2a3d56e28b772b6d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfbc2886cbd14320b330140b89855b09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"371f0c6ac5d4499c8e856607a09dc795":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1a3b707e7de4a858dba1245c05e293d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2b4d69fba314e199abd1833ecf668b4","IPY_MODEL_509395b40e724b1bab087e2477da3187","IPY_MODEL_7a9d165677a04d92a6055bfc2f24bcb3"],"layout":"IPY_MODEL_e57f49d9a7ca4227aa0de4cf2f70a3ae"}},"c2b4d69fba314e199abd1833ecf668b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a6ac4df69134224b2794b4d307fdf45","placeholder":"‚Äã","style":"IPY_MODEL_a950e4ffff214724805215e94e9e3999","value":"Map:‚Äá100%"}},"509395b40e724b1bab087e2477da3187":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08c351fab0ad42fe9845dee03e6e9173","max":5177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb1b8d4167294800b50905cad942189f","value":5177}},"7a9d165677a04d92a6055bfc2f24bcb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bbf9bdb7a4f435bbfa65e22fd319fb2","placeholder":"‚Äã","style":"IPY_MODEL_95ac26a68c1147a3a9560d91d39a4e03","value":"‚Äá5177/5177‚Äá[00:07&lt;00:00,‚Äá680.12‚Äáexamples/s]"}},"e57f49d9a7ca4227aa0de4cf2f70a3ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a6ac4df69134224b2794b4d307fdf45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a950e4ffff214724805215e94e9e3999":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08c351fab0ad42fe9845dee03e6e9173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb1b8d4167294800b50905cad942189f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bbf9bdb7a4f435bbfa65e22fd319fb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ac26a68c1147a3a9560d91d39a4e03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b186036747f34791b37c980a70afb34f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3262831c7894c119c96b2b4b116ba98","IPY_MODEL_99906d8f884546fdab217fe8de50a814","IPY_MODEL_d2023704d7d8450b98529bfb7ee0ca59"],"layout":"IPY_MODEL_57f81472b5574f0d8e09fa1351bf24df"}},"f3262831c7894c119c96b2b4b116ba98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6392dd6dc3604e508003a1c3e0400226","placeholder":"‚Äã","style":"IPY_MODEL_174618d1ef1d4bb39a059d6796110216","value":"Map:‚Äá100%"}},"99906d8f884546fdab217fe8de50a814":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61806ca89af24a4abad3f5f5063eefdb","max":1295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bada6003025457799a6e75b9788d35f","value":1295}},"d2023704d7d8450b98529bfb7ee0ca59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3670cda40584ea7b55280ee3996c519","placeholder":"‚Äã","style":"IPY_MODEL_2a24b2834b62400b8e8242f838d993ca","value":"‚Äá1295/1295‚Äá[00:01&lt;00:00,‚Äá673.99‚Äáexamples/s]"}},"57f81472b5574f0d8e09fa1351bf24df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6392dd6dc3604e508003a1c3e0400226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"174618d1ef1d4bb39a059d6796110216":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61806ca89af24a4abad3f5f5063eefdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bada6003025457799a6e75b9788d35f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3670cda40584ea7b55280ee3996c519":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a24b2834b62400b8e8242f838d993ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d1ef59d5f2e483f98f3e7f7dc86eae9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eee327eae7a64f91847d7a9f18cabcd8","IPY_MODEL_83ca040b8f5845c081ba726fc696684c","IPY_MODEL_898e7cf2a0344a68bb48b98e0e864060"],"layout":"IPY_MODEL_1936c1c434bc43fd9e1c7c58d8330c83"}},"eee327eae7a64f91847d7a9f18cabcd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bbed47540464015962f9d322d009206","placeholder":"‚Äã","style":"IPY_MODEL_1b3df1c31ee14af29bcb0b8b2f5ceedd","value":"Map:‚Äá100%"}},"83ca040b8f5845c081ba726fc696684c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa4abd237bf3483ba6f2be54e076a81c","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5c32272bfa94f4b96740ecfd6a2a4f4","value":3373}},"898e7cf2a0344a68bb48b98e0e864060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6074264ab2244303821b768d7f950796","placeholder":"‚Äã","style":"IPY_MODEL_bf9aba9fe61649768b737b71890e1f01","value":"‚Äá3373/3373‚Äá[00:05&lt;00:00,‚Äá676.03‚Äáexamples/s]"}},"1936c1c434bc43fd9e1c7c58d8330c83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bbed47540464015962f9d322d009206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b3df1c31ee14af29bcb0b8b2f5ceedd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa4abd237bf3483ba6f2be54e076a81c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c32272bfa94f4b96740ecfd6a2a4f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6074264ab2244303821b768d7f950796":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9aba9fe61649768b737b71890e1f01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93fbb81db61546b2a1f66f6424bf08e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f2f89c428d54c199f2f64c97ab58293","IPY_MODEL_931aa18bbff54ac4ba227928f1da4335","IPY_MODEL_5ab02981a4d9488b85c59e88b0f41db4"],"layout":"IPY_MODEL_848c996c62ec4ba1bd556ccae59a4979"}},"9f2f89c428d54c199f2f64c97ab58293":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba4ff5a6f3cc43649bc4d4835d86cefb","placeholder":"‚Äã","style":"IPY_MODEL_6c790127e6c54817b190973b78f06376","value":"Map:‚Äá100%"}},"931aa18bbff54ac4ba227928f1da4335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98a102ab57d748c58e3a0746d9112ffe","max":5177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f810d24f5a714b9589bd4cb55a9ca221","value":5177}},"5ab02981a4d9488b85c59e88b0f41db4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8655c7ddfc784e76b65f78deaaa11f61","placeholder":"‚Äã","style":"IPY_MODEL_7790894c2cdc4effbbdc31cedd6183dc","value":"‚Äá5177/5177‚Äá[00:08&lt;00:00,‚Äá631.92‚Äáexamples/s]"}},"848c996c62ec4ba1bd556ccae59a4979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba4ff5a6f3cc43649bc4d4835d86cefb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c790127e6c54817b190973b78f06376":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98a102ab57d748c58e3a0746d9112ffe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f810d24f5a714b9589bd4cb55a9ca221":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8655c7ddfc784e76b65f78deaaa11f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7790894c2cdc4effbbdc31cedd6183dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"332064343df840929c9215fdb65ff5a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32a0633f026941d5b80e39d593544f8b","IPY_MODEL_3b92d011db7a4ac3954d9dbd3ffe6965","IPY_MODEL_ae95509b1b994ff1890cb95d13ac4240"],"layout":"IPY_MODEL_17090c1e4a864fb7bd0e8aab4b209ca1"}},"32a0633f026941d5b80e39d593544f8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fc01dba1726444c8f14cf1e34dddca3","placeholder":"‚Äã","style":"IPY_MODEL_d57bb7226d44497ab9b9d092fad38d31","value":"Map:‚Äá100%"}},"3b92d011db7a4ac3954d9dbd3ffe6965":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e70e8cf247894d849392c5caad7915fb","max":1295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15b4c37abf8141f19f1724a1c365ccbf","value":1295}},"ae95509b1b994ff1890cb95d13ac4240":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4b8fb237d4a485ca1932de9765d7f0c","placeholder":"‚Äã","style":"IPY_MODEL_f0edbc11e70e4b2ba89b2c9301b156f7","value":"‚Äá1295/1295‚Äá[00:02&lt;00:00,‚Äá629.74‚Äáexamples/s]"}},"17090c1e4a864fb7bd0e8aab4b209ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc01dba1726444c8f14cf1e34dddca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d57bb7226d44497ab9b9d092fad38d31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e70e8cf247894d849392c5caad7915fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15b4c37abf8141f19f1724a1c365ccbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4b8fb237d4a485ca1932de9765d7f0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0edbc11e70e4b2ba89b2c9301b156f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcc953f5dd144ef49e6e9743e8a89c0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5369ead89af8476985caebee55dd1081","IPY_MODEL_493d1bdcf62b42fe857f86519d8cc360","IPY_MODEL_78d8787661ea44a5818aef81de58457b"],"layout":"IPY_MODEL_21ab7660500d469aa956acd8585798a7"}},"5369ead89af8476985caebee55dd1081":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65785fd5fa8e49e3afa55f424779e9c5","placeholder":"‚Äã","style":"IPY_MODEL_5fc1522a6cde4bfd98ee913e29d2fd1a","value":"Map:‚Äá100%"}},"493d1bdcf62b42fe857f86519d8cc360":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_747956f199fb40abaa7ddf0b66ac152d","max":3373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c90d5debec7242449fb4f01d3483ae12","value":3373}},"78d8787661ea44a5818aef81de58457b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0b6985a0470409a94b13480daf1457c","placeholder":"‚Äã","style":"IPY_MODEL_5b415c2a831940aba5d3b765a351e7c7","value":"‚Äá3373/3373‚Äá[00:05&lt;00:00,‚Äá630.56‚Äáexamples/s]"}},"21ab7660500d469aa956acd8585798a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65785fd5fa8e49e3afa55f424779e9c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc1522a6cde4bfd98ee913e29d2fd1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"747956f199fb40abaa7ddf0b66ac152d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c90d5debec7242449fb4f01d3483ae12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0b6985a0470409a94b13480daf1457c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b415c2a831940aba5d3b765a351e7c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a5855cd745242cf9449d60942068214":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca858e85db9e4f7e892e05e486951260","IPY_MODEL_3f0bccaa08324b2d9bbdc8e41eb711e4","IPY_MODEL_a179974394c54d6ea862ff52e459403d"],"layout":"IPY_MODEL_857018c85ea4484fb1e21ae13ea7044e"}},"ca858e85db9e4f7e892e05e486951260":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c5403ae70b84763ab089884e8d53e4c","placeholder":"‚Äã","style":"IPY_MODEL_b4b9d80d9db347e6a3561b1d525eaa74","value":"pytorch_model.bin:‚Äá100%"}},"3f0bccaa08324b2d9bbdc8e41eb711e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e30a03608544736ac473700d75a5209","max":208457495,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0bfd1e558034230a46ac911104e6618","value":208457495}},"a179974394c54d6ea862ff52e459403d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2af401078a444d09879f4fb2d1a43e8","placeholder":"‚Äã","style":"IPY_MODEL_8a23d987e1dc41bfa6830577776bdcb8","value":"‚Äá208M/208M‚Äá[00:02&lt;00:00,‚Äá87.3MB/s]"}},"857018c85ea4484fb1e21ae13ea7044e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c5403ae70b84763ab089884e8d53e4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4b9d80d9db347e6a3561b1d525eaa74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e30a03608544736ac473700d75a5209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0bfd1e558034230a46ac911104e6618":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2af401078a444d09879f4fb2d1a43e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a23d987e1dc41bfa6830577776bdcb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f662b23be99446eafe969c9f7ef022b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2b4069c833b4089a8be05dd846b0935","IPY_MODEL_df8999a76a104736830fc103d89567e0","IPY_MODEL_b461b9df2a314ef7b96de6eb05635305"],"layout":"IPY_MODEL_f4d87ec0e9484d19b7600750f40f5134"}},"c2b4069c833b4089a8be05dd846b0935":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a29dae7e4a747dda0e5014246ad4201","placeholder":"‚Äã","style":"IPY_MODEL_25ff99ba32c444a4876518170b0896bf","value":"model.safetensors:‚Äá100%"}},"df8999a76a104736830fc103d89567e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a6d35c7d42b4a5a9889bf5b1503dcf8","max":208419992,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9aa3e735d6ea470f933e49e282e062d0","value":208419992}},"b461b9df2a314ef7b96de6eb05635305":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cadc84cd9c44429a43a356350e17b8c","placeholder":"‚Äã","style":"IPY_MODEL_0ccb4361ee1c4460aa3eaf9a337e8cd3","value":"‚Äá208M/208M‚Äá[00:01&lt;00:00,‚Äá109MB/s]"}},"f4d87ec0e9484d19b7600750f40f5134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a29dae7e4a747dda0e5014246ad4201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25ff99ba32c444a4876518170b0896bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a6d35c7d42b4a5a9889bf5b1503dcf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa3e735d6ea470f933e49e282e062d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cadc84cd9c44429a43a356350e17b8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ccb4361ee1c4460aa3eaf9a337e8cd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}